[
  {
    "control_id": "1.1",
    "control": "Establish and Maintain Detailed Enterprise Asset Inventory",
    "IG1": "o",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260471,
    "recommendation_id": 2036748,
    "view_level": "2.13",
    "title": "Ensure Cloud Asset Inventory Is Enabled",
    "pivot_control_id": 363,
    "pivot_recommendation_id": 2036748,
    "url": "https://workbench.cisecurity.org/sections/1260471/recommendations/2036748",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 1"
      }
    ],
    "description": "GCP Cloud Asset Inventory is services that provides a historical view of GCP resources and IAM policies through a time-series database.  The information recorded includes metadata on Google Cloud resources, metadata on policies set on Google Cloud projects or resources, and runtime information gathered within a Google Cloud resource.",
    "rationale_statement": "The GCP resources and IAM policies captured by GCP Cloud Asset Inventory enables security analysis, resource change tracking, and compliance auditing.\nIt is recommended GCP Cloud Asset Inventory be enabled for all GCP projects.",
    "impact_statement": "",
    "audit_procedure": "From Google Cloud Console\nEnsure that the Cloud Asset API is enabled:\n\nGo to API & Services/Library by visiting https://console.cloud.google.com/apis/library\nSearch for Cloud Asset API and select the result for Cloud Asset API\nEnsure that API Enabled is displayed.\n\nFrom Google Cloud CLI\nEnsure that the Cloud Asset API is enabled:\n\nQuery enabled services:\n\ngcloud services list --enabled --filter=name:cloudasset.googleapis.com\n\nIf the API is listed, then it is enabled.  If the response is Listed 0 items the API is not enabled.",
    "remediation_procedure": "From Google Cloud Console\nEnable the Cloud Asset API:\n\nGo to API & Services/Library by visiting https://console.cloud.google.com/apis/library\nSearch for Cloud Asset API and select the result for Cloud Asset API\nClick the ENABLE button.\n\nFrom Google Cloud CLI\nEnable the Cloud Asset API:\n\nEnable the Cloud Asset API through the services interface:\n\ngcloud services enable cloudasset.googleapis.com",
    "default_value": "The Cloud Asset Inventory API is disabled by default in each project."
  },
  {
    "control_id": "2.2",
    "control": "Ensure Authorized Software is Currently Supported",
    "IG1": "o",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260473,
    "recommendation_id": 2036782,
    "view_level": "4.12",
    "title": "Ensure the Latest Operating System Updates Are Installed On Your Virtual Machines in All Projects",
    "pivot_control_id": 370,
    "pivot_recommendation_id": 2036782,
    "url": "https://workbench.cisecurity.org/sections/1260473/recommendations/2036782",
    "assessment_status": "Manual",
    "applicable_profiles": [
      {
        "title": "Level 2"
      }
    ],
    "description": "Google Cloud Virtual Machines have the ability via an OS Config agent API to periodically (about every 10 minutes) report OS inventory data. A patch compliance API periodically reads this data, and cross references metadata to determine if the latest updates are installed.\nThis is not the only Patch Management solution available to your organization and you should weigh your needs before committing to using this method.",
    "rationale_statement": "Keeping virtual machine operating systems up to date is a security best practice. Using this service will simplify this process.",
    "impact_statement": "Most Operating Systems require a restart or changing critical resources to apply the updates. Using the Google Cloud VM manager for its OS Patch management will incur additional costs for each VM managed by it. Please view the VM manager pricing reference for further information.",
    "audit_procedure": "From Google Cloud Console\nDetermine if OS Config API is Enabled for the Project\n\nNavigate into a project. In the expanded navigation menu located at the top left of the screen hover over APIs & Services. Then in the menu right of that select API Libraries\nSearch for \"VM Manager (OS Config API) or scroll down in the left hand column and select the filter labeled \"Compute\" where it is the last listed. Open this API.\nVerify the blue button at the top is enabled.\n\nDetermine if VM Instances have correct metadata tags for OSConfig parsing\n\nFrom the main Google Cloud console, open the hamburger menu in the top left. Mouse over Computer Engine to expand the menu next to it.\nUnder the \"Settings\" heading, select \"Metadata\".\nIn this view there will be a list of the project wide metadata tags for VMs. Determine if the tag \"enable-osconfig\" is set to \"true\".\n\nDetermine if the Operating System of VM Instances have the local OS-Config Agent running\nThere is no way to determine this from the Google Cloud console. The only way is to run operating specific commands locally inside the operating system via remote connection. For the sake of brevity of this recommendation please view the docs/troubleshooting/vm-manager/verify-setup reference at the bottom of the page. If you initialized your VM instance with a Google Supplied OS Image with a build date of later than v20200114 it will have the service installed. You should still determine its status for proper operation.\nVerify the service account you have setup for the project in Recommendation 4.1 is running\n\nGo to the VM instances page by visiting:\thttps://console.cloud.google.com/compute/instances.\nClick on each instance name to go to its VM instance details page.\nUnder the section Service Account, take note of the service account\nRun the commands locally for your operating system that are located at the docs/troubleshooting/vm-manager/verify-setup#service-account-enabled reference located at the bottom of this page. They should return the name of your service account.\n\nDetermine if Instances can connect to public update hosting\nEach type of operating system has its own update process. You will need to determine on each operating system that it can reach the update servers via its network connection. The VM Manager doesn't host the updates, it will only allow you to centrally issue a command to each VM to update.\nDetermine if OS Config API is Enabled for the Project\n\nIn each project you wish to enable run the following command\n\ngcloud services list\n\nIf osconfig.googleapis.com is in the left hand column it is enabled for this project.\n\nDetermine if VM Manager is Enabled for the Project\n\nWithin the project run the following command:\n\ngcloud compute instances os-inventory describe VM-NAME \\\n    --zone=ZONE\n\nThe output will look like\nINSTANCE_ID          INSTANCE_NAME  OS                                         OSCONFIG_AGENT_VERSION       UPDATE_TIME\n29255009728795105    centos7        CentOS Linux 7 (Core)                      20210217.00-g1.el7           2021-04-12T22:19:36.559Z\n5138980234596718741  rhel-8         Red Hat Enterprise Linux 8.3 (Ootpa)       20210316.00-g1.el8           2021-09-16T17:19:24Z\n7127836223366142250  windows        Microsoft Windows Server 2019 Datacenter   20210316.00.0+win@1          2021-09-16T17:13:18Z\n\nDetermine if VM Instances have correct metadata tags for OSConfig parsing\n\nSelect the project you want to view tagging in.\n\nFrom Google Cloud Console\n\nFrom the main Google Cloud console, open the hamburger menu in the top left. Mouse over Computer Engine to expand the menu next to it.\nUnder the \"Settings\" heading, select \"Metadata\".\nIn this view there will be a list of the project wide metadata tags for Vms. Verify a tag of \u2018enable-osconfig\u2019 is in this list and it is set to \u2018true\u2019.\n\nFrom Command Line\nRun the following command to view instance data\ngcloud compute instances list --format=\"table(name,status,tags.list())\"\n\nOn each instance it should have a tag of \u2018enable-osconfig\u2019 set to \u2018true\u2019\nDetermine if the Operating System of VM Instances have the local OS-Config Agent running\nThere is no way to determine this from the Google Cloud CLI. The best way is to run the the commands inside the operating system located at 'Check OS-Config agent is installed and running' at the /docs/troubleshooting/vm-manager/verify-setup reference at the bottom of the page. If you initialized your VM instance with a Google Supplied OS Image with a build date of later than v20200114 it will have the service installed. You should still determine its status.\nVerify the service account you have setup for the project in Recommendation 4.1 is running\n\nGo to the VM instances page by visiting:\thttps://console.cloud.google.com/compute/instances.\nClick on each instance name to go to its VM instance details page.\nUnder the section Service Account, take note of the service account\nView the compute/docs/troubleshooting/vm-manager/verify-setup#service-account-enabled resource at the bottom of the page for operating system specific commands to run locally.\n\nDetermine if Instances can connect to public update hosting\nLinux\nDebian Based Operating Systems\nsudo apt update\n\nThe output should have a numbered list of lines with Hit: URL of updates.\nRedhat Based Operating Systems\nyum check-update\n\nThe output should show a list of packages that have updates available.\nWindows\nping http://windowsupdate.microsoft.com/\n\nThe ping should successfully be delivered and received.",
    "remediation_procedure": "From Google Cloud Console\nEnabling OS Patch Management on a Project by Project Basis\nInstall OS Config API for the Project\n\nNavigate into a project. In the expanded portal menu located at the top left of the screen hover over \"APIs & Services\". Then in the menu right of that select \"API Libraries\"\nSearch for \"VM Manager (OS Config API) or scroll down in the left hand column and select the filter labeled \"Compute\" where it is the last listed. Open this API.\nClick the blue 'Enable' button.\n\nAdd MetaData Tags for OSConfig Parsing\n\nFrom the main Google Cloud console, open the portal menu in the top left. Mouse over Computer Engine to expand the menu next to it.\nUnder the \"Settings\" heading, select \"Metadata\".\nIn this view there will be a list of the project wide metadata tags for VMs. Click edit and 'add item' in the key column type 'enable-osconfig' and in the value column set it to 'true'.\n\nFrom Command Line\n\nFor project wide tagging, run the following command\n\ngcloud compute project-info add-metadata \\\n  --project <PROJECT_ID>\\\n  --metadata=enable-osconfig=TRUE\n\nPlease see the reference /compute/docs/troubleshooting/vm-manager/verify-setup#metadata-enabled at the bottom for more options like instance specific tagging.\nNote: Adding a new tag via commandline may overwrite existing tags. You will need to do this at a time of low usage for the least impact.\nInstall and Start the Local OSConfig for Data Parsing\nThere is no way to centrally manage or start the Local OSConfig agent. Please view the reference of manage-os#agent-install to view specific operating system commands.\nSetup a project wide Service Account\nPlease view Recommendation 4.1 to view how to setup a service account. Rerun the audit procedure to test if it has taken effect.\nEnable NAT or Configure Private Google Access to allow Access to Public Update Hosting\nFor the sake of brevity, please see the attached resources to enable NAT or Private Google Access. Rerun the audit procedure to test if it has taken effect.\nFrom Command Line:\nInstall OS Config API for the Project\n\nIn each project you wish to audit run gcloud services enable osconfig.googleapis.com\n\nInstall and Start the Local OSConfig for Data Parsing\nPlease view the reference of manage-os#agent-install to view specific operating system commands.\nSetup a project wide Service Account\nPlease view Recommendation 4.1 to view how to setup a service account. Rerun the audit procedure to test if it has taken effect.\nEnable NAT or Configure Private Google Access to allow Access to Public Update Hosting\nFor the sake of brevity, please see the attached resources to enable NAT or Private Google Access. Rerun the audit procedure to test if it has taken effect.\nDetermine if Instances can connect to public update hosting\nLinux\nDebian Based Operating Systems\nsudo apt update\n\nThe output should have a numbered list of lines with Hit: URL of updates.\nRedhat Based Operating Systems\nyum check-update\n\nThe output should show a list of packages that have updates available.\nWindows\nping http://windowsupdate.microsoft.com/\n\nThe ping should successfully be delivered and received.",
    "default_value": "By default most operating systems and programs do not update themselves. The Google Cloud VM Manager which is a dependency of the OS Patch management feature is installed on Google Built OS images with a build date of v20200114 or later. The VM manager is not enabled in a project by default and will need to be setup."
  },
  {
    "control_id": "2.7",
    "control": "Allowlist Authorized Scripts",
    "IG1": "-",
    "IG2": "-",
    "IG3": "o",
    "section_id": 1260479,
    "recommendation_id": 2036779,
    "view_level": "6.3.1",
    "title": "Ensure 'external scripts enabled' database flag for Cloud SQL SQL Server instance is set to 'off'",
    "pivot_control_id": 375,
    "pivot_recommendation_id": 2036779,
    "url": "https://workbench.cisecurity.org/sections/1260479/recommendations/2036779",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 1"
      }
    ],
    "description": "It is recommended to set external scripts enabled database flag for Cloud SQL SQL Server instance to off",
    "rationale_statement": "external scripts enabled enable the execution of scripts with certain remote language extensions. This property is OFF by default. When Advanced Analytics Services is installed, setup can optionally set this property to true. As the External Scripts Enabled feature allows scripts external to SQL such as files located in an R library to be executed, which could adversely affect the security of the system, hence this should be disabled. This recommendation is applicable to SQL Server database instances.",
    "impact_statement": "Setting custom flags via command line on certain instances will cause all omitted flags to be reset to defaults. This may cause you to lose custom flags and could result in unforeseen complications or instance restarts. Because of this, it is recommended you apply these flags changes during a period of low usage.",
    "audit_procedure": "From Google Cloud Console\n\nGo to the Cloud SQL Instances page in the Google Cloud Console by visiting https://console.cloud.google.com/sql/instances.\nSelect the instance to open its Instance Overview page\nEnsure the database flag external scripts enabled that has been set is listed under the Database flags section.\n\nFrom Google Cloud CLI\n\nEnsure the below command returns off for every Cloud SQL SQL Server database instance\n\ngcloud sql instances list --format=json | jq '.settings.databaseFlags[] | select(.name==\"external scripts enabled\")|.value'",
    "remediation_procedure": "From Google Cloud Console\n\nGo to the Cloud SQL Instances page in the Google Cloud Console by visiting https://console.cloud.google.com/sql/instances.\nSelect the SQL Server instance for which you want to enable to database flag.\nClick Edit.\nScroll down to the Flags section.\nTo set a flag that has not been set on the instance before, click Add item, choose the flag external scripts enabled from the drop-down menu, and set its value to off.\nClick Save to save your changes.\nConfirm your changes under Flags on the Overview page.\n\nFrom Google Cloud CLI\n\nConfigure the external scripts enabled database flag for every Cloud SQL SQL Server database instance using the below command.\n\ngcloud sql instances patch <INSTANCE_NAME> --database-flags \"external scripts enabled=off\"\n\nNote : \n\nThis command will overwrite all database flags previously set. To keep those and add new ones, include the values for all flags you want set on the instance; any flag not specifically included is set to its default value. For flags that do not take a value, specify the flag name followed by an equals sign (\"=\").",
    "default_value": "By default external scripts enabled is off"
  },
  {
    "control_id": "3.3",
    "control": "Configure Data Access Control Lists",
    "IG1": "o",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260470,
    "recommendation_id": 2036714,
    "view_level": "1.6",
    "title": "Ensure That IAM Users Are Not Assigned the Service Account User or Service Account Token Creator Roles at Project Level",
    "pivot_control_id": 379,
    "pivot_recommendation_id": 2036714,
    "url": "https://workbench.cisecurity.org/sections/1260470/recommendations/2036714",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 1"
      }
    ],
    "description": "It is recommended to assign the Service Account User (iam.serviceAccountUser) and Service Account Token Creator (iam.serviceAccountTokenCreator) roles to a user for a specific service account rather than assigning the role to a user at project level.",
    "rationale_statement": "A service account is a special Google account that belongs to an application or a virtual machine (VM), instead of to an individual end-user. Application/VM-Instance uses the service account to call the service's Google API so that users aren't directly involved.\nIn addition to being an identity, a service account is a resource that has IAM policies attached to it. These policies determine who can use the service account.\nUsers with IAM roles to update the App Engine and Compute Engine instances (such as App Engine Deployer or Compute Instance Admin) can effectively run code as the service accounts used to run these instances, and indirectly gain access to all the resources for which the service accounts have access. Similarly, SSH access to a Compute Engine instance may also provide the ability to execute code as that instance/Service account.\nBased on business needs, there could be multiple user-managed service accounts configured for a project. Granting the iam.serviceAccountUser or iam.serviceAccountTokenCreator roles to a user for a project gives the user access to all service accounts in the project, including service accounts that may be created in the future. This can result in elevation of privileges by using service accounts and corresponding Compute Engine instances.\nIn order to implement least privileges best practices, IAM users should not be assigned the Service Account User or Service Account Token Creator roles at the project level. Instead, these roles should be assigned to a user for a specific service account, giving that user access to the service account. The Service Account User allows a user to bind a service account to a long-running job service, whereas the Service Account Token Creator role allows a user to directly impersonate (or assert) the identity of a service account.",
    "impact_statement": "After revoking Service Account User or  Service Account Token Creator roles at the project level from all impacted user account(s), these roles should be assigned to a user(s) for specific service account(s) according to business needs.",
    "audit_procedure": "From Google Cloud Console\n\n\nGo to the IAM page in the GCP Console by visiting https://console.cloud.google.com/iam-admin/iam\n\n\nClick on the filter table text bar, Type Role: Service Account User.\n\n\nEnsure no user is listed as a result of the filter.\n\n\nClick on the filter table text bar, Type Role: Service Account Token Creator.\n\n\nEnsure no user is listed as a result of the filter.\n\n\nFrom Google Cloud CLI\nTo ensure IAM users are not assigned Service Account User role at the project level:\ngcloud projects get-iam-policy PROJECT_ID --format json | jq '.bindings[].role' | grep \"roles/iam.serviceAccountUser\"\n\ngcloud projects get-iam-policy PROJECT_ID --format json | jq '.bindings[].role' | grep \"roles/iam.serviceAccountTokenCreator\"\n\nThese commands should not return any output.",
    "remediation_procedure": "From Google Cloud Console\n\n\nGo to the IAM page in the GCP Console by visiting:  https://console.cloud.google.com/iam-admin/iam.\n\n\nClick on the filter table text bar. Type Role: Service Account User\n\n\nClick the Delete Bin icon in front of the role Service Account User for every user listed as a result of a filter.\n\n\nClick on the filter table text bar. Type Role: Service Account Token Creator\n\n\nClick the Delete Bin icon in front of the role Service Account Token Creator for every user listed as a result of a filter.\n\n\nFrom Google Cloud CLI\n\nUsing a text editor, remove the bindings with the roles/iam.serviceAccountUser or roles/iam.serviceAccountTokenCreator.\n\nFor example, you can use the iam.json file shown below as follows:\n{\n\"bindings\": [\n{\n   \"members\": [\n     \"serviceAccount:[email\u00a0protected]\",\n    ],\n    \"role\": \"roles/appengine.appViewer\"\n},\n{\n    \"members\": [\n     \"user:[email\u00a0protected]\"\n    ],\n    \"role\": \"roles/owner\"\n   },\n{\n    \"members\": [\n      \"serviceAccount:[email\u00a0protected]\",\n      \"serviceAccount:[email\u00a0protected]\"\n    ],\n    \"role\": \"roles/editor\"\n}\n],\n\"etag\": \"BwUjMhCsNvY=\"\n    }\n\n\nUpdate the project's IAM policy:\n\ngcloud projects set-iam-policy PROJECT_ID iam.json",
    "default_value": "By default, users do not have the Service Account User or Service Account Token Creator role assigned at project level."
  },
  {
    "control_id": "3.3",
    "control": "Configure Data Access Control Lists",
    "IG1": "o",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260470,
    "recommendation_id": 2036716,
    "view_level": "1.8",
    "title": "Ensure That Separation of Duties Is Enforced While Assigning Service Account Related Roles to Users",
    "pivot_control_id": 379,
    "pivot_recommendation_id": 2036716,
    "url": "https://workbench.cisecurity.org/sections/1260470/recommendations/2036716",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 2"
      }
    ],
    "description": "It is recommended that the principle of 'Separation of Duties' is enforced while assigning service-account related roles to users.",
    "rationale_statement": "The built-in/predefined IAM role Service Account admin allows the user/identity to create, delete, and manage service account(s).\nThe built-in/predefined IAM role Service Account User allows the user/identity (with adequate privileges on Compute and App Engine) to assign service account(s) to Apps/Compute Instances.\nSeparation of duties is the concept of ensuring that one individual does not have all necessary permissions to be able to complete a malicious action.  In Cloud IAM - service accounts, this could be an action such as using a service account to access resources that user should not normally have access to.\nSeparation of duties is a business control typically used in larger organizations, meant to help avoid security or privacy incidents and errors. It is considered best practice.\nNo user should have Service Account Admin and Service Account User roles assigned at the same time.",
    "impact_statement": "The removed role should be assigned to a different user based on business needs.",
    "audit_procedure": "From Google Cloud Console\n\n\nGo to IAM & Admin/IAM using https://console.cloud.google.com/iam-admin/iam.\n\n\nEnsure no member has the roles Service Account Admin and Service account User assigned together.\n\n\nFrom Google Cloud CLI\n\nList all users and role assignments:\n\ngcloud projects get-iam-policy [Project_ID] --format json | \\\n  jq -r '[\n          ([\"Service_Account_Admin_and_User\"] | (., map(length*\"-\"))), \n            (\n              [\n                .bindings[] | \n                select(.role == \"roles/iam.serviceAccountAdmin\" or .role == \"roles/iam.serviceAccountUser\").members[]\n              ] | \n              group_by(.) | \n              map({User: ., Count: length}) | \n              .[] | \n              select(.Count == 2).User | \n              unique\n            )\n        ] | \n        .[] | \n        @tsv'\n\n\nAll common users listed under Service_Account_Admin_and_User are assigned both the roles/iam.serviceAccountAdmin and roles/iam.serviceAccountUser roles.",
    "remediation_procedure": "From Google Cloud Console\n\n\nGo to IAM & Admin/IAM using https://console.cloud.google.com/iam-admin/iam.\n\n\nFor any member having both Service Account Admin and Service account User roles granted/assigned, click the Delete Bin icon to remove either role from the member.\nRemoval of a role should be done based on the business requirements.",
    "default_value": ""
  },
  {
    "control_id": "3.3",
    "control": "Configure Data Access Control Lists",
    "IG1": "o",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260470,
    "recommendation_id": 2036717,
    "view_level": "1.9",
    "title": "Ensure That Cloud KMS Cryptokeys Are Not Anonymously or Publicly Accessible",
    "pivot_control_id": 379,
    "pivot_recommendation_id": 2036717,
    "url": "https://workbench.cisecurity.org/sections/1260470/recommendations/2036717",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 1"
      }
    ],
    "description": "It is recommended that the IAM policy on Cloud KMS cryptokeys should restrict anonymous and/or public access.",
    "rationale_statement": "Granting permissions to allUsers or allAuthenticatedUsers allows anyone to access the dataset. Such access might not be desirable if sensitive data is stored at the location. In this case, ensure that anonymous and/or public access to a Cloud KMS cryptokey is not allowed.",
    "impact_statement": "Removing the binding for allUsers and allAuthenticatedUsers members denies accessing cryptokeys to anonymous or public users.",
    "audit_procedure": "From Google Cloud CLI\n\nList all Cloud KMS Cryptokeys.\n\ngcloud kms keys list --keyring=[key_ring_name] --location=global --format=json | jq '.[].name'\n\n\nEnsure the below command's output does not contain allUsers or allAuthenticatedUsers.\n\ngcloud kms keys get-iam-policy [key_name] --keyring=[key_ring_name] --location=global --format=json | jq '.bindings[].members[]'",
    "remediation_procedure": "From Google Cloud CLI\n\nList all Cloud KMS Cryptokeys.\n\ngcloud kms keys list --keyring=[key_ring_name] --location=global --format=json | jq '.[].name'\n\n\nRemove IAM policy binding for a KMS key to remove access to allUsers and allAuthenticatedUsers using the below command.\n\ngcloud kms keys remove-iam-policy-binding [key_name] --keyring=[key_ring_name] --location=global --member='allAuthenticatedUsers' --role='[role]'\n\ngcloud kms keys remove-iam-policy-binding [key_name] --keyring=[key_ring_name] --location=global --member='allUsers' --role='[role]'",
    "default_value": "By default Cloud KMS does not allow access to allUsers or allAuthenticatedUsers."
  },
  {
    "control_id": "3.3",
    "control": "Configure Data Access Control Lists",
    "IG1": "o",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260470,
    "recommendation_id": 2036719,
    "view_level": "1.11",
    "title": "Ensure That Separation of Duties Is Enforced While Assigning KMS Related Roles to Users",
    "pivot_control_id": 379,
    "pivot_recommendation_id": 2036719,
    "url": "https://workbench.cisecurity.org/sections/1260470/recommendations/2036719",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 2"
      }
    ],
    "description": "It is recommended that the principle of 'Separation of Duties' is enforced while assigning KMS related roles to users.",
    "rationale_statement": "The built-in/predefined IAM role Cloud KMS Admin allows the user/identity to create, delete, and manage service account(s).\nThe built-in/predefined IAM role Cloud KMS CryptoKey Encrypter/Decrypter allows the user/identity (with adequate privileges on concerned resources) to encrypt and decrypt data at rest using an encryption key(s).\nThe built-in/predefined IAM role Cloud KMS CryptoKey Encrypter allows the user/identity (with adequate privileges on concerned resources) to encrypt data at rest using an encryption key(s).\nThe built-in/predefined IAM role Cloud KMS CryptoKey Decrypter allows the user/identity (with adequate privileges on concerned resources) to decrypt data at rest using an encryption key(s).\nSeparation of duties is the concept of ensuring that one individual does not have all necessary permissions to be able to complete a malicious action. In Cloud KMS, this could be an action such as using a key to access and decrypt data a user should not normally have access to. Separation of duties is a business control typically used in larger organizations, meant to help avoid security or privacy incidents and errors. It is considered best practice.\nNo user(s) should have Cloud KMS Admin and any of the Cloud KMS CryptoKey Encrypter/Decrypter, Cloud KMS CryptoKey Encrypter, Cloud KMS CryptoKey Decrypter roles assigned at the same time.",
    "impact_statement": "Removed roles should be assigned to another user based on business needs.",
    "audit_procedure": "From Google Cloud Console\n\n\nGo to IAM & Admin/IAM by visiting: https://console.cloud.google.com/iam-admin/iam\n\n\nEnsure no member has the roles Cloud KMS Admin and any of the Cloud KMS CryptoKey Encrypter/Decrypter, Cloud KMS CryptoKey Encrypter, Cloud KMS CryptoKey Decrypter assigned.\n\n\nFrom Google Cloud CLI\n\nList all users and role assignments:\n\ngcloud projects get-iam-policy PROJECT_ID\n\n\nEnsure that there are no common users found in the member section for roles cloudkms.admin and any one of Cloud KMS CryptoKey Encrypter/Decrypter, Cloud KMS CryptoKey Encrypter, Cloud KMS CryptoKey Decrypter",
    "remediation_procedure": "From Google Cloud Console\n\n\nGo to IAM & Admin/IAM using https://console.cloud.google.com/iam-admin/iam\n\n\nFor any member having Cloud KMS Admin and any of the Cloud KMS CryptoKey Encrypter/Decrypter, Cloud KMS CryptoKey Encrypter, Cloud KMS CryptoKey Decrypter roles granted/assigned, click the Delete Bin icon to remove the role from the member.\n\n\nNote: Removing a role should be done based on the business requirement.",
    "default_value": ""
  },
  {
    "control_id": "3.3",
    "control": "Configure Data Access Control Lists",
    "IG1": "o",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260471,
    "recommendation_id": 2036728,
    "view_level": "2.3",
    "title": "Ensure That Retention Policies on Cloud Storage Buckets Used for Exporting Logs Are Configured Using Bucket Lock",
    "pivot_control_id": 379,
    "pivot_recommendation_id": 2036728,
    "url": "https://workbench.cisecurity.org/sections/1260471/recommendations/2036728",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 2"
      }
    ],
    "description": "Enabling retention policies on log buckets will protect logs stored in cloud storage buckets from being overwritten or accidentally deleted. It is recommended to set up retention policies and configure Bucket Lock on all storage buckets that are used as log sinks.",
    "rationale_statement": "Logs can be exported by creating one or more sinks that include a log filter and a destination. As Cloud Logging receives new log entries, they are compared against each sink. If a log entry matches a sink's filter, then a copy of the log entry is written to the destination.\nSinks can be configured to export logs in storage buckets. It is recommended to configure a data retention policy for these cloud storage buckets and to lock the data retention policy; thus permanently preventing the policy from being reduced or removed. This way, if the system is ever compromised by an attacker or a malicious insider who wants to cover their tracks, the activity logs are definitely preserved for forensics and security investigations.",
    "impact_statement": "Locking a bucket is an irreversible action. Once you lock a bucket, you cannot remove the retention policy from the bucket or decrease the retention period for the policy. You will then have to wait for the retention period for all items within the bucket before you can delete them, and then the bucket.",
    "audit_procedure": "From Google Cloud Console\n\n\nOpen the Cloud Storage browser in the Google Cloud Console by visiting https://console.cloud.google.com/storage/browser.\n\n\nIn the Column display options menu, make sure Retention policy is checked.\n\n\nIn the list of buckets, the retention period of each bucket is found in the Retention policy column. If the retention policy is locked, an image of a lock appears directly to the left of the retention period.\n\n\nFrom Google Cloud CLI\n\nTo list all sinks destined to storage buckets:\n\ngcloud logging sinks list --folder=FOLDER_ID | --organization=ORGANIZATION_ID | --project=PROJECT_ID\n\n\nFor every storage bucket listed above, verify that retention policies and Bucket Lock are enabled:\n\ngsutil retention get gs://BUCKET_NAME\n\nFor more information, see https://cloud.google.com/storage/docs/using-bucket-lock#view-policy.",
    "remediation_procedure": "From Google Cloud Console\n\n\nIf sinks are not configured, first follow the instructions in the recommendation: Ensure that sinks are configured for all Log entries.\n\n\nFor each storage bucket configured as a sink, go to the Cloud Storage browser at https://console.cloud.google.com/storage/browser/<BUCKET_NAME>.\n\n\nSelect the Bucket Lock tab near the top of the page.\n\n\nIn the Retention policy entry, click the Add Duration link. The Set a retention policy dialog box appears.\n\n\nEnter the desired length of time for the retention period and click Save policy.\n\n\nSet the Lock status for this retention policy to Locked.\n\n\nFrom Google Cloud CLI\n\nTo list all sinks destined to storage buckets:\n\ngcloud logging sinks list --folder=FOLDER_ID | --organization=ORGANIZATION_ID | --project=PROJECT_ID\n\n\nFor each storage bucket listed above, set a retention policy and lock it:\n\ngsutil retention set [TIME_DURATION] gs://[BUCKET_NAME]\ngsutil retention lock gs://[BUCKET_NAME]\n\nFor more information, visit https://cloud.google.com/storage/docs/using-bucket-lock#set-policy.",
    "default_value": "By default, storage buckets used as log sinks do not have retention policies and Bucket Lock configured."
  },
  {
    "control_id": "3.3",
    "control": "Configure Data Access Control Lists",
    "IG1": "o",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260471,
    "recommendation_id": 2036751,
    "view_level": "2.15",
    "title": "Ensure 'Access Approval' is 'Enabled'",
    "pivot_control_id": 379,
    "pivot_recommendation_id": 2036751,
    "url": "https://workbench.cisecurity.org/sections/1260471/recommendations/2036751",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 2"
      }
    ],
    "description": "GCP Access Approval enables you to require your organizations' explicit approval whenever Google support try to access your projects. You can then select users within your organization who can approve these requests through giving them a security role in IAM. All access requests display which Google Employee requested them in an email or Pub/Sub message that you can choose to Approve. This adds an additional control and logging of who in your organization approved/denied these requests.",
    "rationale_statement": "Controlling access to your information is one of the foundations of information security. Google Employees do have access to your organizations' projects for support reasons. With Access Approval, organizations can then be certain that their information is accessed by only approved Google Personnel.",
    "impact_statement": "To use Access Approval your organization will need have enabled Access Transparency and have at one of the following support level: Enhanced or Premium. There will be subscription costs associated with these support levels, as well as increased storage costs for storing the logs. You will also not be able to turn the Access Transparency which Access Approval depends on, off yourself. To do so you will need to submit a service request to Google Cloud Support. There will also be additional overhead in managing user permissions. There may also be a potential delay in support times as Google Personnel will have to wait for their access to be approved.",
    "audit_procedure": "From Google Cloud Console\nDetermine if Access Transparency is Enabled as it is a Dependency\n\n\nFrom the Google Cloud Home inside the project you wish to audit, click on the Navigation hamburger menu in the top left. Hover over the IAM & Admin Menu. Select settings in the middle of the column that opens.\n\n\nThe status should be \"Enabled' under the heading Access Transparency\n\n\nDetermine if Access Approval is Enabled\n\n\nFrom the Google Cloud Home, within the project you wish to check, click on the Navigation hamburger menu in the top left. Hover over the Security Menu. Select Access Approval in the middle of the column that opens.\n\n\nThe status will be displayed here. If you see a screen saying you need to enroll in Access Approval, it is not enabled.\n\n\nFrom Google Cloud CLI\nDetermine if Access Approval is Enabled\n\nFrom within the project you wish to audit, run the following command.\n\ngcloud access-approval settings get\n\n\nThe status will be displayed in the output.\n\nIF Access Approval is not enabled you should get this output:\nAPI [accessapproval.googleapis.com] not enabled on project [-----]. Would you like to enable and retry (this will take a few minutes)? (y/N)?\n\nAfter entering Y if you get the following output, it means that Access Transparency is not enabled:\nERROR: (gcloud.access-approval.settings.get) FAILED_PRECONDITION: Precondition check failed.",
    "remediation_procedure": "From Google Cloud Console\n\n\nFrom the Google Cloud Home, within the project you wish to enable, click on the Navigation hamburger menu in the top left. Hover over the Security Menu. Select Access Approval in the middle of the column that opens.\n\n\nThe status will be displayed here. On this screen, there is an option to click Enroll. If it is greyed out and you see an error bar at the top of the screen that says Access Transparency is not enabled please view the corresponding reference within this section to enable it.\n\n\nIn the second screen click Enroll.\n\n\nGrant an IAM Group or User the role with permissions to Add Users to be Access Approval message Recipients\n\n\nFrom the Google Cloud Home, within the project you wish to enable, click on the Navigation hamburger menu in the top left. Hover over the IAM and Admin. Select IAM in the middle of the column that opens.\n\n\nClick the blue button the says + ADD at the top of the screen.\n\n\nIn the principals field, select a user or group by typing in their associated email address.\n\n\nClick on the role field to expand it. In the filter field enter Access Approval Approver and select it.\n\n\nClick save.\n\n\nAdd a Group or User as an Approver for Access Approval Requests\n\n\nAs a user with the Access Approval Approver permission, within the project where you wish to add an email address to which request will be sent, click on the Navigation hamburger menu in the top left. Hover over the Security Menu. Select Access Approval in the middle of the column that opens.\n\n\nClick Manage Settings\n\n\nUnder Set up approval notifications, enter the email address associated with a Google Cloud User or Group you wish to send Access Approval requests to. All future access approvals will be sent as emails to this address.\n\n\nFrom Google Cloud CLI\n\nTo update all services in an entire project, run the following command from an account that has permissions as an 'Approver for Access Approval Requests'\n\ngcloud access-approval settings update --project=<project name> --enrolled_services=all --notification_emails='<email recipient for access approval requests>@<domain name>'",
    "default_value": "By default Access Approval and its dependency of Access Transparency are not enabled."
  },
  {
    "control_id": "3.3",
    "control": "Configure Data Access Control Lists",
    "IG1": "o",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260473,
    "recommendation_id": 2036776,
    "view_level": "4.9",
    "title": "Ensure That Compute Instances Do Not Have Public IP Addresses",
    "pivot_control_id": 379,
    "pivot_recommendation_id": 2036776,
    "url": "https://workbench.cisecurity.org/sections/1260473/recommendations/2036776",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 2"
      }
    ],
    "description": "Compute instances should not be configured to have external IP addresses.",
    "rationale_statement": "To reduce your attack surface, Compute instances should not have public IP addresses. Instead, instances should be configured behind load balancers, to minimize the instance's exposure to the internet.",
    "impact_statement": "Removing the external IP address from your Compute instance may cause some applications to stop working.",
    "audit_procedure": "From Google Cloud Console\n\n\nGo to the VM instances page by visiting:  https://console.cloud.google.com/compute/instances.\n\n\nFor every VM, ensure that there is no External IP configured.\n\n\nFrom Google Cloud CLI\ngcloud compute instances list --format=json\n\n\nThe output should not contain an accessConfigs section under networkInterfaces. Note that the natIP value is present only for instances that are running or for instances that are stopped but have a static IP address. For instances that are stopped and are configured to have an ephemeral public IP address, the natIP field will not be present.  Example output:\n\nnetworkInterfaces:\n- accessConfigs:\n  - kind: compute#accessConfig\n    name: External NAT\n    networkTier: STANDARD\n    type: ONE_TO_ONE_NAT\n\nException:\nInstances created by GKE should be excluded because some of them have external IP addresses and cannot be changed by editing the instance settings. Instances created by GKE should be excluded. These instances have names that start with \"gke-\" and are labeled \"goog-gke-node\".",
    "remediation_procedure": "From Google Cloud Console\n\n\nGo to the VM instances page by visiting:  https://console.cloud.google.com/compute/instances.\n\n\nClick on the instance name to go the the Instance detail page.\n\n\nClick Edit.\n\n\nFor each Network interface, ensure that External IP is set to None.\n\n\nClick Done and then click Save.\n\n\nFrom Google Cloud CLI\n\nDescribe the instance properties:\n\ngcloud compute instances describe <INSTANCE_NAME> --zone=<ZONE>\n\n\nIdentify the access config name that contains the external IP address. This access config appears in the following format:\n\nnetworkInterfaces:\n- accessConfigs:\n - kind: compute#accessConfig\n   name: External NAT\n   natIP: 130.211.181.55\n   type: ONE_TO_ONE_NAT\n\n\nDelete the access config.\n\ngcloud compute instances delete-access-config <INSTANCE_NAME> --zone=<ZONE> --access-config-name <ACCESS_CONFIG_NAME>\n\nIn the above example, the ACCESS_CONFIG_NAME is External NAT. The name of your access config might be different.\nPrevention:\nYou can configure the Define allowed external IPs for VM instances Organization Policy to prevent VMs from being configured with public IP addresses. Learn more at: https://console.cloud.google.com/orgpolicies/compute-vmExternalIpAccess",
    "default_value": "By default, Compute instances have a public IP address."
  },
  {
    "control_id": "3.3",
    "control": "Configure Data Access Control Lists",
    "IG1": "o",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260477,
    "recommendation_id": 2036758,
    "view_level": "5.1",
    "title": "Ensure That Cloud Storage Bucket Is Not Anonymously or Publicly Accessible",
    "pivot_control_id": 379,
    "pivot_recommendation_id": 2036758,
    "url": "https://workbench.cisecurity.org/sections/1260477/recommendations/2036758",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 1"
      }
    ],
    "description": "It is recommended that IAM policy on Cloud Storage bucket does not allows anonymous or public access.",
    "rationale_statement": "Allowing anonymous or public access grants permissions to anyone to access bucket content. Such access might not be desired if you are storing any sensitive data. Hence, ensure that anonymous or public access to a bucket is not allowed.",
    "impact_statement": "No storage buckets would be publicly accessible. You would have to explicitly administer bucket access.",
    "audit_procedure": "From Google Cloud Console\n\nGo to Storage browser by visiting https://console.cloud.google.com/storage/browser.\nClick on each bucket name to go to its Bucket details page.\nClick on the Permissions tab.\nEnsure that allUsers and allAuthenticatedUsers are not in the Members list.\n\nFrom Google Cloud CLI\n\nList all buckets in a project\n\ngsutil ls\n\n\nCheck the IAM Policy for each bucket:\n\ngsutil iam get gs://BUCKET_NAME\n\nNo role should contain allUsers and/or allAuthenticatedUsers as a member.\nUsing Rest API\n\nList all buckets in a project\n\nGet https://www.googleapis.com/storage/v1/b?project=<ProjectName>\n\n\nCheck the IAM Policy for each bucket\n\nGET https://www.googleapis.com/storage/v1/b/<bucketName>/iam\n\nNo role should contain allUsers and/or allAuthenticatedUsers as a member.",
    "remediation_procedure": "From Google Cloud Console\n\nGo to Storage browser by visiting https://console.cloud.google.com/storage/browser.\nClick on the bucket name to go to its Bucket details page.\nClick on the Permissions tab.\nClick Delete button in front of allUsers and allAuthenticatedUsers to remove that particular role assignment.\n\nFrom Google Cloud CLI\nRemove allUsers and allAuthenticatedUsers access.\ngsutil iam ch -d allUsers gs://BUCKET_NAME\ngsutil iam ch -d allAuthenticatedUsers gs://BUCKET_NAME\n\nPrevention:\nYou can prevent Storage buckets from becoming publicly accessible by setting up the Domain restricted sharing organization policy at: https://console.cloud.google.com/iam-admin/orgpolicies/iam-allowedPolicyMemberDomains .",
    "default_value": "By Default, Storage buckets are not publicly shared."
  },
  {
    "control_id": "3.3",
    "control": "Configure Data Access Control Lists",
    "IG1": "o",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260477,
    "recommendation_id": 2036763,
    "view_level": "5.2",
    "title": "Ensure That Cloud Storage Buckets Have Uniform Bucket-Level Access Enabled",
    "pivot_control_id": 379,
    "pivot_recommendation_id": 2036763,
    "url": "https://workbench.cisecurity.org/sections/1260477/recommendations/2036763",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 2"
      }
    ],
    "description": "It is recommended that uniform bucket-level access is enabled on Cloud Storage buckets.",
    "rationale_statement": "It is recommended to use uniform bucket-level access to unify and simplify how you grant access to your Cloud Storage resources.\nCloud Storage offers two systems for granting users permission to access your buckets and objects: Cloud Identity and Access Management (Cloud IAM) and Access Control Lists (ACLs). These systems act in parallel - in order for a user to access a Cloud Storage resource, only one of the systems needs to grant the user permission. Cloud IAM is used throughout Google Cloud and allows you to grant a variety of permissions at the bucket and project levels. ACLs are used only by Cloud Storage and have limited permission options, but they allow you to grant permissions on a per-object basis.\nIn order to support a uniform permissioning system, Cloud Storage has uniform bucket-level access. Using this feature disables ACLs for all Cloud Storage resources: access to Cloud Storage resources then is granted exclusively through Cloud IAM. Enabling uniform bucket-level access guarantees that if a Storage bucket is not publicly accessible, no object in the bucket is publicly accessible either.",
    "impact_statement": "If you enable uniform bucket-level access, you revoke access from users who gain their access solely through object ACLs.\nCertain Google Cloud services, such as Stackdriver, Cloud Audit Logs, and Datastore, cannot export to Cloud Storage buckets that have uniform bucket-level access enabled.",
    "audit_procedure": "From Google Cloud Console\n\n\nOpen the Cloud Storage browser in the Google Cloud Console by visiting: https://console.cloud.google.com/storage/browser\n\n\nFor each bucket, make sure that Access control column has the value Uniform.\n\n\nFrom Google Cloud CLI\n\nList all buckets in a project\n\ngsutil ls\n\n\nFor each bucket, verify that uniform bucket-level access is enabled.\n\ngsutil uniformbucketlevelaccess get gs://BUCKET_NAME/\n\nIf uniform bucket-level access is enabled, the response looks like:\nUniform bucket-level access setting for gs://BUCKET_NAME/:\n    Enabled: True\n    LockedTime: LOCK_DATE",
    "remediation_procedure": "From Google Cloud Console\n\n\nOpen the Cloud Storage browser in the Google Cloud Console by visiting: https://console.cloud.google.com/storage/browser\n\n\nIn the list of buckets, click on the name of the desired bucket.\n\n\nSelect the Permissions tab near the top of the page.\n\n\nIn the text box that starts with This bucket uses fine-grained access control..., click Edit.\n\n\nIn the pop-up menu that appears, select Uniform.\n\n\nClick Save.\n\n\nFrom Google Cloud CLI\nUse the on option in a uniformbucketlevelaccess set command:\ngsutil uniformbucketlevelaccess set on gs://BUCKET_NAME/\n\nPrevention\nYou can set up an Organization Policy to enforce that any new bucket has uniform bucket level access enabled. Learn more at:\nhttps://cloud.google.com/storage/docs/setting-org-policies#uniform-bucket",
    "default_value": "By default, Cloud Storage buckets do not have uniform bucket-level access enabled."
  },
  {
    "control_id": "3.3",
    "control": "Configure Data Access Control Lists",
    "IG1": "o",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260475,
    "recommendation_id": 2036755,
    "view_level": "6.1.2",
    "title": "Ensure \u2018Skip_show_database\u2019 Database Flag for Cloud SQL MySQL Instance Is Set to \u2018On\u2019",
    "pivot_control_id": 379,
    "pivot_recommendation_id": 2036755,
    "url": "https://workbench.cisecurity.org/sections/1260475/recommendations/2036755",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 1"
      }
    ],
    "description": "It is recommended to set skip_show_database database flag for Cloud SQL Mysql instance to on",
    "rationale_statement": "'skip_show_database' database flag prevents people from using the SHOW DATABASES statement if they do not have the SHOW DATABASES privilege. This can improve security if you have concerns about users being able to see databases belonging to other users. Its effect depends on the SHOW DATABASES privilege: If the variable value is ON, the SHOW DATABASES statement is permitted only to users who have the SHOW DATABASES privilege, and the statement displays all database names. If the value is OFF, SHOW DATABASES is permitted to all users, but displays the names of only those databases for which the user has the SHOW DATABASES or other privilege. This recommendation is applicable to Mysql database instances.",
    "impact_statement": "",
    "audit_procedure": "From Google Cloud Console\n\nGo to the Cloud SQL Instances page in the Google Cloud Console by visiting https://console.cloud.google.com/sql/instances.\nSelect the instance to open its Instance Overview page\nEnsure the database flag skip_show_database that has been set is listed under the Database flags section.\n\nFrom Google Cloud CLI\n\nList all Cloud SQL database Instances\n\ngcloud sql instances list\n\n\nEnsure the below command returns on for every Cloud SQL Mysql database instance\n\ngcloud sql instances describe INSTANCE_NAME --format=json | jq '.settings.databaseFlags[] | select(.name==\"skip_show_database\")|.value'",
    "remediation_procedure": "From Google Cloud Console\n\nGo to the Cloud SQL Instances page in the Google Cloud Console by visiting https://console.cloud.google.com/sql/instances.\nSelect the Mysql instance for which you want to enable to database flag.\nClick Edit.\nScroll down to the Flags section.\nTo set a flag that has not been set on the instance before, click Add item, choose the flag skip_show_database from the drop-down menu, and set its value to on.\nClick Save to save your changes.\nConfirm your changes under Flags on the Overview page.\n\nFrom Google Cloud CLI\n\nList all Cloud SQL database Instances\n\ngcloud sql instances list\n\n\nConfigure the skip_show_database database flag for every Cloud SQL Mysql database instance using the below command.\n\ngcloud sql instances patch INSTANCE_NAME --database-flags skip_show_database=on\n\nNote : \n\nThis command will overwrite all database flags previously set. To keep those and add new ones, include the values for all flags you want set on the instance; any flag not specifically included is set to its default value. For flags that do not take a value, specify the flag name followed by an equals sign (\"=\").",
    "default_value": ""
  },
  {
    "control_id": "3.3",
    "control": "Configure Data Access Control Lists",
    "IG1": "o",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260479,
    "recommendation_id": 2036781,
    "view_level": "6.3.2",
    "title": "Ensure that the 'cross db ownership chaining' database flag for Cloud SQL SQL Server instance is set to 'off'",
    "pivot_control_id": 379,
    "pivot_recommendation_id": 2036781,
    "url": "https://workbench.cisecurity.org/sections/1260479/recommendations/2036781",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 1"
      }
    ],
    "description": "It is recommended to set cross db ownership chaining database flag for Cloud SQL SQL Server instance to off.",
    "rationale_statement": "Use the cross db ownership for chaining option to configure cross-database ownership chaining for an instance of Microsoft SQL Server. This server option allows you to control cross-database ownership chaining at the database level or to allow cross-database ownership chaining for all databases. Enabling cross db ownership is not recommended unless all of the databases hosted by the instance of SQL Server must participate in cross-database ownership chaining and you are aware of the security implications of this setting. This recommendation is applicable to SQL Server database instances.",
    "impact_statement": "Updating flags may cause the database to restart. This may cause it to unavailable for a short amount of time, so this is best done at a time of low usage. You should also determine if the tables in your databases reference another table without using credentials for that database, as turning off cross database ownership will break this relationship.",
    "audit_procedure": "From Google Cloud Console\n\nGo to the Cloud SQL Instances page in the Google Cloud Console.\nSelect the instance to open its Instance Overview page\nEnsure the database flag cross db ownership chaining that has been set is listed under the Database flags section.\n\nFrom Google Cloud CLI\n\nEnsure the below command returns off for every Cloud SQL SQL Server database instance:\n\ngcloud sql instances list --format=json | jq '.settings.databaseFlags[] | select(.name==\"cross db ownership chaining\")|.value'",
    "remediation_procedure": "From Google Cloud Console\n\nGo to the Cloud SQL Instances page in the Google Cloud Console by visiting https://console.cloud.google.com/sql/instances.\nSelect the SQL Server instance for which you want to enable to database flag.\nClick Edit.\nScroll down to the Flags section.\nTo set a flag that has not been set on the instance before, click Add item, choose the flag cross db ownership chaining from the drop-down menu, and set its value to off.\nClick Save.\nConfirm the changes under Flags on the Overview page.\n\nFrom Google Cloud CLI\n\nConfigure the cross db ownership chaining database flag for every Cloud SQL SQL Server database instance using the below command:\n\ngcloud sql instances patch <INSTANCE_NAME> --database-flags \"cross db ownership chaining=off\"\n\nNote:\nThis command will overwrite all database flags previously set. To keep those and add new ones, include the values for all flags to be set on the instance; any flag not specifically included is set to its default value. For flags that do not take a value, specify the flag name followed by an equals sign (\"=\").",
    "default_value": "As you have to manually turn on this flag, the default value for this is 'On'. Though you would have had to design your database schema from the start to include this feature, it often is not enabled."
  },
  {
    "control_id": "3.3",
    "control": "Configure Data Access Control Lists",
    "IG1": "o",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260479,
    "recommendation_id": 2036787,
    "view_level": "6.3.7",
    "title": "Ensure that the 'contained database authentication' database flag for Cloud SQL on the SQL Server instance is set to 'off'",
    "pivot_control_id": 379,
    "pivot_recommendation_id": 2036787,
    "url": "https://workbench.cisecurity.org/sections/1260479/recommendations/2036787",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 1"
      }
    ],
    "description": "It is recommended to set contained database authentication database flag for Cloud SQL on the SQL Server instance to off.",
    "rationale_statement": "A contained database includes all database settings and metadata required to define the database and has no configuration dependencies on the instance of the Database Engine where the database is installed. Users can connect to the database without authenticating a login at the Database Engine level. Isolating the database from the Database Engine makes it possible to easily move the database to another instance of SQL Server. Contained databases have some unique threats that should be understood and mitigated by SQL Server Database Engine administrators. Most of the threats are related to the USER WITH PASSWORD authentication process, which moves the authentication boundary from the Database Engine level to the database level, hence this is recommended to disable this flag. This recommendation is applicable to SQL Server database instances.",
    "impact_statement": "When contained database authentication is off (0) for the instance, contained databases cannot be created, or attached to the Database Engine. Turning on logging will increase the required storage over time. Mismanaged logs may cause your storage costs to increase.Setting custom flags via command line on certain instances will cause all omitted flags to be reset to defaults. This may cause you to lose custom flags and could result in unforeseen complications or instance restarts. Because of this, it is recommended you apply these flags changes during a period of low usage.",
    "audit_procedure": "From Google Cloud Console\n\nGo to the Cloud SQL Instances page in the Google Cloud Console by visiting https://console.cloud.google.com/sql/instances.\nSelect the instance to open its Instance Overview page\nEnsure the database flag contained database authentication that has been set is listed under the Database flags section.\n\nFrom Google Cloud CLI\n\nEnsure the below command returns off for every Cloud SQL SQL Server database instance.\n\ngcloud sql instances list --format=json | jq '.settings.databaseFlags[] | select(.name==\"contained database authentication\")|.value'",
    "remediation_procedure": "From Google Cloud Console\n\nGo to the Cloud SQL Instances page in the Google Cloud Console by visiting https://console.cloud.google.com/sql/instances.\nSelect the SQL Server instance for which you want to enable to database flag.\nClick Edit.\nScroll down to the Flags section.\nTo set a flag that has not been set on the instance before, click Add item, choose the flag contained database authentication from the drop-down menu, and set its value to off.\nClick Save.\nConfirm the changes under Flags on the Overview page.\n\nFrom Google Cloud CLI\n\nConfigure the contained database authentication database flag for every Cloud SQL SQL Server database instance using the below command:\n\ngcloud sql instances patch <INSTANCE_NAME> --database-flags \"contained database authentication=off\"\n\nNote: \n\nThis command will overwrite all database flags previously set. To keep those and add new ones, include the values for all flags to be set on the instance; any flag not specifically included is set to its default value. For flags that do not take a value, specify the flag name followed by an equals sign (\"=\").",
    "default_value": ""
  },
  {
    "control_id": "3.3",
    "control": "Configure Data Access Control Lists",
    "IG1": "o",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260474,
    "recommendation_id": 2036789,
    "view_level": "6.5",
    "title": "Ensure That Cloud SQL Database Instances Do Not Implicitly Whitelist All Public IP Addresses",
    "pivot_control_id": 379,
    "pivot_recommendation_id": 2036789,
    "url": "https://workbench.cisecurity.org/sections/1260474/recommendations/2036789",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 1"
      }
    ],
    "description": "Database Server should accept connections only from trusted Network(s)/IP(s) and restrict access from public IP addresses.",
    "rationale_statement": "To minimize attack surface on a Database server instance, only trusted/known and required IP(s) should be white-listed to connect to it.\nAn authorized network should not have IPs/networks configured to 0.0.0.0/0 which will allow access to the instance from anywhere in the world. Note that authorized networks apply only to instances with public IPs.",
    "impact_statement": "The Cloud SQL database instance would not be available to public IP addresses.",
    "audit_procedure": "From Google Cloud Console\n\nGo to the Cloud SQL Instances page in the Google Cloud Console by visiting https://console.cloud.google.com/sql/instances.\nClick the instance name to open its Instance details page.\nUnder the Configuration section click Edit configurations\nUnder Configuration options expand the Connectivity section.\nEnsure that no authorized network is configured to allow 0.0.0.0/0.\n\nFrom Google Cloud CLI\n\nGet detailed configuration for every Cloud SQL database instance.\n\ngcloud sql instances list --format=json\n\nEnsure that the section settings: ipConfiguration : authorizedNetworks does not have any parameter value containing 0.0.0.0/0.",
    "remediation_procedure": "From Google Cloud Console\n\n\nGo to the Cloud SQL Instances page in the Google Cloud Console by visiting https://console.cloud.google.com/sql/instances.\n\n\nClick the instance name to open its Instance details page.\n\n\nUnder the Configuration section click Edit configurations\n\n\nUnder Configuration options expand the Connectivity section.\n\n\nClick the delete icon for the authorized network 0.0.0.0/0.\n\n\nClick Save to update the instance.\n\n\nFrom Google Cloud CLI\nUpdate the authorized network list by dropping off any addresses.\ngcloud sql instances patch <INSTANCE_NAME> --authorized-networks=IP_ADDR1,IP_ADDR2...\n\nPrevention:\nTo prevent new SQL instances from being configured to accept incoming connections from any IP addresses, set up a Restrict Authorized Networks on Cloud SQL instances Organization Policy at: https://console.cloud.google.com/iam-admin/orgpolicies/sql-restrictAuthorizedNetworks.",
    "default_value": "By default, authorized networks are not configured. Remote connection to Cloud SQL database instance is not possible unless authorized networks are configured."
  },
  {
    "control_id": "3.3",
    "control": "Configure Data Access Control Lists",
    "IG1": "o",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260474,
    "recommendation_id": 2036790,
    "view_level": "6.6",
    "title": "Ensure That Cloud SQL Database Instances Do Not Have Public IPs",
    "pivot_control_id": 379,
    "pivot_recommendation_id": 2036790,
    "url": "https://workbench.cisecurity.org/sections/1260474/recommendations/2036790",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 2"
      }
    ],
    "description": "It is recommended to configure Second Generation Sql instance to use private IPs instead of public IPs.",
    "rationale_statement": "To lower the organization's attack surface, Cloud SQL databases should not have public IPs. Private IPs provide improved network security and lower latency for your application.",
    "impact_statement": "Removing the public IP address on SQL instances may break some applications that relied on it for database connectivity.",
    "audit_procedure": "From Google Cloud Console\n\n\nGo to the Cloud SQL Instances page in the Google Cloud Console: https://console.cloud.google.com/sql/instances\n\n\nEnsure that every instance has a private IP address and no public IP address configured.\n\n\nFrom Google Cloud CLI\n\nList all Cloud SQL database instances using the following command:\n\ngcloud sql instances list\n\n\nFor every instance of type instanceType: CLOUD_SQL_INSTANCE with backendType: SECOND_GEN, get detailed configuration. Ignore instances of type READ_REPLICA_INSTANCE  because these instances inherit their settings from the primary instance. Also, note that first generation instances cannot be configured to have a private IP address.\n\ngcloud sql instances describe <INSTANCE_NAME>\n\n\nEnsure that the setting ipAddresses has an IP address configured of type: PRIVATE and has no IP address of type: PRIMARY. PRIMARY IP addresses are public addresses. An instance can have both a private and public address at the same time. Note also that you cannot use private IP with First Generation instances.",
    "remediation_procedure": "From Google Cloud Console\n\nGo to the Cloud SQL Instances page in the Google Cloud Console: https://console.cloud.google.com/sql/instances\nClick the instance name to open its Instance details page.\nSelect the Connections tab.\nDeselect the Public IP checkbox.\nClick Save to update the instance.\n\nFrom Google Cloud CLI\n\nFor every instance remove its public IP and assign a private IP instead:\n\ngcloud sql instances patch <INSTANCE_NAME> --network=<VPC_NETWORK_NAME> --no-assign-ip\n\n\nConfirm the changes using the following command::\n\ngcloud sql instances describe <INSTANCE_NAME>\n\nPrevention:\nTo prevent new SQL instances from getting configured with public IP addresses, set up a Restrict Public IP access on Cloud SQL instances Organization policy at: https://console.cloud.google.com/iam-admin/orgpolicies/sql-restrictPublicIp.",
    "default_value": "By default, Cloud Sql instances have a public IP."
  },
  {
    "control_id": "3.3",
    "control": "Configure Data Access Control Lists",
    "IG1": "o",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260476,
    "recommendation_id": 2036754,
    "view_level": "7.1",
    "title": "Ensure That BigQuery Datasets Are Not Anonymously or Publicly Accessible",
    "pivot_control_id": 379,
    "pivot_recommendation_id": 2036754,
    "url": "https://workbench.cisecurity.org/sections/1260476/recommendations/2036754",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 1"
      }
    ],
    "description": "It is recommended that the IAM policy on BigQuery datasets does not allow anonymous and/or public access.",
    "rationale_statement": "Granting permissions to allUsers or allAuthenticatedUsers allows anyone to access the dataset. Such access might not be desirable if sensitive data is being stored in the dataset. Therefore, ensure that anonymous and/or public access to a dataset is not allowed.",
    "impact_statement": "The dataset is not publicly accessible. Explicit modification of IAM privileges would be necessary to make them publicly accessible.",
    "audit_procedure": "From Google Cloud Console\n\nGo to BigQuery by visiting: https://console.cloud.google.com/bigquery.\nSelect a dataset from Resources.\nClick SHARING near the right side of the window and select Permissions.\nValidate that none of the attached roles contain allUsers or  allAuthenticatedUsers.\n\nFrom Google Cloud CLI\nList the name of all datasets.\nbq ls\n\nRetrieve each dataset details using the following command:\nbq show PROJECT_ID:DATASET_NAME\n\nEnsure that allUsers and allAuthenticatedUsers have not been granted access to the dataset.",
    "remediation_procedure": "From Google Cloud Console\n\nGo to BigQuery by visiting: https://console.cloud.google.com/bigquery.\nSelect the dataset from 'Resources'.\nClick SHARING near the right side of the window and select Permissions.\nReview each attached role.\nClick the delete icon for each member allUsers or allAuthenticatedUsers. On the popup click Remove.\n\nFrom Google Cloud CLI\nList the name of all datasets.\nbq ls\n\nRetrieve the data set details:\nbq show --format=prettyjson PROJECT_ID:DATASET_NAME > PATH_TO_FILE\n\nIn the access section of the JSON file, update the dataset information to remove all roles containing allUsers or allAuthenticatedUsers.\nUpdate the dataset:\nbq update --source PATH_TO_FILE PROJECT_ID:DATASET_NAME\n\nPrevention:\nYou can prevent Bigquery dataset from becoming publicly accessible by setting up the Domain restricted sharing organization policy at: https://console.cloud.google.com/iam-admin/orgpolicies/iam-allowedPolicyMemberDomains .",
    "default_value": "By default, BigQuery datasets are not publicly accessible."
  },
  {
    "control_id": "3.10",
    "control": "Encrypt Sensitive Data in Transit",
    "IG1": "-",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260472,
    "recommendation_id": 2036747,
    "view_level": "3.9",
    "title": "Ensure No HTTPS or SSL Proxy Load Balancers Permit SSL Policies With Weak Cipher Suites",
    "pivot_control_id": 528,
    "pivot_recommendation_id": 2036747,
    "url": "https://workbench.cisecurity.org/sections/1260472/recommendations/2036747",
    "assessment_status": "Manual",
    "applicable_profiles": [
      {
        "title": "Level 1"
      }
    ],
    "description": "Secure Sockets Layer (SSL) policies determine what port Transport Layer Security (TLS) features clients are permitted to use when connecting to load balancers. To prevent usage of insecure features, SSL policies should use (a) at least TLS 1.2 with the MODERN profile; or (b) the RESTRICTED profile, because it effectively requires clients to use TLS 1.2 regardless of the chosen minimum TLS version; or (3) a CUSTOM profile that does not support any of the following features:\nTLS_RSA_WITH_AES_128_GCM_SHA256\nTLS_RSA_WITH_AES_256_GCM_SHA384\nTLS_RSA_WITH_AES_128_CBC_SHA\nTLS_RSA_WITH_AES_256_CBC_SHA\nTLS_RSA_WITH_3DES_EDE_CBC_SHA",
    "rationale_statement": "Load balancers are used to efficiently distribute traffic across multiple servers. Both SSL proxy and HTTPS load balancers are external load balancers, meaning they distribute traffic from the Internet to a GCP network. GCP customers can configure load balancer SSL policies with a minimum TLS version (1.0, 1.1, or 1.2) that clients can use to establish a connection, along with a profile (Compatible, Modern, Restricted, or Custom) that specifies permissible cipher suites. To comply with users using outdated protocols, GCP load balancers can be configured to permit insecure cipher suites. In fact, the GCP default SSL policy uses a minimum TLS version of 1.0 and a Compatible profile, which allows the widest range of insecure cipher suites. As a result, it is easy for customers to configure a load balancer without even knowing that they are permitting outdated cipher suites.",
    "impact_statement": "Creating more secure SSL policies can prevent clients using older TLS versions from establishing a connection.",
    "audit_procedure": "From Google Cloud Console\n\nSee all load balancers by visiting https://console.cloud.google.com/net-services/loadbalancing/loadBalancers/list.\nFor each load balancer for SSL (Proxy) or HTTPS, click on its name to go the Load balancer details page.\nEnsure that each target proxy entry in the Frontend table has an SSL Policy configured.\nClick on each SSL policy to go to its SSL policy details page.\nEnsure that the SSL policy satisfies one of the following conditions:\n\n\nhas a Min TLS set to TLS 1.2 and Profile set to Modern profile, or\nhas Profile set to Restricted. Note that a Restricted profile effectively requires clients to use TLS 1.2 regardless of the chosen minimum TLS version, or\nhas Profile set to Custom and the following features are all disabled:\n\nTLS_RSA_WITH_AES_128_GCM_SHA256\nTLS_RSA_WITH_AES_256_GCM_SHA384\nTLS_RSA_WITH_AES_128_CBC_SHA\nTLS_RSA_WITH_AES_256_CBC_SHA\nTLS_RSA_WITH_3DES_EDE_CBC_SHA\n\nFrom Google Cloud CLI\n\nList all TargetHttpsProxies and TargetSslProxies.\n\ngcloud compute target-https-proxies list\ngcloud compute target-ssl-proxies list\n\n\nFor each target proxy, list its properties:\n\ngcloud compute target-https-proxies describe TARGET_HTTPS_PROXY_NAME\ngcloud compute target-ssl-proxies describe TARGET_SSL_PROXY_NAME\n\n\nEnsure that the sslPolicy field is present and identifies the name of the SSL policy:\n\nsslPolicy: https://www.googleapis.com/compute/v1/projects/PROJECT_ID/global/sslPolicies/SSL_POLICY_NAME\n\nIf the sslPolicy field is missing from the configuration, it means that the GCP default policy is used, which is insecure.\n\nDescribe the SSL policy:\n\ngcloud compute ssl-policies describe SSL_POLICY_NAME\n\n\nEnsure that the policy satisfies one of the following conditions:\n\n\nhas Profile set to Modern and minTlsVersion set to TLS_1_2, or\nhas Profile set to Restricted, or\nhas Profile set to Custom and \u00a0enabledFeatures does not contain any of the following values:\n\nTLS_RSA_WITH_AES_128_GCM_SHA256\nTLS_RSA_WITH_AES_256_GCM_SHA384\nTLS_RSA_WITH_AES_128_CBC_SHA\nTLS_RSA_WITH_AES_256_CBC_SHA\nTLS_RSA_WITH_3DES_EDE_CBC_SHA",
    "remediation_procedure": "From Google Cloud Console\nIf the TargetSSLProxy or TargetHttpsProxy does not have an SSL policy configured, create a new SSL policy. Otherwise, modify the existing insecure policy.\n\nNavigate to the SSL Policies page by visiting: https://console.cloud.google.com/net-security/sslpolicies\nClick on the name of the insecure policy to go to its SSL policy details page.\nClick EDIT.\nSet Minimum TLS version to TLS 1.2.\nSet Profile to Modern or Restricted.\nAlternatively, if teh user selects the profile Custom, make sure that the following features are disabled:\n\nTLS_RSA_WITH_AES_128_GCM_SHA256\nTLS_RSA_WITH_AES_256_GCM_SHA384\nTLS_RSA_WITH_AES_128_CBC_SHA\nTLS_RSA_WITH_AES_256_CBC_SHA\nTLS_RSA_WITH_3DES_EDE_CBC_SHA\n\nFrom Google Cloud CLI\n\nFor each insecure SSL policy, update it to use secure cyphers:\n\ngcloud compute ssl-policies update NAME [--profile COMPATIBLE|MODERN|RESTRICTED|CUSTOM] --min-tls-version 1.2 [--custom-features FEATURES]\n\n\nIf the target proxy has a GCP default SSL policy, use the following command corresponding to the proxy type to update it.\n\ngcloud compute target-ssl-proxies update TARGET_SSL_PROXY_NAME --ssl-policy SSL_POLICY_NAME\ngcloud compute target-https-proxies update TARGET_HTTPS_POLICY_NAME --ssl-policy SSL_POLICY_NAME",
    "default_value": "The GCP default SSL policy is the least secure setting: Min TLS 1.0 and Compatible profile"
  },
  {
    "control_id": "3.10",
    "control": "Encrypt Sensitive Data in Transit",
    "IG1": "-",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260473,
    "recommendation_id": 2036761,
    "view_level": "4.3",
    "title": "Ensure \u201cBlock Project-Wide SSH Keys\u201d Is Enabled for VM Instances",
    "pivot_control_id": 528,
    "pivot_recommendation_id": 2036761,
    "url": "https://workbench.cisecurity.org/sections/1260473/recommendations/2036761",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 1"
      }
    ],
    "description": "It is recommended to use Instance specific SSH key(s) instead of using common/shared project-wide SSH key(s) to access Instances.",
    "rationale_statement": "Project-wide SSH keys are stored in Compute/Project-meta-data. Project wide SSH keys can be used to login into all the instances within project. Using project-wide SSH keys eases the SSH key management but if compromised, poses the security risk which can impact all the instances within project.\nIt is recommended to use Instance specific SSH keys which can limit the attack surface if the SSH keys are compromised.",
    "impact_statement": "Users already having Project-wide ssh key pairs and using third party SSH clients will lose access to the impacted Instances. For Project users using gcloud or GCP Console based SSH option, no manual key creation and distribution is required and will be handled by GCE (Google Compute Engine) itself. To access Instance using third party SSH clients Instance specific SSH key pairs need to be created and distributed to the required users.",
    "audit_procedure": "From Google Cloud Console\n\n\nGo to the VM instances page by visiting https://console.cloud.google.com/compute/instances. It will list all the instances in your project.\n\n\nFor every instance, click on the name of the instance.\n\n\nUnder SSH Keys, ensure Block project-wide SSH keys is selected.\n\n\nFrom Google Cloud CLI\n\nList the instances in your project and get details on each instance:\n\ngcloud compute instances list --format=json\n\n\nEnsure key: block-project-ssh-keys is set to value: 'true'.",
    "remediation_procedure": "From Google Cloud Console\n\n\nGo to the VM instances page by visiting: https://console.cloud.google.com/compute/instances. It will list all the instances in your project.\n\n\nClick on the name of the Impacted instance\n\n\nClick Edit in the toolbar\n\n\nUnder SSH Keys, go to the Block project-wide SSH keys checkbox\n\n\nTo block users with project-wide SSH keys from connecting to this instance, select Block project-wide SSH keys\n\n\nClick Save at the bottom of the page\n\n\nRepeat steps for every impacted Instance\n\n\nFrom Google Cloud CLI\nTo block project-wide public SSH keys, set the metadata value to TRUE:\ngcloud compute instances add-metadata <INSTANCE_NAME> --metadata block-project-ssh-keys=TRUE",
    "default_value": "By Default Block Project-wide SSH keys is not enabled."
  },
  {
    "control_id": "3.10",
    "control": "Encrypt Sensitive Data in Transit",
    "IG1": "-",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260473,
    "recommendation_id": 2036778,
    "view_level": "4.10",
    "title": "Ensure That App Engine Applications Enforce HTTPS Connections",
    "pivot_control_id": 528,
    "pivot_recommendation_id": 2036778,
    "url": "https://workbench.cisecurity.org/sections/1260473/recommendations/2036778",
    "assessment_status": "Manual",
    "applicable_profiles": [
      {
        "title": "Level 2"
      }
    ],
    "description": "In order to maintain the highest level of security all connections to an application should be secure by default.",
    "rationale_statement": "Insecure HTTP connections maybe subject to eavesdropping which can expose sensitive data.",
    "impact_statement": "All connections to appengine will automatically be redirected to the HTTPS endpoint ensuring that all connections are secured by TLS.",
    "audit_procedure": "Verify that the app.yaml file controlling the application contains a line which enforces secure connections. For example\nhandlers:\n- url: /.*\n  secure: always\n  redirect_http_response_code: 301\n  script: auto\n\nhttps://cloud.google.com/appengine/docs/standard/python3/config/appref",
    "remediation_procedure": "Add a line to the app.yaml file controlling the application which enforces secure connections. For example\nhandlers:\n- url: /.*\n  **secure: always**\n  redirect_http_response_code: 301\n  script: auto\n\n[https://cloud.google.com/appengine/docs/standard/python3/config/appref]",
    "default_value": "By default both HTTP and HTTP are supported"
  },
  {
    "control_id": "3.10",
    "control": "Encrypt Sensitive Data in Transit",
    "IG1": "-",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260474,
    "recommendation_id": 2036788,
    "view_level": "6.4",
    "title": "Ensure That the Cloud SQL Database Instance Requires All Incoming Connections To Use SSL",
    "pivot_control_id": 528,
    "pivot_recommendation_id": 2036788,
    "url": "https://workbench.cisecurity.org/sections/1260474/recommendations/2036788",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 1"
      }
    ],
    "description": "It is recommended to enforce all incoming connections to SQL database instance to use SSL.",
    "rationale_statement": "SQL database connections if successfully trapped (MITM); can reveal sensitive data like credentials, database queries, query outputs etc.\nFor security, it is recommended to always use SSL encryption when connecting to your instance.\nThis recommendation is applicable for Postgresql, MySql generation 1, MySql generation 2 and SQL Server 2017 instances.",
    "impact_statement": "After enforcing SSL connection, existing client will not be able to communicate with SQL server unless configured with appropriate client-certificates to communicate to SQL database instance.",
    "audit_procedure": "From Google Cloud Console\n\n\nGo to https://console.cloud.google.com/sql/instances.\n\n\nClick on an instance name to see its configuration overview.\n\n\nIn the left-side panel, select Connections.\n\n\nIn the SSL connections section, ensure that Only secured connections are allowed to connect to this instance..\n\n\nFrom Google Cloud CLI\n\nGet the detailed configuration for every SQL database instance using the following command:\n\ngcloud sql instances list --format=json\n\nEnsure that section settings: ipConfiguration has the parameter requireSsl set to true.",
    "remediation_procedure": "From Google Cloud Console\n\n\nGo to https://console.cloud.google.com/sql/instances.\n\n\nClick on an instance name to see its configuration overview.\n\n\nIn the left-side panel, select Connections.\n\n\nIn the SSL connections section, click Allow only SSL connections.\n\n\nUnder Configure SSL server certificates click Create new certificate.\n\n\nUnder Configure SSL client certificates click Create a client certificate.\n\n\nFollow the instructions shown to learn how to connect to your instance.\n\n\nFrom Google Cloud CLI\nTo enforce SSL encryption for an instance run the command:\ngcloud sql instances patch <INSTANCE_NAME> --require-ssl\n\nNote:\nRESTART is required for type MySQL Generation 1 Instances (backendType: FIRST_GEN) to get this configuration in effect.",
    "default_value": "By default parameter settings: ipConfiguration: requireSsl is not set which is equivalent to requireSsl:false."
  },
  {
    "control_id": "3.11",
    "control": "Encrypt Sensitive Data at Rest",
    "IG1": "-",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260470,
    "recommendation_id": 2036718,
    "view_level": "1.10",
    "title": "Ensure KMS Encryption Keys Are Rotated Within a Period of 90 Days",
    "pivot_control_id": 386,
    "pivot_recommendation_id": 2036718,
    "url": "https://workbench.cisecurity.org/sections/1260470/recommendations/2036718",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 1"
      }
    ],
    "description": "Google Cloud Key Management Service stores cryptographic keys in a hierarchical structure designed for useful and elegant access control management.\nThe format for the rotation schedule depends on the client library that is used. For the gcloud command-line tool, the next rotation time must be in ISO or RFC3339 format, and the rotation period must be in the form INTEGER[UNIT], where units can be one of seconds (s), minutes (m), hours (h) or days (d).",
    "rationale_statement": "Set a key rotation period and starting time. A key can be created with a specified rotation period, which is the time between when new key versions are generated automatically. A key can also be created with a specified next rotation time. A key is a named object representing a cryptographic key used for a specific purpose. The key material, the actual bits used for encryption, can change over time as new key versions are created.\nA key is used to protect some corpus of data. A collection of files could be encrypted with the same key and people with decrypt permissions on that key would be able to decrypt those files. Therefore, it's necessary to make sure the rotation period is set to a specific time.",
    "impact_statement": "After a successful key rotation, the older key version is required in order to decrypt the data encrypted by that previous key version.",
    "audit_procedure": "From Google Cloud Console\n\nGo to Cryptographic Keys by visiting: https://console.cloud.google.com/security/kms.\nClick on each key ring, then ensure each key in the keyring has Next Rotation set for less than 90 days from the current date.\n\nFrom Google Cloud CLI\n\nEnsure rotation is scheduled by ROTATION_PERIOD and NEXT_ROTATION_TIME for each key :\n\ngcloud kms keys list --keyring=<KEY_RING> --location=<LOCATION> --format=json'(rotationPeriod)'\n\nEnsure outcome values for rotationPeriod and nextRotationTime satisfy the below criteria:\nrotationPeriod   is <= 129600m\nrotationPeriod   is <= 7776000s\nrotationPeriod   is <= 2160h\nrotationPeriod   is <= 90d\nnextRotationTime is <= 90days from current DATE",
    "remediation_procedure": "From Google Cloud Console\n\nGo to Cryptographic Keys by visiting: https://console.cloud.google.com/security/kms.\nClick on the specific key ring\nFrom the list of keys, choose the specific key and Click on Right side pop up the blade (3 dots).\nClick on Edit rotation period.\nOn the pop-up window, Select a new rotation period in days which should be less than 90 and then choose Starting on date (date from which the rotation period begins).\n\nFrom Google Cloud CLI\n\nUpdate and schedule rotation by ROTATION_PERIOD and NEXT_ROTATION_TIME for each key:\n\ngcloud kms keys update new --keyring=KEY_RING --location=LOCATION --next-rotation-time=NEXT_ROTATION_TIME --rotation-period=ROTATION_PERIOD",
    "default_value": "By default, KMS encryption keys are rotated every 90 days."
  },
  {
    "control_id": "3.11",
    "control": "Encrypt Sensitive Data at Rest",
    "IG1": "-",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260470,
    "recommendation_id": 2036727,
    "view_level": "1.17",
    "title": "Ensure that Dataproc Cluster is encrypted using Customer-Managed Encryption Key",
    "pivot_control_id": 386,
    "pivot_recommendation_id": 2036727,
    "url": "https://workbench.cisecurity.org/sections/1260470/recommendations/2036727",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 2"
      }
    ],
    "description": "When you use Dataproc, cluster and job data is stored on Persistent Disks (PDs) associated with the Compute Engine VMs in your cluster and in a Cloud Storage staging bucket. This PD and bucket data is encrypted using a Google-generated data encryption key (DEK) and key encryption key (KEK). The CMEK feature allows you to create, use, and revoke the key encryption key (KEK). Google still controls the data encryption key (DEK).",
    "rationale_statement": "\"Cloud services offer the ability to protect data related to those services using encryption keys managed by the customer within Cloud KMS. These encryption keys are called customer-managed encryption keys (CMEK). When you protect data in Google Cloud services with CMEK, the CMEK key is within your control.",
    "impact_statement": "Using Customer Managed Keys involves additional overhead in maintenance by administrators.",
    "audit_procedure": "From Google Cloud Console\n\nLogin to the GCP Console and navigate to the Dataproc Cluster page by visiting https://console.cloud.google.com/dataproc/clusters.\nSelect the project from the project dropdown list.\nOn the Dataproc Clusters page, select the cluster and click on the Name attribute value that you want to examine.\nOn the details page, select the Configurations tab.\nOn the Configurations tab, check the Encryption type configuration attribute value. If the value is set to Google-managed key, then Dataproc Cluster is not encrypted with Customer managed encryption keys.\n\nRepeat step no. 3 - 5 for other Dataproc Clusters available in the selected project.\n\nChange the project from the project dropdown list and repeat the audit procedure for other projects.\n\nFrom Google Cloud CLI\n\nRun clusters list command to list all the Dataproc Clusters available in the region:\n\ngcloud dataproc clusters list --region='us-central1'\n\n\nRun clusters describe command to get the key details of the selected cluster:\n\ngcloud dataproc clusters describe <cluster_name> --region=us-central1 --flatten=config.encryptionConfig.gcePdKmsKeyName\n\n\nIf the above command output return \"null\", then the selected cluster is not encrypted with Customer managed encryption keys.\nRepeat step no. 2 and 3 for other Dataproc Clusters available in the selected region. Change the region by updating --region and repeat step no. 2 for other clusters available in the project. Change the project by running the below command and repeat the audit procedure for other Dataproc clusters available in other projects:\n\ngcloud config set project <project_ID>\"",
    "remediation_procedure": "From Google Cloud Console\n\nLogin to the GCP Console and navigate to the Dataproc Cluster page by visiting https://console.cloud.google.com/dataproc/clusters.\nSelect the project from the projects dropdown list.\nOn the Dataproc Cluster page, click on the Create Cluster to create a new cluster with Customer managed encryption keys.\nOn Create a cluster page, perform below steps:\n\n\nInside Set up cluster section perform below steps:\n-In the Name textbox, provide a name for your cluster.\n\nFrom Location select the location in which you want to deploy a cluster.\nConfigure other configurations as per your requirements.\n\n\nInside Configure Nodes and Customize cluster section configure the settings as per your requirements.\nInside Manage security section, perform below steps:\n\nFrom Encryption, select Customer-managed key.\nSelect a customer-managed key from dropdown list.\nEnsure that the selected KMS Key have Cloud KMS CryptoKey Encrypter/Decrypter role assign to Dataproc Cluster service account (\"serviceAccount:service-<project_number>@compute-system.iam.gserviceaccount.com\").\nClick on Create to create a cluster.\n\n\nOnce the cluster is created migrate all your workloads from the older cluster to the new cluster and delete the old cluster by performing the below steps:\n\nOn the Clusters page, select the old cluster and click on Delete cluster.\nOn the Confirm deletion window, click on Confirm to delete the cluster.\nRepeat step above for other Dataproc clusters available in the selected project.\n\n\nChange the project from the project dropdown list and repeat the remediation procedure for other Dataproc clusters available in other projects.\n\nFrom Google Cloud CLI\nBefore creating cluster ensure that the selected KMS Key have Cloud KMS CryptoKey Encrypter/Decrypter role assign to Dataproc Cluster service account (\"serviceAccount:service-<project_number>@compute-system.iam.gserviceaccount.com\").\nRun clusters create command to create new cluster with customer-managed key:\ngcloud dataproc clusters create <cluster_name> --region=us-central1 --gce-pd-kms-key=<key_resource_name>\n\nThe above command will create a new cluster in the selected region.\nOnce the cluster is created migrate all your workloads from the older cluster to the new cluster and Run clusters delete command to delete cluster:\ngcloud dataproc clusters delete <cluster_name> --region=us-central1\n\nRepeat step no. 1 to create a new Dataproc cluster.\nChange the project by running the below command and repeat the remediation procedure for other projects:\ngcloud config set project <project_ID>\"",
    "default_value": ""
  },
  {
    "control_id": "3.11",
    "control": "Encrypt Sensitive Data at Rest",
    "IG1": "-",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260470,
    "recommendation_id": 2036729,
    "view_level": "1.18",
    "title": "Ensure Secrets are Not Stored in Cloud Functions Environment Variables by Using Secret Manager",
    "pivot_control_id": 386,
    "pivot_recommendation_id": 2036729,
    "url": "https://workbench.cisecurity.org/sections/1260470/recommendations/2036729",
    "assessment_status": "Manual",
    "applicable_profiles": [
      {
        "title": "Level 1"
      }
    ],
    "description": "Google Cloud Functions allow you to host serverless code that is executed when an event is triggered, without the requiring the management a host operating system. These functions can also store environment variables to be used by the code that may contain authentication or other information that needs to remain confidential.",
    "rationale_statement": "It is recommended to use the Secret Manager, because environment variables are stored unencrypted, and accessible for all users who have access to the code.",
    "impact_statement": "There should be no impact on the Cloud Function. There are minor costs after 10,000 requests a month to the Secret Manager API as well for a high use of other functions. Modifying the Cloud Function to use the Secret Manager may prevent it running to completion.",
    "audit_procedure": "Determine if Confidential Information is Stored in your Functions in Cleartext\nFrom Google Cloud Console\n\nWithin the project you wish to audit, select the Navigation hamburger menu in the top left. Scroll down to under the heading 'Serverless', then select 'Cloud Functions'\nClick on a function name from the list\nOpen the Variables tab and you will see both buildEnvironmentVariables and environmentVariables\nReview the variables whether they are secrets\nRepeat step 3-5 until all functions are reviewed\n\nFrom Google Cloud CLI\n\nTo view a list of your cloud functions run\n\ngcloud functions list\n\n\nFor each cloud function in the list run the following command.\n\ngcloud functions describe <function_name>\n\n\nReview the settings of the buildEnvironmentVariables and environmentVariables. Determine if this is data that should not be publicly accessible.\n\nDetermine if Secret Manager API is 'Enabled' for your Project\nFrom Google Cloud Console\n\nWithin the project you wish to audit, select the Navigation hamburger menu in the top left. Hover over 'APIs & Services' to under the heading 'Serverless', then select 'Enabled APIs & Services' in the menu that opens up.\nClick the button '+ Enable APIS and Services'\nIn the Search bar, search for 'Secret Manager API' and select it.\nIf it is enabled, the blue box that normally says 'Enable' will instead say 'Manage'.\n\nFrom Google Cloud CLI\n\nWithin the project you wish to audit, run the following command.\n\ngcloud services list\n\n\nIf 'Secret Manager API' is in the list, it is enabled.",
    "remediation_procedure": "Enable Secret Manager API for your Project\nFrom Google Cloud Console\n\nWithin the project you wish to enable, select the Navigation hamburger menu in the top left. Hover over 'APIs & Services' to under the heading 'Serverless', then select 'Enabled APIs & Services' in the menu that opens up.\nClick the button '+ Enable APIS and Services'\nIn the Search bar, search for 'Secret Manager API' and select it.\nClick the blue box that says 'Enable'.\n\nFrom Google Cloud CLI\n\nWithin the project you wish to enable the API in, run the following command.\n\ngcloud services enable Secret Manager API \n\nReviewing Environment Variables That Should Be Migrated to Secret Manager\nFrom Google Cloud Console\n\nLog in to the Google Cloud Web Portal (https://console.cloud.google.com/)\nGo to Cloud Functions\nClick on a function name from the list\nClick on Edit and review the Runtime environment for variables that should be secrets. Leave this list open for the next step.\n\nFrom Google Cloud CLI\n\nTo view a list of your cloud functions run\n\ngcloud functions list\n\n\nFor each cloud function run the following command.\n\ngcloud functions describe <function_name>\n\n\nReview the settings of the buildEnvironmentVariables and environmentVariables. Keep this information for the next step.\n\nMigrating Environment Variables to Secrets within the Secret Manager\nFrom Google Cloud Console\n\nGo to the Secret Manager page in the Cloud Console.\nOn the Secret Manager page, click Create Secret.\nOn the Create secret page, under Name, enter the name of the Environment Variable you are replacing. This will then be the Secret Variable you will reference in your code.\nYou will also need to add a version. This is the actual value of the variable that will be referenced from the code. To add a secret version when creating the initial secret, in the Secret value field, enter the value from the Environment Variable you are replacing.\nLeave the Regions section unchanged.\nClick the Create secret button.\nRepeat for all Environment Variables\n\nFrom Google Cloud CLI\n\nRun the following command with the Environment Variable name you are replacing in the <secret-id>. It is most secure to point this command to a file with the Environment Variable value located in it, as if you entered it via command line it would show up in your shell\u2019s command history.\n\ngcloud secrets create <secret-id> --data-file=\"/path/to/file.txt\"\n\nGranting your Runtime's Service Account Access to Secrets\nFrom Google Cloud Console\n\nWithin the project containing your runtime login with account that has the 'roles/secretmanager.secretAccessor' permission.\nSelect the Navigation hamburger menu in the top left. Hover over 'Security' to under the  then select 'Secret Manager' in the menu that opens up.\nClick the name of a secret listed in this screen.\nIf it is not already open, click Show Info Panel in this screen to open the panel.\n5.In the info panel, click Add principal.\n6.In the New principals field, enter the service account your function uses for its identity. (If you need help locating or updating your runtime's service account, please see the 'docs/securing/function-identity#runtime_service_account' reference.)\nIn the Select a role dropdown, choose Secret Manager and then Secret Manager Secret Accessor.\n\nFrom Google Cloud CLI\nAs of the time of writing, using Google CLI to list Runtime variables is only in beta. Because this is likely to change we are not including it here.\nModifying the Code to use the Secrets in Secret Manager\nFrom Google Cloud Console\nThis depends heavily on which language your runtime is in. For the sake of the brevity of this recommendation, please see the '/docs/creating-and-accessing-secrets#access' reference for language specific instructions.\nFrom Google Cloud CLI\nThis depends heavily on which language your runtime is in. For the sake of the brevity of this recommendation, please see the' /docs/creating-and-accessing-secrets#access' reference for language specific instructions.\nDeleting the Insecure Environment Variables\nBe certain to do this step last. Removing variables from code actively referencing them will prevent it from completing successfully.\nFrom Google Cloud Console\n\nSelect the Navigation hamburger menu in the top left. Hover over 'Security'  then select 'Secret Manager' in the menu that opens up.\nClick the name of a function. Click Edit.\nClick Runtime, build and connections settings to expand the advanced configuration options.\nClick 'Security\u2019. Hover over the secret you want to remove, then click 'Delete'.\nClick Next. Click Deploy. The latest version of the runtime will now reference the secrets in Secret Manager.\n\nFrom Google Cloud CLI\ngcloud functions deploy <Function name>--remove-env-vars <env vars>\n\nIf you need to find the env vars to remove, they are from the step where \u2018gcloud functions describe <function_name>\u2019 was run.",
    "default_value": "By default Secret Manager is not enabled."
  },
  {
    "control_id": "3.11",
    "control": "Encrypt Sensitive Data at Rest",
    "IG1": "-",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260473,
    "recommendation_id": 2036772,
    "view_level": "4.7",
    "title": "Ensure VM Disks for Critical VMs Are Encrypted With Customer-Supplied Encryption Keys (CSEK)",
    "pivot_control_id": 386,
    "pivot_recommendation_id": 2036772,
    "url": "https://workbench.cisecurity.org/sections/1260473/recommendations/2036772",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 2"
      }
    ],
    "description": "Customer-Supplied Encryption Keys (CSEK) are a feature in Google Cloud Storage and Google Compute Engine. If you supply your own encryption keys, Google uses your key to protect the Google-generated keys used to encrypt and decrypt your data. By default, Google Compute Engine encrypts all data at rest. Compute Engine handles and manages this encryption for you without any additional actions on your part. However, if you wanted to control and manage this encryption yourself, you can provide your own encryption keys.",
    "rationale_statement": "By default, Google Compute Engine encrypts all data at rest. Compute Engine handles and manages this encryption for you without any additional actions on your part. However, if you wanted to control and manage this encryption yourself, you can provide your own encryption keys.\nIf you provide your own encryption keys, Compute Engine uses your key to protect the Google-generated keys used to encrypt and decrypt your data. Only users who can provide the correct key can use resources protected by a customer-supplied encryption key.\nGoogle does not store your keys on its servers and cannot access your protected data unless you provide the key. This also means that if you forget or lose your key, there is no way for Google to recover the key or to recover any data encrypted with the lost key.\nAt least business critical VMs should have VM disks encrypted with CSEK.",
    "impact_statement": "If you lose your encryption key, you will not be able to recover the data.",
    "audit_procedure": "From Google Cloud Console\n\nGo to Compute Engine Disks by visiting: https://console.cloud.google.com/compute/disks.\nClick on the disk for your critical VMs to see its configuration details.\nEnsure that Encryption type is set to Customer supplied.\n\nFrom Google Cloud CLI\nEnsure diskEncryptionKey property in the below command's response is not null, and contains key sha256 with corresponding value\ngcloud compute disks describe <DISK_NAME> --zone <ZONE> --format=\"json(diskEncryptionKey,name)\"",
    "remediation_procedure": "Currently there is no way to update the encryption of an existing disk. Therefore you should create a new disk with Encryption set to Customer supplied.\nFrom Google Cloud Console\n\nGo to Compute Engine Disks by visiting: https://console.cloud.google.com/compute/disks.\nClick CREATE DISK.\nSet Encryption type to Customer supplied,\nProvide the Key in the box.\nSelect Wrapped key.\nClick Create.\n\nFrom Google Cloud CLI\nIn the gcloud compute tool, encrypt a disk using the --csek-key-file flag during instance creation. If you are using an RSA-wrapped key, use the gcloud beta component:\ngcloud compute instances create <INSTANCE_NAME> --csek-key-file <example-file.json>\n\nTo encrypt a standalone persistent disk:\ngcloud compute disks create <DISK_NAME> --csek-key-file <example-file.json>",
    "default_value": "By default, VM disks are encrypted with Google-managed keys. They are not encrypted with Customer-Supplied Encryption Keys."
  },
  {
    "control_id": "3.11",
    "control": "Encrypt Sensitive Data at Rest",
    "IG1": "-",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260473,
    "recommendation_id": 2036780,
    "view_level": "4.11",
    "title": "Ensure That Compute Instances Have Confidential Computing Enabled",
    "pivot_control_id": 386,
    "pivot_recommendation_id": 2036780,
    "url": "https://workbench.cisecurity.org/sections/1260473/recommendations/2036780",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 2"
      }
    ],
    "description": "Google Cloud encrypts data at-rest and in-transit, but customer data must be decrypted for processing. Confidential Computing is a breakthrough technology which encrypts data in-use\u2014while it is being processed. Confidential Computing environments keep data encrypted in memory and elsewhere outside the central processing unit (CPU).\nConfidential VMs leverage the Secure Encrypted Virtualization (SEV) feature of AMD EPYC\u2122 CPUs. Customer data will stay encrypted while it is used, indexed, queried, or trained on. Encryption keys are generated in hardware, per VM, and not exportable. Thanks to built-in hardware optimizations of both performance and security, there is no significant performance penalty to Confidential Computing workloads.",
    "rationale_statement": "Confidential Computing enables customers' sensitive code and other data encrypted in memory during processing. Google does not have access to the encryption keys. Confidential VM can help alleviate concerns about risk related to either dependency on Google infrastructure or Google insiders' access to customer data in the clear.",
    "impact_statement": "Confidential Computing for Compute instances does not support live migration. Unlike regular Compute instances, Confidential VMs experience disruptions during maintenance events like a software or hardware update.\nAdditional charges may be incurred when enabling this security feature. See https://cloud.google.com/compute/confidential-vm/pricing for more info.",
    "audit_procedure": "Note: Confidential Computing is currently only supported on N2D machines. To learn more about types of N2D machines, visit https://cloud.google.com/compute/docs/machine-types#n2d_machine_types\nFrom Google Cloud Console\n\n\nGo to the VM instances page by visiting: https://console.cloud.google.com/compute/instances.\n\n\nClick on the instance name to see its VM instance details page.\n\n\nEnsure that Confidential VM service is Enabled.\n\n\nFrom Google Cloud CLI\n\nList the instances in your project and get details on each instance:\n\ngcloud compute instances list --format=json\n\n\nEnsure that enableConfidentialCompute is set to true for all instances with machine type starting with \"n2d-\".\n\nconfidentialInstanceConfig:\n  enableConfidentialCompute: true",
    "remediation_procedure": "Confidential Computing can only be enabled when an instance is created. You must delete the current instance and create a new one.\nFrom Google Cloud Console\n\n\nGo to the VM instances page by visiting: https://console.cloud.google.com/compute/instances.\n\n\nClick CREATE INSTANCE.\n\n\nFill out the desired configuration for your instance.\n\n\nUnder the Confidential VM service section, check the option Enable the Confidential Computing service on this VM instance.\n\n\nClick Create.\n\n\nFrom Google Cloud CLI\nCreate a new instance with Confidential Compute enabled.\ngcloud compute instances create <INSTANCE_NAME>   --zone <ZONE>   --confidential-compute  --maintenance-policy=TERMINATE",
    "default_value": "By default, Confidential Computing is disabled for Compute instances."
  },
  {
    "control_id": "3.11",
    "control": "Encrypt Sensitive Data at Rest",
    "IG1": "-",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260476,
    "recommendation_id": 2036756,
    "view_level": "7.2",
    "title": "Ensure That All BigQuery Tables Are Encrypted With Customer-Managed Encryption Key (CMEK)",
    "pivot_control_id": 386,
    "pivot_recommendation_id": 2036756,
    "url": "https://workbench.cisecurity.org/sections/1260476/recommendations/2036756",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 2"
      }
    ],
    "description": "BigQuery by default encrypts the data as rest by employing Envelope Encryption using Google managed cryptographic keys. The data is encrypted using the data encryption keys and data encryption keys themselves are further encrypted using key encryption keys. This is seamless and do not require any additional input from the user. However, if you want to have greater control, Customer-managed encryption keys (CMEK) can be used as encryption key management solution for BigQuery Data Sets. If CMEK is used, the CMEK is used to encrypt the data encryption keys instead of using google-managed encryption keys.",
    "rationale_statement": "BigQuery by default encrypts the data as rest by employing Envelope Encryption using Google managed cryptographic keys. This is seamless and does not require any additional input from the user.\nFor greater control over the encryption, customer-managed encryption keys (CMEK) can be used as encryption key management solution for BigQuery tables. The CMEK is used to encrypt the data encryption keys instead of using google-managed encryption keys. BigQuery stores the table and CMEK association and the encryption/decryption is done automatically.\nApplying the Default Customer-managed keys on BigQuery data sets ensures that all the new tables created in the future will be encrypted using CMEK but existing tables need to be updated to use CMEK individually.\nNote: Google does not store your keys on its servers and cannot access your protected data unless you provide the key. This also means that if you forget or lose your key, there is no way for Google to recover the key or to recover any data encrypted with the lost key.",
    "impact_statement": "Using Customer-managed encryption keys (CMEK) will incur additional labor-hour investment to create, protect, and manage the keys.",
    "audit_procedure": "From Google Cloud Console\n\nGo to Analytics\nGo to BigQuery\nUnder SQL Workspace, select the project\nSelect Data Set, select the table\nGo to Details tab\nUnder Table info, verify Customer-managed key is present.\nRepeat for each table in all data sets for all projects.\n\nFrom Google Cloud CLI\nList all dataset names\nbq ls\n\nUse the following command to view the table details. Verify the kmsKeyName is present.\nbq show <table_object>",
    "remediation_procedure": "From Google Cloud CLI\nUse the following command to copy the data. The source and the destination needs to be same in case copying to the original table.\nbq cp --destination_kms_key <customer_managed_key> source_dataset.source_table destination_dataset.destination_table",
    "default_value": "Google Managed keys are used as key encryption keys."
  },
  {
    "control_id": "3.11",
    "control": "Encrypt Sensitive Data at Rest",
    "IG1": "-",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260476,
    "recommendation_id": 2036760,
    "view_level": "7.3",
    "title": "Ensure That a Default Customer-Managed Encryption Key (CMEK) Is Specified for All BigQuery Data Sets",
    "pivot_control_id": 386,
    "pivot_recommendation_id": 2036760,
    "url": "https://workbench.cisecurity.org/sections/1260476/recommendations/2036760",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 2"
      }
    ],
    "description": "BigQuery by default encrypts the data as rest by employing Envelope Encryption using Google managed cryptographic keys. The data is encrypted using the data encryption keys and data encryption keys themselves are further encrypted using key encryption keys. This is seamless and do not require any additional input from the user. However, if you want to have greater control, Customer-managed encryption keys (CMEK) can be used as encryption key management solution for BigQuery Data Sets.",
    "rationale_statement": "BigQuery by default encrypts the data as rest by employing Envelope Encryption using Google managed cryptographic keys. This is seamless and does not require any additional input from the user.\nFor greater control over the encryption, customer-managed encryption keys (CMEK) can be used as encryption key management solution for BigQuery Data Sets. Setting a Default Customer-managed encryption key (CMEK) for a data set ensure any tables created in future will use the specified CMEK if none other is provided.\nNote: Google does not store your keys on its servers and cannot access your protected data unless you provide the key. This also means that if you forget or lose your key, there is no way for Google to recover the key or to recover any data encrypted with the lost key.",
    "impact_statement": "Using Customer-managed encryption keys (CMEK) will incur additional labor-hour investment to create, protect, and manage the keys.",
    "audit_procedure": "From Google Cloud Console\n\nGo to Analytics\nGo to BigQuery\nUnder Analysis click on SQL Workspaces, select the project\nSelect Data Set\nEnsure Customer-managed key is present under Dataset info section.\nRepeat for each data set in all projects.\n\nFrom Google Cloud CLI\nList all dataset names\nbq ls\n\nUse the following command to view each dataset details.\nbq show <data_set_object>\n\nVerify the kmsKeyName is present.",
    "remediation_procedure": "From Google Cloud CLI\nThe default CMEK for existing data sets can be updated by specifying the default key in the EncryptionConfiguration.kmsKeyName field when calling the datasets.insert or datasets.patch methods",
    "default_value": "Google Managed keys are used as key encryption keys."
  },
  {
    "control_id": "4.1",
    "control": "Establish and Maintain a Secure Configuration Process",
    "IG1": "o",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260479,
    "recommendation_id": 2036783,
    "view_level": "6.3.3",
    "title": "Ensure 'user Connections' Database Flag for Cloud Sql Sql Server Instance Is Set to a Non-limiting Value",
    "pivot_control_id": 391,
    "pivot_recommendation_id": 2036783,
    "url": "https://workbench.cisecurity.org/sections/1260479/recommendations/2036783",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 1"
      }
    ],
    "description": "It is recommended to check the user connections for a Cloud SQL SQL Server instance to ensure that it is not artificially limiting connections.",
    "rationale_statement": "The user connections option specifies the maximum number of simultaneous user connections that are allowed on an instance of SQL Server. The actual number of user connections allowed also depends on the version of SQL Server that you are using, and also the limits of your application or applications and hardware. SQL Server allows a maximum of 32,767 user connections. Because user connections is by default a self-configuring value, with SQL Server adjusting the maximum number of user connections automatically as needed, up to the maximum value allowable. For example, if only 10 users are logged in, 10 user connection objects are allocated. In most cases, you do not have to change the value for this option. The default is 0, which means that the maximum (32,767) user connections are allowed. However if there is a number defined here that limits connections, SQL Server will not allow anymore above this limit. If the connections are at the limit, any new requests will be dropped, potentially causing lost data or outages for those using the database.",
    "impact_statement": "Setting custom flags via command line on certain instances will cause all omitted flags to be reset to defaults. This may cause you to lose custom flags and could result in unforeseen complications or instance restarts. Because of this, it is recommended you apply these flags changes during a period of low usage.",
    "audit_procedure": "From Google Cloud Console\n\nGo to the Cloud SQL Instances page in the Google Cloud Console by visiting https://console.cloud.google.com/sql/instances.\nSelect the instance to open its Instance Overview page\nEnsure the database flag user connections listed under the Database flags section is 0.\n\nFrom Google Cloud CLI\n\nEnsure the below command returns a value of 0, for every Cloud SQL SQL Server database instance.\n\ngcloud sql instances list --format=json | jq '.settings.databaseFlags[] | select(.name==\"user connections\")|.value'",
    "remediation_procedure": "From Google Cloud Console\n\nGo to the Cloud SQL Instances page in the Google Cloud Console by visiting https://console.cloud.google.com/sql/instances.\nSelect the SQL Server instance for which you want to enable to database flag.\nClick Edit.\nScroll down to the Flags section.\nTo set a flag that has not been set on the instance before, click Add item, choose the flag user connections from the drop-down menu, and set its value to your organization recommended value.\nClick Save to save your changes.\nConfirm your changes under Flags on the Overview page.\n\nFrom Google Cloud CLI\n\nConfigure the user connections database flag for every Cloud SQL SQL Server database instance using the below command.\n\ngcloud sql instances patch <INSTANCE_NAME> --database-flags \"user connections=[0-32,767]\"\n\nNote : \n\nThis command will overwrite all database flags previously set. To keep those and add new ones, include the values for all flags you want set on the instance; any flag not specifically included is set to its default value. For flags that do not take a value, specify the flag name followed by an equals sign (\"=\").",
    "default_value": "By default user connections is set to '0' which does not limit the number of connections, giving the server free reign to facilitate a max of 32,767 connections."
  },
  {
    "control_id": "4.1",
    "control": "Establish and Maintain a Secure Configuration Process",
    "IG1": "o",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260479,
    "recommendation_id": 2036784,
    "view_level": "6.3.4",
    "title": "Ensure 'user options' database flag for Cloud SQL SQL Server instance is not configured",
    "pivot_control_id": 391,
    "pivot_recommendation_id": 2036784,
    "url": "https://workbench.cisecurity.org/sections/1260479/recommendations/2036784",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 1"
      }
    ],
    "description": "It is recommended that, user options database flag for Cloud SQL SQL Server instance should not be configured.",
    "rationale_statement": "The user options option specifies global defaults for all users. A list of default query processing options is established for the duration of a user's work session. The user options option allows you to change the default values of the SET options (if the server's default settings are not appropriate).\nA user can override these defaults by using the SET statement. You can configure user options dynamically for new logins. After you change the setting of user options, new login sessions use the new setting; current login sessions are not affected. This recommendation is applicable to SQL Server database instances.",
    "impact_statement": "Setting custom flags via command line on certain instances will cause all omitted flags to be reset to defaults. This may cause you to lose custom flags and could result in unforeseen complications or instance restarts. Because of this, it is recommended you apply these flags changes during a period of low usage.",
    "audit_procedure": "From Google Cloud Console\n\nGo to the Cloud SQL Instances page in the Google Cloud Console by visiting https://console.cloud.google.com/sql/instances.\nSelect the instance to open its Instance Overview page\nEnsure the database flag user options that has been set is not listed under the Database flags section.\n\nFrom Google Cloud CLI\n\nEnsure the below command returns empty result for every Cloud SQL SQL Server database instance\n\ngcloud sql instances list --format=json | jq '.settings.databaseFlags[] | select(.name==\"user options\")|.value'",
    "remediation_procedure": "From Google Cloud Console\n\nGo to the Cloud SQL Instances page in the Google Cloud Console by visiting https://console.cloud.google.com/sql/instances.\nSelect the SQL Server instance for which you want to enable to database flag.\nClick Edit.\nScroll down to the Flags section.\nClick the X next user options flag shown\nClick Save to save your changes.\nConfirm your changes under Flags on the Overview page.\n\nFrom Google Cloud CLI\n\nList all Cloud SQL database Instances\n\ngcloud sql instances list\n\n\nClear the user options database flag for every Cloud SQL SQL Server database instance using either of the below commands.\n\n1.Clearing all flags to their default value\n\ngcloud sql instances patch <INSTANCE_NAME> --clear-database-flags\n\nOR\n2. To clear only `user options` database flag, configure the database flag by overriding the `user options`. Exclude `user options` flag and its value, and keep all other flags you want to configure.\n\ngcloud sql instances patch <INSTANCE_NAME> --database-flags [FLAG1=VALUE1,FLAG2=VALUE2]\n\nNote : \n\nThis command will overwrite all database flags previously set. To keep those and add new ones, include the values for all flags you want set on the instance; any flag not specifically included is set to its default value. For flags that do not take a value, specify the flag name followed by an equals sign (\"=\").",
    "default_value": "By default 'user options' is not configured."
  },
  {
    "control_id": "4.1",
    "control": "Establish and Maintain a Secure Configuration Process",
    "IG1": "o",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260479,
    "recommendation_id": 2036786,
    "view_level": "6.3.6",
    "title": "Ensure '3625 (trace flag)' database flag for all Cloud SQL Server instances is set to 'on'",
    "pivot_control_id": 391,
    "pivot_recommendation_id": 2036786,
    "url": "https://workbench.cisecurity.org/sections/1260479/recommendations/2036786",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 1"
      }
    ],
    "description": "It is recommended to set 3625 (trace flag) database flag for Cloud SQL SQL Server instance to on.",
    "rationale_statement": "Microsoft SQL Trace Flags are frequently used to diagnose performance issues or to debug stored procedures or complex computer systems, but they may also be recommended by Microsoft Support to address behavior that is negatively impacting a specific workload. All documented trace flags and those recommended by Microsoft Support are fully supported in a production environment when used as directed. 3625(trace log) Limits the amount of information returned to users who are not members of the sysadmin fixed server role, by masking the parameters of some error messages using '******'. Setting this in a Google Cloud flag for the instance allows for security through obscurity and prevents the disclosure of sensitive information, hence this is recommended to set this flag globally to on to prevent the flag having been left off, or changed by bad actors. This recommendation is applicable to SQL Server database instances.",
    "impact_statement": "Changing flags on a database may cause it to be restarted. The best time to do this is at a time where there is low usage.",
    "audit_procedure": "From Google Cloud Console\n\nGo to the Cloud SQL Instances page in the Google Cloud Console by visiting https://console.cloud.google.com/sql/instances.\nSelect the instance to open its Instance Overview page\nEnsure the database flag 3625 that has been set is listed under the Database flags section.\n\nFrom Google Cloud CLI\n\nEnsure the below command returns on for every Cloud SQL SQL Server database instance\n\ngcloud sql instances list --format=json | jq '.settings.databaseFlags[] | select(.name==\"3625\")|.value'",
    "remediation_procedure": "From Google Cloud Console\n\nGo to the Cloud SQL Instances page in the Google Cloud Console by visiting https://console.cloud.google.com/sql/instances.\nSelect the SQL Server instance for which you want to enable to database flag.\nClick Edit.\nScroll down to the Flags section.\nTo set a flag that has not been set on the instance before, click Add item, choose the flag 3625 from the drop-down menu, and set its value to on.\nClick Save to save your changes.\nConfirm your changes under Flags on the Overview page.\n\nFrom Google Cloud CLI\n\nConfigure the 3625 database flag for every Cloud SQL SQL Server database instance using the below command.\n\ngcloud sql instances patch <INSTANCE_NAME> --database-flags \"3625=on\"\n\nNote :\nThis command will overwrite all database flags previously set. To keep those and add new ones, include the values for all flags you want set on the instance; any flag not specifically included is set to its default value. For flags that do not take a value, specify the flag name followed by an equals sign (\"=\").",
    "default_value": "MySQL implementations by default have trace flags turned off, as they are used for logging purposes."
  },
  {
    "control_id": "4.2",
    "control": "Establish and Maintain a Secure Configuration Process for Network Infrastructure",
    "IG1": "o",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260472,
    "recommendation_id": 2036732,
    "view_level": "3.1",
    "title": "Ensure That the Default Network Does Not Exist in a Project",
    "pivot_control_id": 392,
    "pivot_recommendation_id": 2036732,
    "url": "https://workbench.cisecurity.org/sections/1260472/recommendations/2036732",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 2"
      }
    ],
    "description": "To prevent use of default network, a project should not have a default network.",
    "rationale_statement": "The default network has a preconfigured network configuration and automatically generates the following insecure firewall rules:\n\ndefault-allow-internal: Allows ingress connections for all protocols and ports among instances in the network.\ndefault-allow-ssh: Allows ingress connections on TCP port 22(SSH) from any source to any instance in the network.\ndefault-allow-rdp: Allows ingress connections on TCP port 3389(RDP) from any source to any instance in the network.\ndefault-allow-icmp: Allows ingress ICMP traffic from any source to any instance in the network.\n\nThese automatically created firewall rules do not get audit logged and cannot be configured to enable firewall rule logging.\nFurthermore, the default network is an auto mode network, which means that its subnets use the same predefined range of IP addresses, and as a result, it's not possible to use Cloud VPN or VPC Network Peering with the default network.\nBased on organization security and networking requirements, the organization should create a new network and delete the default network.",
    "impact_statement": "When an organization deletes the default network, it may need to migrate or service onto a new network.",
    "audit_procedure": "From Google Cloud Console\n\n\nGo to the VPC networks page by visiting: https://console.cloud.google.com/networking/networks/list.\n\n\nEnsure that a network with the name default is not present.\n\n\nFrom Google Cloud CLI\n\nSet the project name in the Google Cloud Shell:\n\n\ngcloud config set project PROJECT_ID \n\n\nList the networks configured in that project:\n\ngcloud compute networks list \n\nIt should not list default as one of the available networks in that project.",
    "remediation_procedure": "From Google Cloud Console\n\n\nGo to the VPC networks page by visiting: https://console.cloud.google.com/networking/networks/list.\n\n\nClick the network named default.\n\n\nOn the network detail page, click EDIT.\n\n\nClick DELETE VPC NETWORK.\n\n\nIf needed, create a new network to replace the default network.\n\n\nFrom Google Cloud CLI\nFor each Google Cloud Platform project,\n\nDelete the default network:\n\ngcloud compute networks delete default\n\n\nIf needed, create a new network to replace it:\n\ngcloud compute networks create NETWORK_NAME\n\nPrevention:\nThe user can prevent the default network and its insecure default firewall rules from being created by setting up an Organization Policy to Skip default network creation at https://console.cloud.google.com/iam-admin/orgpolicies/compute-skipDefaultNetworkCreation.",
    "default_value": "By default, for each project, a default network is created."
  },
  {
    "control_id": "4.2",
    "control": "Establish and Maintain a Secure Configuration Process for Network Infrastructure",
    "IG1": "o",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260472,
    "recommendation_id": 2036734,
    "view_level": "3.2",
    "title": "Ensure Legacy Networks Do Not Exist for Older Projects",
    "pivot_control_id": 392,
    "pivot_recommendation_id": 2036734,
    "url": "https://workbench.cisecurity.org/sections/1260472/recommendations/2036734",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 1"
      }
    ],
    "description": "In order to prevent use of legacy networks, a project should not have a legacy network configured. As of now, Legacy Networks are gradually being phased out, and you can no longer create projects with them. This recommendation is to check older projects to ensure that they are not using Legacy Networks.",
    "rationale_statement": "Legacy networks have a single network IPv4 prefix range and a single gateway IP address for the whole network. The network is global in scope and spans all cloud regions. Subnetworks cannot be created in a legacy network and are unable to switch from legacy to auto or custom subnet networks. Legacy networks can have an impact for high network traffic projects and are subject to a single point of contention or failure.",
    "impact_statement": "None.",
    "audit_procedure": "From Google Cloud CLI\nFor each Google Cloud Platform project,\n\nSet the project name in the Google Cloud Shell:\n\n\ngcloud config set project <Project-ID> \n\n\nList the networks configured in that project:\n\n\ngcloud compute networks list \n\nNone of the listed networks should be in the legacy mode.",
    "remediation_procedure": "From Google Cloud CLI\nFor each Google Cloud Platform project,\n\n\nFollow the documentation and create a non-legacy network suitable for the organization's requirements.\n\n\nFollow the documentation and delete the networks in the legacy mode.",
    "default_value": "By default, networks are not created in the legacy mode."
  },
  {
    "control_id": "4.2",
    "control": "Establish and Maintain a Secure Configuration Process for Network Infrastructure",
    "IG1": "o",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260472,
    "recommendation_id": 2036736,
    "view_level": "3.3",
    "title": "Ensure That DNSSEC Is Enabled for Cloud DNS",
    "pivot_control_id": 392,
    "pivot_recommendation_id": 2036736,
    "url": "https://workbench.cisecurity.org/sections/1260472/recommendations/2036736",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 1"
      }
    ],
    "description": "Cloud Domain Name System (DNS) is a fast, reliable and cost-effective domain name system that powers millions of domains on the internet. Domain Name System Security Extensions (DNSSEC) in Cloud DNS enables domain owners to take easy steps to protect their domains against DNS hijacking and man-in-the-middle and other attacks.",
    "rationale_statement": "Domain Name System Security Extensions (DNSSEC) adds security to the DNS protocol by enabling DNS responses to be validated. Having a trustworthy DNS that translates a domain name like www.example.com into its associated IP address is an increasingly important building block of today\u2019s web-based applications. Attackers can hijack this process of domain/IP lookup and redirect users to a malicious site through DNS hijacking and man-in-the-middle attacks. DNSSEC helps mitigate the risk of such attacks by cryptographically signing DNS records. As a result, it prevents attackers from issuing fake DNS responses that may misdirect browsers to nefarious websites.",
    "impact_statement": "",
    "audit_procedure": "From Google Cloud Console\n\nGo to Cloud DNS by visiting https://console.cloud.google.com/net-services/dns/zones.\nFor each zone of Type Public, ensure that DNSSEC is set to On.\n\nFrom Google Cloud CLI\n\nList all the Managed Zones in a project:\n\ngcloud dns managed-zones list\n\n\nFor each zone of VISIBILITY public, get its metadata:\n\ngcloud dns managed-zones describe ZONE_NAME\n\n\nEnsure that dnssecConfig.state property is on.",
    "remediation_procedure": "From Google Cloud Console\n\nGo to Cloud DNS by visiting https://console.cloud.google.com/net-services/dns/zones.\nFor each zone of Type Public, set DNSSEC to On.\n\nFrom Google Cloud CLI\nUse the below command to enable DNSSEC for Cloud DNS Zone Name.\ngcloud dns managed-zones update ZONE_NAME --dnssec-state on",
    "default_value": "By default DNSSEC is not enabled."
  },
  {
    "control_id": "4.2",
    "control": "Establish and Maintain a Secure Configuration Process for Network Infrastructure",
    "IG1": "o",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260472,
    "recommendation_id": 2036738,
    "view_level": "3.4",
    "title": "Ensure That RSASHA1 Is Not Used for the Key-Signing Key in Cloud DNS DNSSEC",
    "pivot_control_id": 392,
    "pivot_recommendation_id": 2036738,
    "url": "https://workbench.cisecurity.org/sections/1260472/recommendations/2036738",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 1"
      }
    ],
    "description": "NOTE: Currently, the SHA1  algorithm has been removed from general use by Google, and, if being used, needs to be whitelisted on a project basis by Google and will also, therefore, require a Google Cloud support contract.\nDNSSEC algorithm numbers in this registry may be used in CERT RRs. Zone signing (DNSSEC) and transaction security mechanisms (SIG(0) and TSIG) make use of particular subsets of these algorithms. The algorithm used for key signing should be a recommended one and it should be strong.",
    "rationale_statement": "Domain Name System Security Extensions (DNSSEC) algorithm numbers in this registry may be used in CERT RRs. Zonesigning (DNSSEC) and transaction security mechanisms (SIG(0) and TSIG) make use of particular subsets of these algorithms.\nThe algorithm used for key signing should be a recommended one and it should be strong. When enabling DNSSEC for a managed zone, or creating a managed zone with DNSSEC, the user can select the DNSSEC signing algorithms and the denial-of-existence type. Changing the DNSSEC settings is only effective for a managed zone if DNSSEC is not already enabled. If there is a need to change the settings for a managed zone where it has been enabled, turn DNSSEC off and then re-enable it with different settings.",
    "impact_statement": "",
    "audit_procedure": "From Google Cloud CLI\nEnsure the property algorithm for keyType keySigning is not using RSASHA1.\ngcloud dns managed-zones describe ZONENAME --format=\"json(dnsName,dnssecConfig.state,dnssecConfig.defaultKeySpecs)\"",
    "remediation_procedure": "From Google Cloud CLI\n\nIf it is necessary to change the settings for a managed zone where it has been enabled, NSSEC must be turned off and re-enabled with different settings. To turn off DNSSEC, run the following command:\n\ngcloud dns managed-zones update ZONE_NAME --dnssec-state off\n\n\nTo update key-signing for a reported managed DNS Zone, run the following command:\n\ngcloud dns managed-zones update ZONE_NAME --dnssec-state on --ksk-algorithm KSK_ALGORITHM --ksk-key-length KSK_KEY_LENGTH --zsk-algorithm ZSK_ALGORITHM --zsk-key-length ZSK_KEY_LENGTH --denial-of-existence DENIAL_OF_EXISTENCE\n\nSupported algorithm options and key lengths are as follows.\nAlgorithm                        KSK Length               ZSK Length\n---------                        ----------               ----------\nRSASHA1                          1024,2048                1024,2048\nRSASHA256                        1024,2048                1024,2048\nRSASHA512                        1024,2048                1024,2048\nECDSAP256SHA256                  256                      256\nECDSAP384SHA384                  384                      384",
    "default_value": ""
  },
  {
    "control_id": "4.2",
    "control": "Establish and Maintain a Secure Configuration Process for Network Infrastructure",
    "IG1": "o",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260472,
    "recommendation_id": 2036739,
    "view_level": "3.5",
    "title": "Ensure That RSASHA1 Is Not Used for the Zone-Signing Key in Cloud DNS DNSSEC",
    "pivot_control_id": 392,
    "pivot_recommendation_id": 2036739,
    "url": "https://workbench.cisecurity.org/sections/1260472/recommendations/2036739",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 1"
      }
    ],
    "description": "NOTE: Currently, the SHA1 algorithm has been removed from general use by Google, and, if being used, needs to be whitelisted on a project basis by Google and will also, therefore, require a Google Cloud support contract.\nDNSSEC algorithm numbers in this registry may be used in CERT RRs. Zone signing (DNSSEC) and transaction security mechanisms (SIG(0) and TSIG) make use of particular subsets of these algorithms. The algorithm used for key signing should be a recommended one and it should be strong.",
    "rationale_statement": "DNSSEC algorithm numbers in this registry may be used in CERT RRs. Zone signing (DNSSEC) and transaction security mechanisms (SIG(0) and TSIG) make use of particular subsets of these algorithms.\nThe algorithm used for key signing should be a recommended one and it should be strong. When enabling DNSSEC for a managed zone, or creating a managed zone with DNSSEC, the DNSSEC signing algorithms and the denial-of-existence type can be selected. Changing the DNSSEC settings is only effective for a managed zone if DNSSEC is not already enabled. If the need exists to change the settings for a managed zone where it has been enabled, turn DNSSEC off and then re-enable it with different settings.",
    "impact_statement": "",
    "audit_procedure": "From Google Cloud CLI\nEnsure the property algorithm for keyType zone signing is not using RSASHA1.\ngcloud dns managed-zones describe --format=\"json(dnsName,dnssecConfig.state,dnssecConfig.defaultKeySpecs)\"",
    "remediation_procedure": "From Google Cloud CLI\n\nIf the need exists to change the settings for a managed zone where it has been enabled, DNSSEC must be turned off and then re-enabled with different settings. To turn off DNSSEC, run following command:\n\ngcloud dns managed-zones update ZONE_NAME --dnssec-state off\n\n\nTo update zone-signing for a reported managed DNS Zone, run the following command:\n\ngcloud dns managed-zones update ZONE_NAME --dnssec-state on --ksk-algorithm KSK_ALGORITHM --ksk-key-length KSK_KEY_LENGTH --zsk-algorithm ZSK_ALGORITHM --zsk-key-length ZSK_KEY_LENGTH --denial-of-existence DENIAL_OF_EXISTENCE\n\nSupported algorithm options and key lengths are as follows.\nAlgorithm                 KSK Length            ZSK Length\n---------                 ----------            ----------\nRSASHA1                   1024,2048             1024,2048\nRSASHA256                 1024,2048             1024,2048\nRSASHA512                 1024,2048             1024,2048\nECDSAP256SHA256           256                   384\nECDSAP384SHA384           384                   384",
    "default_value": ""
  },
  {
    "control_id": "4.4",
    "control": "Implement and Manage a Firewall on Servers",
    "IG1": "o",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260472,
    "recommendation_id": 2036741,
    "view_level": "3.6",
    "title": "Ensure That SSH Access Is Restricted From the Internet",
    "pivot_control_id": 394,
    "pivot_recommendation_id": 2036741,
    "url": "https://workbench.cisecurity.org/sections/1260472/recommendations/2036741",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 2"
      }
    ],
    "description": "GCP Firewall Rules are specific to a VPC Network. Each rule either allows or denies traffic when its conditions are met. Its conditions allow the user to specify the type of traffic, such as ports and protocols, and the source or destination of the traffic, including IP addresses, subnets, and instances.\nFirewall rules are defined at the VPC network level and are specific to the network in which they are defined. The rules themselves cannot be shared among networks. Firewall rules only support IPv4 traffic. When specifying a source for an ingress rule or a destination for an egress rule by address, only an IPv4 address or IPv4 block in CIDR notation can be used. Generic (0.0.0.0/0) incoming traffic from the internet to VPC or VM instance using SSH on Port 22 can be avoided.",
    "rationale_statement": "GCP Firewall Rules within a VPC Network apply to outgoing (egress) traffic from instances and incoming (ingress) traffic to instances in the network. Egress and ingress traffic flows are controlled even if the traffic stays within the network (for example, instance-to-instance communication).\nFor an instance to have outgoing Internet access, the network must have a valid Internet gateway route or custom route whose destination IP is specified. This route simply defines the path to the Internet, to avoid the most general (0.0.0.0/0) destination IP Range specified from the Internet through SSH with the default Port 22. Generic access from the Internet to a specific IP Range needs to be restricted.",
    "impact_statement": "All Secure Shell (SSH) connections from outside of the network to the concerned VPC(s) will be blocked. There could be a business need where SSH access is required from outside of the network to access resources associated with the VPC. In that case, specific source IP(s) should be mentioned in firewall rules to white-list access to SSH port for the concerned VPC(s).",
    "audit_procedure": "From Google Cloud Console\n\nGo to VPC network.\nGo to the Firewall Rules.\nEnsure that Port is not equal to 22 and Action is not set to Allow.\nEnsure IP Ranges is not equal to 0.0.0.0/0 under Source filters.\n\nFrom Google Cloud CLI\ngcloud compute firewall-rules list --format=table'(name,direction,sourceRanges,allowed)'\n\nEnsure that there is no rule matching the below criteria:\n\nSOURCE_RANGES is 0.0.0.0/0\nAND DIRECTION is INGRESS\nAND IPProtocol is tcp or ALL\nAND PORTS is set to 22 or range containing 22 or Null (not set)\n\nNote:\n\nWhen ALL TCP ports are allowed in a rule, PORT does not have any value set (NULL)\nWhen ALL Protocols are allowed in a rule, PORT does not have any value set (NULL)",
    "remediation_procedure": "From Google Cloud Console\n\nGo to VPC Network.\nGo to the Firewall Rules.\nClick the Firewall Rule you want to modify.\nClick Edit.\nModify Source IP ranges to specific IP.\nClick Save.\n\nFrom Google Cloud CLI\n1.Update the Firewall rule with the new SOURCE_RANGE from the below command:\ngcloud compute firewall-rules update FirewallName --allow=[PROTOCOL[:PORT[-PORT]],...] --source-ranges=[CIDR_RANGE,...]",
    "default_value": ""
  },
  {
    "control_id": "4.4",
    "control": "Implement and Manage a Firewall on Servers",
    "IG1": "o",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260472,
    "recommendation_id": 2036743,
    "view_level": "3.7",
    "title": "Ensure That RDP Access Is Restricted From the Internet",
    "pivot_control_id": 394,
    "pivot_recommendation_id": 2036743,
    "url": "https://workbench.cisecurity.org/sections/1260472/recommendations/2036743",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 2"
      }
    ],
    "description": "GCP Firewall Rules are specific to a VPC Network. Each rule either allows or denies traffic when its conditions are met. Its conditions allow users to specify the type of traffic, such as ports and protocols, and the source or destination of the traffic, including IP addresses, subnets, and instances.\nFirewall rules are defined at the VPC network level and are specific to the network in which they are defined. The rules themselves cannot be shared among networks. Firewall rules only support IPv4 traffic. When specifying a source for an ingress rule or a destination for an egress rule by address, an IPv4 address or IPv4 block in CIDR notation can be used. Generic (0.0.0.0/0) incoming traffic from the Internet to a VPC or VM instance using RDP on Port 3389 can be avoided.",
    "rationale_statement": "GCP Firewall Rules within a VPC Network. These rules apply to outgoing (egress) traffic from instances and incoming (ingress) traffic to instances in the network. Egress and ingress traffic flows are controlled even if the traffic stays within the network (for example, instance-to-instance communication).\nFor an instance to have outgoing Internet access, the network must have a valid Internet gateway route or custom route whose destination IP is specified. This route simply defines the path to the Internet, to avoid the most general (0.0.0.0/0) destination IP Range specified from the Internet through RDP with the default Port 3389. Generic access from the Internet to a specific IP Range should be restricted.",
    "impact_statement": "All Remote Desktop Protocol (RDP) connections from outside of the network to the concerned VPC(s) will be blocked. There could be a business need where secure shell access is required from outside of the network to access resources associated with the VPC. In that case, specific source IP(s) should be mentioned in firewall rules to white-list access to RDP port for the concerned VPC(s).",
    "audit_procedure": "From Google Cloud Console\n\nGo to VPC network.\nGo to the Firewall Rules.\nEnsure Port is not equal to 3389 and Action is not Allow.\nEnsure IP Ranges is not equal to 0.0.0.0/0 under Source filters.\n\nFrom Google Cloud CLI\ngcloud compute firewall-rules list --format=table'(name,direction,sourceRanges,allowed.ports)'\n\nEnsure that there is no rule matching the below criteria:\n\nSOURCE_RANGES is 0.0.0.0/0\nAND DIRECTION is INGRESS\nAND IPProtocol is TCP or ALL\nAND PORTS is set to 3389 or range containing 3389 or Null (not set)\n\nNote:\n\nWhen ALL TCP ports are allowed in a rule, PORT does not have any value set (NULL)\nWhen ALL Protocols are allowed in a rule, PORT does not have any value set (NULL)",
    "remediation_procedure": "From Google Cloud Console\n\nGo to VPC Network.\nGo to the Firewall Rules.\nClick the Firewall Rule to be modified.\nClick Edit.\nModify Source IP ranges to specific IP.\nClick Save.\n\nFrom Google Cloud CLI\n1.Update RDP Firewall rule with new SOURCE_RANGE from the below command:\ngcloud compute firewall-rules update FirewallName --allow=[PROTOCOL[:PORT[-PORT]],...] --source-ranges=[CIDR_RANGE,...]",
    "default_value": ""
  },
  {
    "control_id": "4.4",
    "control": "Implement and Manage a Firewall on Servers",
    "IG1": "o",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260473,
    "recommendation_id": 2036769,
    "view_level": "4.6",
    "title": "Ensure That IP Forwarding Is Not Enabled on Instances",
    "pivot_control_id": 394,
    "pivot_recommendation_id": 2036769,
    "url": "https://workbench.cisecurity.org/sections/1260473/recommendations/2036769",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 1"
      }
    ],
    "description": "Compute Engine instance cannot forward a packet unless the source IP address of the packet matches the IP address of the instance. Similarly, GCP won't deliver a packet whose destination IP address is different than the IP address of the instance receiving the packet. However, both capabilities are required if you want to use instances to help route packets.\nForwarding of data packets should be disabled to prevent data loss or information disclosure.",
    "rationale_statement": "Compute Engine instance cannot forward a packet unless the source IP address of the packet matches the IP address of the instance. Similarly, GCP won't deliver a packet whose destination IP address is different than the IP address of the instance receiving the packet. However, both capabilities are required if you want to use instances to help route packets.\nTo enable this source and destination IP check, disable the canIpForward field, which allows an instance to send and receive packets with non-matching destination or source IPs.",
    "impact_statement": "Deleting instance(s) acting as routers/packet forwarders may break the network connectivity.",
    "audit_procedure": "From Google Cloud Console\n\nGo to the VM Instances page by visiting: https://console.cloud.google.com/compute/instances.\nFor every instance, click on its name to go to the VM instance details page.\nUnder the Network interfaces section, ensure that IP forwarding is set to Off for every network interface.\n\nFrom Google Cloud CLI\n\nList all instances:\n\ngcloud compute instances list --format='table(name,canIpForward)'\n\n\nEnsure that CAN_IP_FORWARD column in the output of above command does not contain True for any VM instance.\n\nException:\nInstances created by GKE should be excluded because they need to have IP forwarding enabled and cannot be changed. Instances created by GKE have names that start with \"gke-\".",
    "remediation_procedure": "You only edit the canIpForward setting at instance creation time. Therefore, you need to delete the instance and create a new one where canIpForward is set to false.\nFrom Google Cloud Console\n\nGo to the VM Instances page by visiting: https://console.cloud.google.com/compute/instances.\nSelect the VM Instance you want to remediate.\nClick the Delete button.\nOn the 'VM Instances' page, click `CREATE INSTANCE'.\nCreate a new instance with the desired configuration. By default, the instance is configured to not allow IP forwarding.\n\nFrom Google Cloud CLI\n\nDelete the instance:\n\ngcloud compute instances delete INSTANCE_NAME\n\n\nCreate a new instance to replace it, with IP forwarding set to Off\n\ngcloud compute instances create",
    "default_value": "By default, instances are not configured to allow IP forwarding."
  },
  {
    "control_id": "4.5",
    "control": "Implement and Manage a Firewall on End-User Devices",
    "IG1": "o",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260472,
    "recommendation_id": 2036741,
    "view_level": "3.6",
    "title": "Ensure That SSH Access Is Restricted From the Internet",
    "pivot_control_id": 395,
    "pivot_recommendation_id": 2036741,
    "url": "https://workbench.cisecurity.org/sections/1260472/recommendations/2036741",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 2"
      }
    ],
    "description": "GCP Firewall Rules are specific to a VPC Network. Each rule either allows or denies traffic when its conditions are met. Its conditions allow the user to specify the type of traffic, such as ports and protocols, and the source or destination of the traffic, including IP addresses, subnets, and instances.\nFirewall rules are defined at the VPC network level and are specific to the network in which they are defined. The rules themselves cannot be shared among networks. Firewall rules only support IPv4 traffic. When specifying a source for an ingress rule or a destination for an egress rule by address, only an IPv4 address or IPv4 block in CIDR notation can be used. Generic (0.0.0.0/0) incoming traffic from the internet to VPC or VM instance using SSH on Port 22 can be avoided.",
    "rationale_statement": "GCP Firewall Rules within a VPC Network apply to outgoing (egress) traffic from instances and incoming (ingress) traffic to instances in the network. Egress and ingress traffic flows are controlled even if the traffic stays within the network (for example, instance-to-instance communication).\nFor an instance to have outgoing Internet access, the network must have a valid Internet gateway route or custom route whose destination IP is specified. This route simply defines the path to the Internet, to avoid the most general (0.0.0.0/0) destination IP Range specified from the Internet through SSH with the default Port 22. Generic access from the Internet to a specific IP Range needs to be restricted.",
    "impact_statement": "All Secure Shell (SSH) connections from outside of the network to the concerned VPC(s) will be blocked. There could be a business need where SSH access is required from outside of the network to access resources associated with the VPC. In that case, specific source IP(s) should be mentioned in firewall rules to white-list access to SSH port for the concerned VPC(s).",
    "audit_procedure": "From Google Cloud Console\n\nGo to VPC network.\nGo to the Firewall Rules.\nEnsure that Port is not equal to 22 and Action is not set to Allow.\nEnsure IP Ranges is not equal to 0.0.0.0/0 under Source filters.\n\nFrom Google Cloud CLI\ngcloud compute firewall-rules list --format=table'(name,direction,sourceRanges,allowed)'\n\nEnsure that there is no rule matching the below criteria:\n\nSOURCE_RANGES is 0.0.0.0/0\nAND DIRECTION is INGRESS\nAND IPProtocol is tcp or ALL\nAND PORTS is set to 22 or range containing 22 or Null (not set)\n\nNote:\n\nWhen ALL TCP ports are allowed in a rule, PORT does not have any value set (NULL)\nWhen ALL Protocols are allowed in a rule, PORT does not have any value set (NULL)",
    "remediation_procedure": "From Google Cloud Console\n\nGo to VPC Network.\nGo to the Firewall Rules.\nClick the Firewall Rule you want to modify.\nClick Edit.\nModify Source IP ranges to specific IP.\nClick Save.\n\nFrom Google Cloud CLI\n1.Update the Firewall rule with the new SOURCE_RANGE from the below command:\ngcloud compute firewall-rules update FirewallName --allow=[PROTOCOL[:PORT[-PORT]],...] --source-ranges=[CIDR_RANGE,...]",
    "default_value": ""
  },
  {
    "control_id": "4.5",
    "control": "Implement and Manage a Firewall on End-User Devices",
    "IG1": "o",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260472,
    "recommendation_id": 2036743,
    "view_level": "3.7",
    "title": "Ensure That RDP Access Is Restricted From the Internet",
    "pivot_control_id": 395,
    "pivot_recommendation_id": 2036743,
    "url": "https://workbench.cisecurity.org/sections/1260472/recommendations/2036743",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 2"
      }
    ],
    "description": "GCP Firewall Rules are specific to a VPC Network. Each rule either allows or denies traffic when its conditions are met. Its conditions allow users to specify the type of traffic, such as ports and protocols, and the source or destination of the traffic, including IP addresses, subnets, and instances.\nFirewall rules are defined at the VPC network level and are specific to the network in which they are defined. The rules themselves cannot be shared among networks. Firewall rules only support IPv4 traffic. When specifying a source for an ingress rule or a destination for an egress rule by address, an IPv4 address or IPv4 block in CIDR notation can be used. Generic (0.0.0.0/0) incoming traffic from the Internet to a VPC or VM instance using RDP on Port 3389 can be avoided.",
    "rationale_statement": "GCP Firewall Rules within a VPC Network. These rules apply to outgoing (egress) traffic from instances and incoming (ingress) traffic to instances in the network. Egress and ingress traffic flows are controlled even if the traffic stays within the network (for example, instance-to-instance communication).\nFor an instance to have outgoing Internet access, the network must have a valid Internet gateway route or custom route whose destination IP is specified. This route simply defines the path to the Internet, to avoid the most general (0.0.0.0/0) destination IP Range specified from the Internet through RDP with the default Port 3389. Generic access from the Internet to a specific IP Range should be restricted.",
    "impact_statement": "All Remote Desktop Protocol (RDP) connections from outside of the network to the concerned VPC(s) will be blocked. There could be a business need where secure shell access is required from outside of the network to access resources associated with the VPC. In that case, specific source IP(s) should be mentioned in firewall rules to white-list access to RDP port for the concerned VPC(s).",
    "audit_procedure": "From Google Cloud Console\n\nGo to VPC network.\nGo to the Firewall Rules.\nEnsure Port is not equal to 3389 and Action is not Allow.\nEnsure IP Ranges is not equal to 0.0.0.0/0 under Source filters.\n\nFrom Google Cloud CLI\ngcloud compute firewall-rules list --format=table'(name,direction,sourceRanges,allowed.ports)'\n\nEnsure that there is no rule matching the below criteria:\n\nSOURCE_RANGES is 0.0.0.0/0\nAND DIRECTION is INGRESS\nAND IPProtocol is TCP or ALL\nAND PORTS is set to 3389 or range containing 3389 or Null (not set)\n\nNote:\n\nWhen ALL TCP ports are allowed in a rule, PORT does not have any value set (NULL)\nWhen ALL Protocols are allowed in a rule, PORT does not have any value set (NULL)",
    "remediation_procedure": "From Google Cloud Console\n\nGo to VPC Network.\nGo to the Firewall Rules.\nClick the Firewall Rule to be modified.\nClick Edit.\nModify Source IP ranges to specific IP.\nClick Save.\n\nFrom Google Cloud CLI\n1.Update RDP Firewall rule with new SOURCE_RANGE from the below command:\ngcloud compute firewall-rules update FirewallName --allow=[PROTOCOL[:PORT[-PORT]],...] --source-ranges=[CIDR_RANGE,...]",
    "default_value": ""
  },
  {
    "control_id": "4.5",
    "control": "Implement and Manage a Firewall on End-User Devices",
    "IG1": "o",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260473,
    "recommendation_id": 2036769,
    "view_level": "4.6",
    "title": "Ensure That IP Forwarding Is Not Enabled on Instances",
    "pivot_control_id": 395,
    "pivot_recommendation_id": 2036769,
    "url": "https://workbench.cisecurity.org/sections/1260473/recommendations/2036769",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 1"
      }
    ],
    "description": "Compute Engine instance cannot forward a packet unless the source IP address of the packet matches the IP address of the instance. Similarly, GCP won't deliver a packet whose destination IP address is different than the IP address of the instance receiving the packet. However, both capabilities are required if you want to use instances to help route packets.\nForwarding of data packets should be disabled to prevent data loss or information disclosure.",
    "rationale_statement": "Compute Engine instance cannot forward a packet unless the source IP address of the packet matches the IP address of the instance. Similarly, GCP won't deliver a packet whose destination IP address is different than the IP address of the instance receiving the packet. However, both capabilities are required if you want to use instances to help route packets.\nTo enable this source and destination IP check, disable the canIpForward field, which allows an instance to send and receive packets with non-matching destination or source IPs.",
    "impact_statement": "Deleting instance(s) acting as routers/packet forwarders may break the network connectivity.",
    "audit_procedure": "From Google Cloud Console\n\nGo to the VM Instances page by visiting: https://console.cloud.google.com/compute/instances.\nFor every instance, click on its name to go to the VM instance details page.\nUnder the Network interfaces section, ensure that IP forwarding is set to Off for every network interface.\n\nFrom Google Cloud CLI\n\nList all instances:\n\ngcloud compute instances list --format='table(name,canIpForward)'\n\n\nEnsure that CAN_IP_FORWARD column in the output of above command does not contain True for any VM instance.\n\nException:\nInstances created by GKE should be excluded because they need to have IP forwarding enabled and cannot be changed. Instances created by GKE have names that start with \"gke-\".",
    "remediation_procedure": "You only edit the canIpForward setting at instance creation time. Therefore, you need to delete the instance and create a new one where canIpForward is set to false.\nFrom Google Cloud Console\n\nGo to the VM Instances page by visiting: https://console.cloud.google.com/compute/instances.\nSelect the VM Instance you want to remediate.\nClick the Delete button.\nOn the 'VM Instances' page, click `CREATE INSTANCE'.\nCreate a new instance with the desired configuration. By default, the instance is configured to not allow IP forwarding.\n\nFrom Google Cloud CLI\n\nDelete the instance:\n\ngcloud compute instances delete INSTANCE_NAME\n\n\nCreate a new instance to replace it, with IP forwarding set to Off\n\ngcloud compute instances create",
    "default_value": "By default, instances are not configured to allow IP forwarding."
  },
  {
    "control_id": "4.6",
    "control": "Securely Manage Enterprise Assets and Software",
    "IG1": "o",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260478,
    "recommendation_id": 2570645,
    "view_level": "6.2.9",
    "title": "Ensure Instance IP assignment is set to private",
    "pivot_control_id": 396,
    "pivot_recommendation_id": 2570645,
    "url": "https://workbench.cisecurity.org/sections/1260478/recommendations/2570645",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 1"
      }
    ],
    "description": "Instance addresses can be public IP or private IP. Public IP means that the instance is accessible through the public internet. In contrast, instances using only private IP are not accessible through the public internet, but are accessible through a Virtual Private Cloud (VPC).\nLimiting network access to your database will limit potential attacks.",
    "rationale_statement": "Setting databases access only to private will reduce attack surface.",
    "impact_statement": "If you set a database IP to private, only host from the same network will have the ability to connect your database.\nConfiguring an existing Cloud SQL instance to use private IP causes the instance to restart.",
    "audit_procedure": "From Google Cloud Console\n\nIn the Google Cloud console, go to the Cloud SQL Instances page.\nOpen the Overview page of an instance by clicking the instance name.\nLook for a field labeled Private IP address This field will only show if the Private IP option is checked. The IP listed should be in the private IP space.\n\nFrom Google Cloud CLI\n\nList cloud SQL instances\n\ngcloud sql instances list --format=\"json\" | jq '.[] | .connectionName,.ipAddresses'\n\nEach instance listed should have a type of PRIVATE.\n\nIf you want to view a specific instance, note the <INSTANCE_NAME>(s) listed and run the following.\n\ngcloud sql instances describe <INSTANCE_NAME> --format=\"json\" | jq '.ipAddresses'\n\nType should be \"PRIVATE\"\n  {\n    \"ipAddress\": \"10.21.0.2\",\n    \"type\": \"PRIVATE\"\n  }",
    "remediation_procedure": "From Google Cloud Console\n\nIn the Google Cloud console, go to the Cloud SQL Instances page.\nOpen the Overview page of an instance by clicking the instance name.\nSelect Connections from the SQL navigation menu.\nCheck the Private IP checkbox.  A drop-down list shows the available networks in your project.\nSelect the VPC network you want to use:\nIf you see Private service connection required:\n\nClick Set up connection.\nIn the Allocate an IP range section, choose one of the following options:\n\n\nSelect one or more existing IP ranges or create a new one from the dropdown. The dropdown includes previously allocated ranges, if there are any, or you can select Allocate a new IP range and enter a new range and name.\nUse an automatically allocated IP range in your network.\nNote: You can specify an address range only for a primary instance, not for a read replica or clone.\n\n\nClick Continue.\nClick Create connection.\nVerify that you see the Private service connection for network VPC_NETWORK_NAME has been successfully created status.\n\n\n[Optional step for Private Services Access - review reference links to VPC documents for additional detail] If you want to allow other Google Cloud services such as BigQuery to access data in Cloud SQL and make queries against this data over a private IP connection, then select the Private path for Google Cloud services check box.\nClick Save\n\nFrom Google Cloud CLI\n\nList cloud SQL instances\n\ngcloud sql instances list --format=\"json\" | jq '.[] | .connectionName,.ipAddresses'\n\nNote the project name of the instance you want to set to a private IP, this will be <PROJECT_ID>\nNote the instance name of the instance you want to set to a private IP, this will be <INSTANCE_ID>\nExample public instance output:\n\"my-project-123456:us-central1:my-instance\"\n[\n  {\n    \"ipAddress\": \"0.0.0.0\",\n    \"type\": \"PRIMARY\"\n  },\n  {\n    \"ipAddress\": \"0.0.0.0\",\n    \"type\": \"OUTGOING\"\n  }\n\n\nrun the following command to list the available VPCs\n\ngcloud compute networks list --format=\"json\" | jq '.[].name'\n\nNote the name of the VPC to use for the instance private IP, this will be <VPC_NETWORK_NAME>\n\nrun the following to set instance to a private IP\n\ngcloud beta sql instances patch <INSTANCE_ID> \\\n--project=<PROJECT_ID> \\\n--network=projects/<PROJECT_ID>/global/networks/<VPC_NETWORK_NAME> \\\n--no-assign-ip",
    "default_value": "Public IP"
  },
  {
    "control_id": "4.7",
    "control": "Manage Default Accounts on Enterprise Assets and Software",
    "IG1": "o",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260473,
    "recommendation_id": 2036752,
    "view_level": "4.1",
    "title": "Ensure That Instances Are Not Configured To Use the Default Service Account",
    "pivot_control_id": 397,
    "pivot_recommendation_id": 2036752,
    "url": "https://workbench.cisecurity.org/sections/1260473/recommendations/2036752",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 1"
      }
    ],
    "description": "It is recommended to configure your instance to not use the default Compute Engine service account because it has the Editor role on the project.",
    "rationale_statement": "The default Compute Engine service account has the Editor role on the project, which allows read and write access to most Google Cloud Services. To defend against privilege escalations if your VM is compromised and prevent an attacker from gaining access to all of your project, it is recommended to not use the default Compute Engine service account. Instead, you should create a new service account and assigning only the permissions needed by your instance.\nThe default Compute Engine service account is named [PROJECT_NUMBER][email\u00a0protected].",
    "impact_statement": "",
    "audit_procedure": "From Google Cloud Console\n\nGo to the VM instances page by visiting:\thttps://console.cloud.google.com/compute/instances.\nClick on each instance name to go to its VM instance details page.\nUnder the section API and identity management, ensure that the default Compute Engine service account is not used. This account is named [PROJECT_NUMBER][email\u00a0protected].\n\nFrom Google Cloud CLI\n\nList the instances in your project and get details on each instance:\n\ngcloud compute instances list --format=json | jq -r '. | \"SA: \\(.[].serviceAccounts[].email) Name: \\(.[].name)\"'\n\n\nEnsure that the service account section has an email that does not match the pattern [PROJECT_NUMBER][email\u00a0protected].\n\nException:\nVMs created by GKE should be excluded. These VMs have names that start with gke- and are labeled goog-gke-node.",
    "remediation_procedure": "From Google Cloud Console\n\nGo to the VM instances page by visiting:\thttps://console.cloud.google.com/compute/instances.\nClick on the instance name to go to its VM instance details page.\nClick STOP and then click EDIT.\nUnder the section API and identity management, select a service account other than the default Compute Engine service account. You may first need to create a new service account.\nClick Save and then click START.\n\nFrom Google Cloud CLI\n\nStop the instance:\n\ngcloud compute instances stop <INSTANCE_NAME>\n\n\nUpdate the instance:\n\ngcloud compute instances set-service-account <INSTANCE_NAME> --service-account=<SERVICE_ACCOUNT> \n\n\nRestart the instance:\n\ngcloud compute instances start <INSTANCE_NAME>",
    "default_value": "By default, Compute instances are configured to use the default Compute Engine service account."
  },
  {
    "control_id": "4.7",
    "control": "Manage Default Accounts on Enterprise Assets and Software",
    "IG1": "o",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260473,
    "recommendation_id": 2036757,
    "view_level": "4.2",
    "title": "Ensure That Instances Are Not Configured To Use the Default Service Account With Full Access to All Cloud APIs",
    "pivot_control_id": 397,
    "pivot_recommendation_id": 2036757,
    "url": "https://workbench.cisecurity.org/sections/1260473/recommendations/2036757",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 1"
      }
    ],
    "description": "To support principle of least privileges and prevent potential privilege escalation it is recommended that instances are not assigned to default service account Compute Engine default service account with Scope Allow full access to all Cloud APIs.",
    "rationale_statement": "Along with ability to optionally create, manage and use user managed custom service accounts, Google Compute Engine provides default service account Compute Engine default service account for an instances to access necessary cloud services.\nProject Editor role is assigned to Compute Engine default service account hence, This service account has almost all capabilities over all cloud services except billing.\nHowever, when Compute Engine default service account assigned to an instance it can operate in 3 scopes.\n1. Allow default access: Allows only minimum access required to run an Instance (Least Privileges)\n\n2. Allow full access to all Cloud APIs: Allow full access to all the cloud APIs/Services (Too much access)\n\n3. Set access for each API: Allows Instance administrator to choose only those APIs that are needed to perform specific business functionality expected by instance\n\nWhen an instance is configured with Compute Engine default service account with Scope Allow full access to all Cloud APIs, based on IAM roles assigned to the user(s) accessing Instance, it may allow user to perform cloud operations/API calls that user is not supposed to perform leading to successful privilege escalation.",
    "impact_statement": "In order to change service account or scope for an instance, it needs to be stopped.",
    "audit_procedure": "From Google Cloud Console\n\nGo to the VM instances page by visiting:\thttps://console.cloud.google.com/compute/instances.\nClick on each instance name to go to its VM instance details page.\nUnder the API and identity management, ensure that Cloud API access scopes is not set to Allow full access to all Cloud APIs.\n\nFrom Google Cloud CLI\n\nList the instances in your project and get details on each instance:\n\ngcloud compute instances list --format=json | jq -r '. | \"SA Scopes: \\(.[].serviceAccounts[].scopes) Name: \\(.[].name) Email: \\(.[].serviceAccounts[].email)\"'\n\n\nEnsure that the service account section has an email that does not match the pattern [PROJECT_NUMBER][email\u00a0protected].\n\nException:\nVMs created by GKE should be excluded. These VMs have names that start with gke- and are labeled `goog-gke-node",
    "remediation_procedure": "From Google Cloud Console\n\n\nGo to the VM instances page by visiting:\thttps://console.cloud.google.com/compute/instances.\n\n\nClick on the impacted VM instance.\n\n\nIf the instance is not stopped, click the Stop button. Wait for the instance to be stopped.\n\n\nNext, click the Edit button.\n\n\nScroll down to the Service Account section.\n\n\nSelect a different service account or ensure that Allow full access to all Cloud APIs is not selected.\n\n\nClick the Save button to save your changes and then click START.\n\n\nFrom Google Cloud CLI\n\nStop the instance:\n\ngcloud compute instances stop <INSTANCE_NAME>\n\n\nUpdate the instance:\n\ngcloud compute instances set-service-account <INSTANCE_NAME> --service-account=<SERVICE_ACCOUNT> --scopes [SCOPE1, SCOPE2...]\n\n\nRestart the instance:\n\ngcloud compute instances start <INSTANCE_NAME>",
    "default_value": "While creating an VM instance, default service account is used with scope Allow default access."
  },
  {
    "control_id": "4.7",
    "control": "Manage Default Accounts on Enterprise Assets and Software",
    "IG1": "o",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260475,
    "recommendation_id": 2036753,
    "view_level": "6.1.1",
    "title": "Ensure That a MySQL Database Instance Does Not Allow Anyone To Connect With Administrative Privileges",
    "pivot_control_id": 397,
    "pivot_recommendation_id": 2036753,
    "url": "https://workbench.cisecurity.org/sections/1260475/recommendations/2036753",
    "assessment_status": "Manual",
    "applicable_profiles": [
      {
        "title": "Level 1"
      }
    ],
    "description": "It is recommended to set a password for the administrative user (root by default) to prevent unauthorized access to the SQL database instances.\nThis recommendation is applicable only for MySQL Instances. PostgreSQL does not offer any setting for No Password from the cloud console.",
    "rationale_statement": "At the time of MySQL Instance creation, not providing an administrative password allows anyone to connect to the SQL database instance with administrative privileges. The root password should be set to ensure only authorized users have these privileges.",
    "impact_statement": "Connection strings for administrative clients need to be reconfigured to use a password.",
    "audit_procedure": "From Google Cloud CLI\n\nList All SQL database instances of type MySQL:\n\ngcloud sql instances list --filter='DATABASE_VERSION:MYSQL* --project <project_id> --format=\"(NAME,PRIMARY_ADDRESS)\"'\n\n\nFor every MySQL instance try to connect using the PRIMARY_ADDRESS, if available:\n\nmysql -u root -h <mysql_instance_ip_address>\n\nThe command should return either an error message or a password prompt.\nSample Error message:\nERROR 1045 (28000): Access denied for user 'root'@'<Instance_IP>' (using password: NO)\n\nIf a command produces the mysql> prompt, the MySQL instance allows anyone to connect with administrative privileges without needing a password.\nNote: The No Password setting is exposed only at the time of MySQL instance creation. Once the instance is created, the Google Cloud Platform Console does not expose the set to confirm whether a password for an administrative user is set to a MySQL instance.",
    "remediation_procedure": "From Google Cloud Console\n\n\nGo to the Cloud SQL Instances page in the Google Cloud Platform Console using https://console.cloud.google.com/sql/\n\n\nSelect the instance to open its Overview page.\n\n\nSelect Access Control > Users.\n\n\nClick the More actions icon for the user to be updated.\n\n\nSelect Change password, specify a New password, and click OK.\n\n\nFrom Google Cloud CLI\n\nSet a password to a MySql instance:\n\ngcloud sql users set-password root --host=<host> --instance=<instance_name> --prompt-for-password\n\n\nA prompt will appear, requiring the user to enter a password:\n\nInstance Password:\n\n\nWith a successful password configured, the following message should be seen:\n\nUpdating Cloud SQL user...done.",
    "default_value": "From the Google Cloud Platform Console, the Create Instance workflow enforces the rule to enter the root password unless the option No Password is selected explicitly."
  },
  {
    "control_id": "4.8",
    "control": "Uninstall or Disable Unnecessary Services on Enterprise Assets and Software",
    "IG1": "-",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260473,
    "recommendation_id": 2036767,
    "view_level": "4.5",
    "title": "Ensure \u2018Enable Connecting to Serial Ports\u2019 Is Not Enabled for VM Instance",
    "pivot_control_id": 398,
    "pivot_recommendation_id": 2036767,
    "url": "https://workbench.cisecurity.org/sections/1260473/recommendations/2036767",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 1"
      }
    ],
    "description": "Interacting with a serial port is often referred to as the serial console, which is similar to using a terminal window, in that input and output is entirely in text mode and there is no graphical interface or mouse support.\nIf you enable the interactive serial console on an instance, clients can attempt to connect to that instance from any IP address. Therefore interactive serial console support should be disabled.",
    "rationale_statement": "A virtual machine instance has four virtual serial ports. Interacting with a serial port is similar to using a terminal window, in that input and output is entirely in text mode and there is no graphical interface or mouse support. The instance's operating system, BIOS, and other system-level entities often write output to the serial ports, and can accept input such as commands or answers to prompts. Typically, these system-level entities use the first serial port (port 1) and serial port 1 is often referred to as the serial console.\nThe interactive serial console does not support IP-based access restrictions such as IP whitelists. If you enable the interactive serial console on an instance, clients can attempt to connect to that instance from any IP address. This allows anybody to connect to that instance if they know the correct SSH key, username, project ID, zone, and instance name.\nTherefore interactive serial console support should be disabled.",
    "impact_statement": "",
    "audit_procedure": "From Google Cloud CLI\n\nLogin to Google Cloud console\nGo to Computer Engine\nGo to VM instances\nClick on the Specific VM\nEnsure Enable connecting to serial ports below Remote access block is unselected.\n\nFrom Google Cloud Console\nEnsure the below command's output shows null:\ngcloud compute instances describe <vmName> --zone=<region> --format=\"json(metadata.items[].key,metadata.items[].value)\"\n\nor key and value properties from below command's json response are equal to serial-port-enable and 0 or false respectively.\n    {\n      \"metadata\": {\n        \"items\": [\n          {\n           \"key\": \"serial-port-enable\",\n            \"value\": \"0\"\n          }\n        ]\n     }\n    }",
    "remediation_procedure": "From Google Cloud CLI\n\nLogin to Google Cloud console\nGo to Computer Engine\nGo to VM instances\nClick on the Specific VM\nClick EDIT\nUnselect Enable connecting to serial ports below Remote access block.\nClick Save\n\nFrom Google Cloud Console\nUse the below command to disable\ngcloud compute instances add-metadata <INSTANCE_NAME> --zone=<ZONE> --metadata=serial-port-enable=false\n\nor\ngcloud compute instances add-metadata <INSTANCE_NAME> --zone=<ZONE> --metadata=serial-port-enable=0\n\nPrevention:\nYou can prevent VMs from having serial port access enable by Disable VM serial port access organization policy:\nhttps://console.cloud.google.com/iam-admin/orgpolicies/compute-disableSerialPortAccess.",
    "default_value": "By default, connecting to serial ports is not enabled."
  },
  {
    "control_id": "4.8",
    "control": "Uninstall or Disable Unnecessary Services on Enterprise Assets and Software",
    "IG1": "-",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260479,
    "recommendation_id": 2036785,
    "view_level": "6.3.5",
    "title": "Ensure 'remote access' database flag for Cloud SQL SQL Server instance is set to 'off'",
    "pivot_control_id": 398,
    "pivot_recommendation_id": 2036785,
    "url": "https://workbench.cisecurity.org/sections/1260479/recommendations/2036785",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 1"
      }
    ],
    "description": "It is recommended to set remote access database flag for Cloud SQL SQL Server instance to off.",
    "rationale_statement": "The remote access option controls the execution of stored procedures from local or remote servers on which instances of SQL Server are running. This default value for this option is 1. This grants permission to run local stored procedures from remote servers or remote stored procedures from the local server. To prevent local stored procedures from being run from a remote server or remote stored procedures from being run on the local server, this must be disabled. The Remote Access option controls the execution of local stored procedures on remote servers or remote stored procedures on local server.  'Remote access' functionality can be abused to launch a Denial-of-Service (DoS) attack on remote servers by off-loading query processing to a target, hence this should be disabled. This recommendation is applicable to SQL Server database instances.",
    "impact_statement": "Setting custom flags via command line on certain instances will cause all omitted flags to be reset to defaults. This may cause you to lose custom flags and could result in unforeseen complications or instance restarts. Because of this, it is recommended you apply these flags changes during a period of low usage.",
    "audit_procedure": "From Google Cloud Console\n\nGo to the Cloud SQL Instances page in the Google Cloud Console by visiting https://console.cloud.google.com/sql/instances.\nSelect the instance to open its Instance Overview page\nEnsure the database flag remote access that has been set is listed under the Database flags section.\n\nFrom Google Cloud CLI\n\nEnsure the below command returns off for every Cloud SQL SQL Server database instance\n\ngcloud sql instances list --format=json | jq '.settings.databaseFlags[] | select(.name==\"remote access\")|.value'",
    "remediation_procedure": "From Google Cloud Console\n\nGo to the Cloud SQL Instances page in the Google Cloud Console by visiting https://console.cloud.google.com/sql/instances.\nSelect the SQL Server instance for which you want to enable to database flag.\nClick Edit.\nScroll down to the Flags section.\nTo set a flag that has not been set on the instance before, click Add item, choose the flag remote access from the drop-down menu, and set its value to off.\nClick Save to save your changes.\nConfirm your changes under Flags on the Overview page.\n\nFrom Google Cloud CLI\n\nConfigure the remote access database flag for every Cloud SQL SQL Server database instance using the below command\n\ngcloud sql instances patch <INSTANCE_NAME> --database-flags \"remote access=off\"\n\nNote : \n\nThis command will overwrite all database flags previously set. To keep those and add new ones, include the values for all flags you want set on the instance; any flag not specifically included is set to its default value. For flags that do not take a value, specify the flag name followed by an equals sign (\"=\").",
    "default_value": "By default 'remote access' is 'on'."
  },
  {
    "control_id": "5.2",
    "control": "Use Unique Passwords",
    "IG1": "o",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260473,
    "recommendation_id": 2036761,
    "view_level": "4.3",
    "title": "Ensure \u201cBlock Project-Wide SSH Keys\u201d Is Enabled for VM Instances",
    "pivot_control_id": 404,
    "pivot_recommendation_id": 2036761,
    "url": "https://workbench.cisecurity.org/sections/1260473/recommendations/2036761",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 1"
      }
    ],
    "description": "It is recommended to use Instance specific SSH key(s) instead of using common/shared project-wide SSH key(s) to access Instances.",
    "rationale_statement": "Project-wide SSH keys are stored in Compute/Project-meta-data. Project wide SSH keys can be used to login into all the instances within project. Using project-wide SSH keys eases the SSH key management but if compromised, poses the security risk which can impact all the instances within project.\nIt is recommended to use Instance specific SSH keys which can limit the attack surface if the SSH keys are compromised.",
    "impact_statement": "Users already having Project-wide ssh key pairs and using third party SSH clients will lose access to the impacted Instances. For Project users using gcloud or GCP Console based SSH option, no manual key creation and distribution is required and will be handled by GCE (Google Compute Engine) itself. To access Instance using third party SSH clients Instance specific SSH key pairs need to be created and distributed to the required users.",
    "audit_procedure": "From Google Cloud Console\n\n\nGo to the VM instances page by visiting https://console.cloud.google.com/compute/instances. It will list all the instances in your project.\n\n\nFor every instance, click on the name of the instance.\n\n\nUnder SSH Keys, ensure Block project-wide SSH keys is selected.\n\n\nFrom Google Cloud CLI\n\nList the instances in your project and get details on each instance:\n\ngcloud compute instances list --format=json\n\n\nEnsure key: block-project-ssh-keys is set to value: 'true'.",
    "remediation_procedure": "From Google Cloud Console\n\n\nGo to the VM instances page by visiting: https://console.cloud.google.com/compute/instances. It will list all the instances in your project.\n\n\nClick on the name of the Impacted instance\n\n\nClick Edit in the toolbar\n\n\nUnder SSH Keys, go to the Block project-wide SSH keys checkbox\n\n\nTo block users with project-wide SSH keys from connecting to this instance, select Block project-wide SSH keys\n\n\nClick Save at the bottom of the page\n\n\nRepeat steps for every impacted Instance\n\n\nFrom Google Cloud CLI\nTo block project-wide public SSH keys, set the metadata value to TRUE:\ngcloud compute instances add-metadata <INSTANCE_NAME> --metadata block-project-ssh-keys=TRUE",
    "default_value": "By Default Block Project-wide SSH keys is not enabled."
  },
  {
    "control_id": "5.4",
    "control": "Restrict Administrator Privileges to Dedicated Administrator Accounts",
    "IG1": "o",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260470,
    "recommendation_id": 2036713,
    "view_level": "1.5",
    "title": "Ensure That Service Account Has No Admin Privileges",
    "pivot_control_id": 406,
    "pivot_recommendation_id": 2036713,
    "url": "https://workbench.cisecurity.org/sections/1260470/recommendations/2036713",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 1"
      }
    ],
    "description": "A service account is a special Google account that belongs to an application or a VM, instead of to an individual end-user. The application uses the service account to call the service's Google API so that users aren't directly involved. It's recommended not to use admin access for ServiceAccount.",
    "rationale_statement": "Service accounts represent service-level security of the Resources (application or a VM) which can be determined by the roles assigned to it. Enrolling ServiceAccount with Admin rights gives full access to an assigned application or a VM. A ServiceAccount Access holder can perform critical actions like delete, update change settings, etc. without user intervention. For this reason, it's recommended that service accounts not have Admin rights.",
    "impact_statement": "Removing *Admin or *admin or Editor or Owner role assignments from service accounts may break functionality that uses impacted service accounts. Required role(s) should be assigned to impacted service accounts in order to restore broken functionalities.",
    "audit_procedure": "From Google Cloud Console\n\nGo to IAM & admin/IAM using https://console.cloud.google.com/iam-admin/iam\nGo to the Members\nEnsure that there are no User-Managed user created service account(s) with roles containing *Admin or *admin or role matching Editor or role matching Owner\n\nFrom Google Cloud CLI\n\nGet the policy that you want to modify, and write it to a JSON file:\n\ngcloud projects get-iam-policy PROJECT_ID --format json > iam.json\n\n\nThe contents of the JSON file will look similar to the following. Note that role of members group associated with each serviceaccount does not contain *Admin or *admin or does not match roles/editor or does not match roles/owner.\n\nThis recommendation is only applicable to User-Managed user-created service accounts. These accounts have the nomenclature: SERVICE_ACCOUNT_NAME@PROJECT_ID.iam.gserviceaccount.com. Note that some Google-managed, Google-created service accounts have the same naming format, and should be excluded (e.g., [email\u00a0protected] which needs the Owner role).\nSample Json output:\n{\n\"bindings\": [\n{\n   \"members\": [\n      \"serviceAccount:[email\u00a0protected]\",\n    ],\n    \"role\": \"roles/appengine.appAdmin\"\n},\n{\n    \"members\": [\n      \"user:[email\u00a0protected]\"\n    ],\n    \"role\": \"roles/owner\"\n},\n{\n   \"members\": [\n      \"serviceAccount:[email\u00a0protected]\",\n      \"serviceAccount:[email\u00a0protected]\"\n    ],\n    \"role\": \"roles/editor\"\n}\n],\n\"etag\": \"BwUjMhCsNvY=\",\n\"version\": 1\n}",
    "remediation_procedure": "From Google Cloud Console\n\nGo to IAM & admin/IAM using https://console.cloud.google.com/iam-admin/iam\nGo to the Members\nIdentify User-Managed user created service account with roles containing *Admin or *admin or role matching Editor or role matching Owner\nClick the Delete bin icon to remove the role from the member (service account in this case)\n\nFrom Google Cloud CLI\ngcloud projects get-iam-policy PROJECT_ID --format json > iam.json\n\n\nUsing a text editor, Remove Role which contains roles/*Admin or roles/*admin or matched roles/editor or matches 'roles/owner`. Add a role to the bindings array that defines the group members and the role for those members.\n\nFor example, to grant the role roles/appengine.appViewer to the ServiceAccount which is roles/editor, you would change the example shown below as follows:\n{\n\"bindings\": [\n{\n   \"members\": [\n     \"serviceAccount:[email\u00a0protected]\",\n    ],\n    \"role\": \"roles/appengine.appViewer\"\n},\n{\n    \"members\": [\n     \"user:[email\u00a0protected]\"\n    ],\n    \"role\": \"roles/owner\"\n   },\n{\n    \"members\": [\n      \"serviceAccount:[email\u00a0protected]\",\n      \"serviceAccount:[email\u00a0protected]\"\n    ],\n    \"role\": \"roles/editor\"\n}\n],\n\"etag\": \"BwUjMhCsNvY=\"\n}\n\n\nUpdate the project's IAM policy:\n\ngcloud projects set-iam-policy PROJECT_ID iam.json",
    "default_value": "User Managed (and not user-created) default service accounts have the Editor (roles/editor) role assigned to them to support GCP services they offer.\nBy default, there are no roles assigned to User Managed User created service accounts."
  },
  {
    "control_id": "5.6",
    "control": "Centralize Account Management",
    "IG1": "-",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260470,
    "recommendation_id": 2036709,
    "view_level": "1.1",
    "title": "Ensure that Corporate Login Credentials are Used",
    "pivot_control_id": 408,
    "pivot_recommendation_id": 2036709,
    "url": "https://workbench.cisecurity.org/sections/1260470/recommendations/2036709",
    "assessment_status": "Manual",
    "applicable_profiles": [
      {
        "title": "Level 1"
      }
    ],
    "description": "Use corporate login credentials instead of personal accounts, such as Gmail accounts.",
    "rationale_statement": "It is recommended fully-managed corporate Google accounts be used for increased visibility, auditing, and controlling access to Cloud Platform resources. Email accounts based outside of the user's organization, such as personal accounts, should not be used for business purposes.",
    "impact_statement": "There will be increased overhead as maintaining accounts will now be required. For smaller organizations, this will not be an issue, but will balloon with size.",
    "audit_procedure": "For each Google Cloud Platform project, list the accounts that have been granted access to that project:\nFrom Google Cloud CLI\ngcloud projects get-iam-policy PROJECT_ID\n\nAlso list the accounts added on each folder:\ngcloud resource-manager folders get-iam-policy FOLDER_ID \n\nAnd list your organization's IAM policy:\ngcloud organizations get-iam-policy ORGANIZATION_ID\n\nNo email accounts outside the organization domain should be granted permissions in the IAM policies. This excludes Google-owned service accounts.",
    "remediation_procedure": "Follow the documentation and setup corporate login accounts.\nPrevention:\nTo ensure that no email addresses outside the organization can be granted IAM permissions to its Google Cloud projects, folders or organization, turn on the Organization Policy for Domain Restricted Sharing. Learn more at: https://cloud.google.com/resource-manager/docs/organization-policy/restricting-domains",
    "default_value": "By default, no email addresses outside the organization's domain have access to its Google Cloud deployments, but any user email account can be added to the IAM policy for Google Cloud Platform projects, folders, or organizations."
  },
  {
    "control_id": "5.6",
    "control": "Centralize Account Management",
    "IG1": "-",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260472,
    "recommendation_id": 2036749,
    "view_level": "3.10",
    "title": "Use Identity Aware Proxy (IAP) to Ensure Only Traffic From Google IP Addresses are 'Allowed'",
    "pivot_control_id": 408,
    "pivot_recommendation_id": 2036749,
    "url": "https://workbench.cisecurity.org/sections/1260472/recommendations/2036749",
    "assessment_status": "Manual",
    "applicable_profiles": [
      {
        "title": "Level 2"
      }
    ],
    "description": "IAP authenticates the user requests to your apps via a Google single sign in. You can then manage these users with permissions to control access. It is recommended to use both IAP permissions and firewalls to restrict this access to your apps with sensitive information.",
    "rationale_statement": "IAP ensure that access to VMs is controlled by authenticating incoming requests. Access to your apps and the VMs should be restricted by firewall rules that allow only the proxy IAP IP addresses contained in the 35.235.240.0/20 subnet. Otherwise, unauthenticated requests can be made to your apps. To ensure that load balancing works correctly health checks should also be allowed.",
    "impact_statement": "If firewall rules are not configured correctly, legitimate business services could be negatively impacted. It is recommended to make these changes during a time of low usage.",
    "audit_procedure": "From Google Cloud Console\n\nFor each of your apps that have IAP enabled go to the Cloud Console VPC network > Firewall rules.\nVerify that the only rules correspond to the following values:\n\nTargets: All instances in the network\nSource IP ranges:\n\nIAP Proxy Addresses 35.235.240.0/20\nGoogle Health Check 130.211.0.0/22\nGoogle Health Check 35.191.0.0/16\n\n\nProtocols and ports:\n- Specified protocols and ports required for access and management of your app. For example most health check connection protocols would be covered by;\n\ntcp:80 (Default HTTP Health Check port)\ntcp:443 (Default HTTPS Health Check port)\n\n\n\n\n\nNote: if you have custom ports used by your load balancers, you will need to list them here",
    "remediation_procedure": "From Google Cloud Console\n\nGo to the Cloud Console VPC network > Firewall rules.\nSelect the checkbox next to the following rules:\n\ndefault-allow-http\ndefault-allow-https\ndefault-allow-internal\n\n\nClick Delete.\nClick Create firewall rule and set the following values:\n\nName: allow-iap-traffic\nTargets: All instances in the network\nSource IP ranges (press Enter after you paste each value in the box, copy each full CIDR IP address):\n\nIAP Proxy Addresses 35.235.240.0/20\nGoogle Health Check 130.211.0.0/22\nGoogle Health Check 35.191.0.0/16\n\n\nProtocols and ports:\n\nSpecified protocols and ports required for access and management of your app. For example most health check connection protocols would be covered by;\ntcp:80 (Default HTTP Health Check port)\ntcp:443 (Default HTTPS Health Check port)\nNote: if you have custom ports used by your load balancers, you will need to list them here\n\n\n\n\nWhen you're finished updating values, click Create.",
    "default_value": "By default all traffic is allowed."
  },
  {
    "control_id": "5.6",
    "control": "Centralize Account Management",
    "IG1": "-",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260473,
    "recommendation_id": 2036765,
    "view_level": "4.4",
    "title": "Ensure Oslogin Is Enabled for a Project",
    "pivot_control_id": 408,
    "pivot_recommendation_id": 2036765,
    "url": "https://workbench.cisecurity.org/sections/1260473/recommendations/2036765",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 1"
      }
    ],
    "description": "Enabling OS login binds SSH certificates to IAM users and facilitates effective SSH certificate management.",
    "rationale_statement": "Enabling osLogin ensures that SSH keys used to connect to instances are mapped with IAM users. Revoking access to IAM user will revoke all the SSH keys associated with that particular user. It facilitates centralized and automated SSH key pair management which is useful in handling cases like response to compromised SSH key pairs and/or revocation of external/third-party/Vendor users.",
    "impact_statement": "Enabling OS Login on project disables metadata-based SSH key configurations on all instances from a project. Disabling OS Login restores SSH keys that you have configured in project or instance meta-data.",
    "audit_procedure": "From Google Cloud Console\n\n\nGo to the VM compute metadata page by visiting https://console.cloud.google.com/compute/metadata.\n\n\nEnsure that key enable-oslogin is present with value set to TRUE.\n\n\nBecause instances can override project settings, ensure that no instance has custom metadata with key enable-oslogin and value FALSE.\n\n\nFrom Google Cloud CLI\n\nList the instances in your project and get details on each instance:\n\ngcloud compute instances list --format=json\n\n\nVerify that the section commonInstanceMetadata has a key enable-oslogin set to value TRUE.\nException:\nVMs created by GKE should be excluded. These VMs have names that start with gke- and are labeled goog-gke-node",
    "remediation_procedure": "From Google Cloud Console\n\n\nGo to the VM compute metadata page by visiting: https://console.cloud.google.com/compute/metadata.\n\n\nClick Edit.\n\n\nAdd a metadata entry where the key is enable-oslogin and the value is TRUE.\n\n\nClick Save to apply the changes.\n\n\nFor every instance that overrides the project setting, go to the VM Instances page at https://console.cloud.google.com/compute/instances.\n\n\nClick the name of the instance on which you want to remove the metadata value.\n\n\nAt the top of the instance details page, click Edit to edit the instance settings.\n\n\nUnder Custom metadata, remove any entry with key enable-oslogin and the value is FALSE\n\n\nAt the bottom of the instance details page, click Save to apply your changes to the instance.\n\n\nFrom Google Cloud CLI\n\nConfigure oslogin on the project:\n\ngcloud compute project-info add-metadata --metadata enable-oslogin=TRUE\n\n\nRemove instance metadata that overrides the project setting.\n\ngcloud compute instances remove-metadata <INSTANCE_NAME> --keys=enable-oslogin\n\nOptionally, you can enable two factor authentication for OS login. For more information, see: https://cloud.google.com/compute/docs/oslogin/setup-two-factor-authentication.",
    "default_value": "By default, parameter enable-oslogin is not set, which is equivalent to setting it to FALSE."
  },
  {
    "control_id": "6.3",
    "control": "Require MFA for Externally-Exposed Applications",
    "IG1": "-",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260470,
    "recommendation_id": 2036710,
    "view_level": "1.2",
    "title": "Ensure that Multi-Factor Authentication is 'Enabled' for All Non-Service Accounts",
    "pivot_control_id": 412,
    "pivot_recommendation_id": 2036710,
    "url": "https://workbench.cisecurity.org/sections/1260470/recommendations/2036710",
    "assessment_status": "Manual",
    "applicable_profiles": [
      {
        "title": "Level 1"
      }
    ],
    "description": "Setup multi-factor authentication for Google Cloud Platform accounts.",
    "rationale_statement": "Multi-factor authentication requires more than one mechanism to authenticate a user. This secures user logins from attackers exploiting stolen or weak credentials.",
    "impact_statement": "",
    "audit_procedure": "From Google Cloud Console\nFor each Google Cloud Platform project, folder, or organization:\n\n\nIdentify non-service accounts.\n\n\nManually verify that multi-factor authentication for each account is set.",
    "remediation_procedure": "From Google Cloud Console\nFor each Google Cloud Platform project:\n\n\nIdentify non-service accounts.\n\n\nSetup multi-factor authentication for each account.",
    "default_value": "By default, multi-factor authentication is not set."
  },
  {
    "control_id": "6.3",
    "control": "Require MFA for Externally-Exposed Applications",
    "IG1": "-",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260470,
    "recommendation_id": 2036711,
    "view_level": "1.3",
    "title": "Ensure that Security Key Enforcement is Enabled for All Admin Accounts",
    "pivot_control_id": 412,
    "pivot_recommendation_id": 2036711,
    "url": "https://workbench.cisecurity.org/sections/1260470/recommendations/2036711",
    "assessment_status": "Manual",
    "applicable_profiles": [
      {
        "title": "Level 2"
      }
    ],
    "description": "Setup Security Key Enforcement for Google Cloud Platform admin accounts.",
    "rationale_statement": "Google Cloud Platform users with Organization Administrator roles have the highest level of privilege in the organization. These accounts should be protected with the strongest form of two-factor authentication: Security Key Enforcement. Ensure that admins use Security Keys to log in instead of weaker second factors like SMS or one-time passwords (OTP). Security Keys are actual physical keys used to access Google Organization Administrator Accounts. They send an encrypted signature rather than a code, ensuring that logins cannot be phished.",
    "impact_statement": "If an organization administrator loses access to their security key, the user could lose access to their account. For this reason, it is important to set up backup security keys.",
    "audit_procedure": "Identify users with Organization Administrator privileges:\n\ngcloud organizations get-iam-policy ORGANIZATION_ID\n\nLook for members granted the role \"roles/resourcemanager.organizationAdmin\".\n\nManually verify that Security Key Enforcement has been enabled for each account.",
    "remediation_procedure": "Identify users with the Organization Administrator role.\n\n\nSetup Security Key Enforcement for each account. Learn more at: https://cloud.google.com/security-key/",
    "default_value": "By default, Security Key Enforcement is not enabled for Organization Administrators."
  },
  {
    "control_id": "6.6",
    "control": "Establish and Maintain an Inventory of Authentication and Authorization Systems",
    "IG1": "-",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260471,
    "recommendation_id": 2036748,
    "view_level": "2.13",
    "title": "Ensure Cloud Asset Inventory Is Enabled",
    "pivot_control_id": 415,
    "pivot_recommendation_id": 2036748,
    "url": "https://workbench.cisecurity.org/sections/1260471/recommendations/2036748",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 1"
      }
    ],
    "description": "GCP Cloud Asset Inventory is services that provides a historical view of GCP resources and IAM policies through a time-series database.  The information recorded includes metadata on Google Cloud resources, metadata on policies set on Google Cloud projects or resources, and runtime information gathered within a Google Cloud resource.",
    "rationale_statement": "The GCP resources and IAM policies captured by GCP Cloud Asset Inventory enables security analysis, resource change tracking, and compliance auditing.\nIt is recommended GCP Cloud Asset Inventory be enabled for all GCP projects.",
    "impact_statement": "",
    "audit_procedure": "From Google Cloud Console\nEnsure that the Cloud Asset API is enabled:\n\nGo to API & Services/Library by visiting https://console.cloud.google.com/apis/library\nSearch for Cloud Asset API and select the result for Cloud Asset API\nEnsure that API Enabled is displayed.\n\nFrom Google Cloud CLI\nEnsure that the Cloud Asset API is enabled:\n\nQuery enabled services:\n\ngcloud services list --enabled --filter=name:cloudasset.googleapis.com\n\nIf the API is listed, then it is enabled.  If the response is Listed 0 items the API is not enabled.",
    "remediation_procedure": "From Google Cloud Console\nEnable the Cloud Asset API:\n\nGo to API & Services/Library by visiting https://console.cloud.google.com/apis/library\nSearch for Cloud Asset API and select the result for Cloud Asset API\nClick the ENABLE button.\n\nFrom Google Cloud CLI\nEnable the Cloud Asset API:\n\nEnable the Cloud Asset API through the services interface:\n\ngcloud services enable cloudasset.googleapis.com",
    "default_value": "The Cloud Asset Inventory API is disabled by default in each project."
  },
  {
    "control_id": "6.7",
    "control": "Centralize Access Control",
    "IG1": "-",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260473,
    "recommendation_id": 2036765,
    "view_level": "4.4",
    "title": "Ensure Oslogin Is Enabled for a Project",
    "pivot_control_id": 416,
    "pivot_recommendation_id": 2036765,
    "url": "https://workbench.cisecurity.org/sections/1260473/recommendations/2036765",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 1"
      }
    ],
    "description": "Enabling OS login binds SSH certificates to IAM users and facilitates effective SSH certificate management.",
    "rationale_statement": "Enabling osLogin ensures that SSH keys used to connect to instances are mapped with IAM users. Revoking access to IAM user will revoke all the SSH keys associated with that particular user. It facilitates centralized and automated SSH key pair management which is useful in handling cases like response to compromised SSH key pairs and/or revocation of external/third-party/Vendor users.",
    "impact_statement": "Enabling OS Login on project disables metadata-based SSH key configurations on all instances from a project. Disabling OS Login restores SSH keys that you have configured in project or instance meta-data.",
    "audit_procedure": "From Google Cloud Console\n\n\nGo to the VM compute metadata page by visiting https://console.cloud.google.com/compute/metadata.\n\n\nEnsure that key enable-oslogin is present with value set to TRUE.\n\n\nBecause instances can override project settings, ensure that no instance has custom metadata with key enable-oslogin and value FALSE.\n\n\nFrom Google Cloud CLI\n\nList the instances in your project and get details on each instance:\n\ngcloud compute instances list --format=json\n\n\nVerify that the section commonInstanceMetadata has a key enable-oslogin set to value TRUE.\nException:\nVMs created by GKE should be excluded. These VMs have names that start with gke- and are labeled goog-gke-node",
    "remediation_procedure": "From Google Cloud Console\n\n\nGo to the VM compute metadata page by visiting: https://console.cloud.google.com/compute/metadata.\n\n\nClick Edit.\n\n\nAdd a metadata entry where the key is enable-oslogin and the value is TRUE.\n\n\nClick Save to apply the changes.\n\n\nFor every instance that overrides the project setting, go to the VM Instances page at https://console.cloud.google.com/compute/instances.\n\n\nClick the name of the instance on which you want to remove the metadata value.\n\n\nAt the top of the instance details page, click Edit to edit the instance settings.\n\n\nUnder Custom metadata, remove any entry with key enable-oslogin and the value is FALSE\n\n\nAt the bottom of the instance details page, click Save to apply your changes to the instance.\n\n\nFrom Google Cloud CLI\n\nConfigure oslogin on the project:\n\ngcloud compute project-info add-metadata --metadata enable-oslogin=TRUE\n\n\nRemove instance metadata that overrides the project setting.\n\ngcloud compute instances remove-metadata <INSTANCE_NAME> --keys=enable-oslogin\n\nOptionally, you can enable two factor authentication for OS login. For more information, see: https://cloud.google.com/compute/docs/oslogin/setup-two-factor-authentication.",
    "default_value": "By default, parameter enable-oslogin is not set, which is equivalent to setting it to FALSE."
  },
  {
    "control_id": "8.2",
    "control": "Collect Audit Logs",
    "IG1": "o",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260471,
    "recommendation_id": 2036723,
    "view_level": "2.1",
    "title": "Ensure That Cloud Audit Logging Is Configured Properly",
    "pivot_control_id": 428,
    "pivot_recommendation_id": 2036723,
    "url": "https://workbench.cisecurity.org/sections/1260471/recommendations/2036723",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 1"
      }
    ],
    "description": "It is recommended that Cloud Audit Logging is configured to track all admin activities and read, write access to user data.",
    "rationale_statement": "Cloud Audit Logging maintains two audit logs for each project, folder, and organization: Admin Activity and Data Access.\n\n\nAdmin Activity logs contain log entries for API calls or other administrative actions that modify the configuration or metadata of resources. Admin Activity audit logs are enabled for all services and cannot be configured.\n\n\nData Access audit logs record API calls that create, modify, or read user-provided data. These are disabled by default and should be enabled.\nThere are three kinds of Data Access audit log information:\n\nAdmin read: Records operations that read metadata or configuration information. Admin Activity audit logs record writes of metadata and configuration information that cannot be disabled.\nData read: Records operations that read user-provided data.\nData write: Records operations that write user-provided data.\n\n\n\nIt is recommended to have an effective default audit config configured in such a way that:\n\n\nlogtype is set to DATA_READ (to log user activity tracking) and DATA_WRITES (to log changes/tampering to user data).\n\n\naudit config is enabled for all the services supported by the Data Access audit logs feature.\n\n\nLogs should be captured for all users, i.e., there are no exempted users in any of the audit config sections. This will ensure overriding the audit config will not contradict the requirement.",
    "impact_statement": "There is no charge for Admin Activity audit logs.\nEnabling the Data Access audit logs might result in your project being charged for the additional logs usage.",
    "audit_procedure": "From Google Cloud Console\n\nGo to Audit Logs by visiting https://console.cloud.google.com/iam-admin/audit.\nEnsure that Admin Read, Data Write, and Data Read are enabled for all Google Cloud services and that no exemptions are allowed.\n\nFrom Google Cloud CLI\n\nList the Identity and Access Management (IAM) policies for the project, folder, or organization:\n\ngcloud organizations get-iam-policy ORGANIZATION_ID\ngcloud resource-manager folders get-iam-policy FOLDER_ID\ngcloud projects get-iam-policy PROJECT_ID\n\n\nPolicy should have a default auditConfigs section which has the logtype set to DATA_WRITES and DATA_READ for all services. Note that projects inherit settings from folders, which in turn inherit settings from the organization. When called, projects get-iam-policy, the result shows only the policies set in the project, not the policies inherited from the parent folder or organization. Nevertheless, if the parent folder has Cloud Audit Logging enabled, the project does as well.\n\nSample output for default audit configs may look like this:\n\tauditConfigs:\n\t- auditLogConfigs:\n  \t- logType: ADMIN_READ\n  \t- logType: DATA_WRITE\n  \t- logType: DATA_READ\n \t service: allServices\n\n\nAny of the auditConfigs sections should not have parameter \"exemptedMembers:\" set, which will ensure that Logging is enabled for all users and no user is exempted.",
    "remediation_procedure": "From Google Cloud Console\n\nGo to Audit Logs by visiting https://console.cloud.google.com/iam-admin/audit.\nFollow the steps at https://cloud.google.com/logging/docs/audit/configure-data-access to enable audit logs for all Google Cloud services. Ensure that no exemptions are allowed.\n\nFrom Google Cloud CLI\n\nTo read the project's IAM policy and store it in a file run a command:\n\ngcloud projects get-iam-policy PROJECT_ID > /tmp/project_policy.yaml\n\nAlternatively, the policy can be set at the organization or folder level. If setting the policy at the organization level, it is not necessary to also set it for each folder or project.\ngcloud organizations get-iam-policy ORGANIZATION_ID > /tmp/org_policy.yaml\ngcloud resource-manager folders get-iam-policy FOLDER_ID > /tmp/folder_policy.yaml\n\n\nEdit policy in /tmp/policy.yaml, adding or changing only the audit logs configuration to:\nNote: Admin Activity Logs are enabled by default, and cannot be disabled. So they are not listed in these configuration changes.\n\nauditConfigs:\n- auditLogConfigs:\n  - logType: DATA_WRITE\n  - logType: DATA_READ\n  service: allServices\n\nNote: exemptedMembers: is not set as audit logging should be enabled for all the users\n\nTo write new IAM policy run command:\n\ngcloud organizations set-iam-policy ORGANIZATION_ID /tmp/org_policy.yaml\ngcloud resource-manager folders set-iam-policy FOLDER_ID /tmp/folder_policy.yaml\ngcloud projects set-iam-policy PROJECT_ID /tmp/project_policy.yaml\n\nIf the preceding command reports a conflict with another change, then repeat these steps, starting with the first step.",
    "default_value": "Admin Activity logs are always enabled. They cannot be disabled.\nData Access audit logs are disabled by default because they can be quite large."
  },
  {
    "control_id": "8.2",
    "control": "Collect Audit Logs",
    "IG1": "o",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260471,
    "recommendation_id": 2036726,
    "view_level": "2.2",
    "title": "Ensure That Sinks Are Configured for All Log Entries",
    "pivot_control_id": 428,
    "pivot_recommendation_id": 2036726,
    "url": "https://workbench.cisecurity.org/sections/1260471/recommendations/2036726",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 1"
      }
    ],
    "description": "It is recommended to create a sink that will export copies of all the log entries. This can help aggregate logs from multiple projects and export them to a Security Information and Event Management (SIEM).",
    "rationale_statement": "Log entries are held in Cloud Logging. To aggregate logs, export them to a SIEM. To keep them longer, it is recommended to set up a log sink. Exporting involves writing a filter that selects the log entries to export, and choosing a destination in Cloud Storage, BigQuery, or Cloud Pub/Sub. The filter and destination are held in an object called a sink. To ensure all log entries are exported to sinks, ensure that there is no filter configured for a sink.\nSinks can be created in projects, organizations, folders, and billing accounts.",
    "impact_statement": "There are no costs or limitations in Cloud Logging for exporting logs, but the export destinations charge for storing or transmitting the log data.",
    "audit_procedure": "From Google Cloud Console\n\n\nGo to Logs Router by visiting https://console.cloud.google.com/logs/router.\n\n\nFor every sink, click the 3-dot button for Menu options and select View sink details.\n\n\nEnsure there is at least one sink with an empty Inclusion filter.\n\n\nAdditionally, ensure that the resource configured as Destination exists.\n\n\nFrom Google Cloud CLI\n\nEnsure that a sink with an empty filter exists. List the sinks for the project, folder or organization. If sinks are configured at a folder or organization level, they do not need to be configured for each project:\n\ngcloud logging sinks list --folder=FOLDER_ID | --organization=ORGANIZATION_ID | --project=PROJECT_ID\n\nThe output should list at least one sink with an empty filter.\n\nAdditionally, ensure that the resource configured as Destination exists.\n\nSee https://cloud.google.com/sdk/gcloud/reference/beta/logging/sinks/list for more information.",
    "remediation_procedure": "From Google Cloud Console\n\n\nGo to Logs Router by visiting https://console.cloud.google.com/logs/router.\n\n\nClick on the arrow symbol with CREATE SINK text.\n\n\nFill out the fields for Sink details.\n\n\nChoose Cloud Logging bucket in the Select sink destination drop down menu.\n\n\nChoose a log bucket in the next drop down menu.\n\n\nIf an inclusion filter is not provided for this sink, all ingested logs will be routed to the destination provided above. This may result in higher than expected resource usage.\n\n\nClick Create Sink.\n\n\nFor more information, see https://cloud.google.com/logging/docs/export/configure_export_v2#dest-create.\nFrom Google Cloud CLI\nTo create a sink to export all log entries in a Google Cloud Storage bucket:\ngcloud logging sinks create <sink-name> storage.googleapis.com/DESTINATION_BUCKET_NAME\n\nSinks can be created for a folder or organization, which will include all projects.\ngcloud logging sinks create <sink-name> storage.googleapis.com/DESTINATION_BUCKET_NAME --include-children --folder=FOLDER_ID | --organization=ORGANIZATION_ID\n\nNote:\n\n\nA sink created by the command-line above will export logs in storage buckets. However, sinks can be configured to export logs into BigQuery, or Cloud Pub/Sub, or Custom Destination.\n\n\nWhile creating a sink, the sink option --log-filter is not used to ensure the sink exports all log entries.\n\n\nA sink can be created at a folder or organization level that collects the logs of all the projects underneath bypassing the option --include-children in the gcloud command.",
    "default_value": "By default, there are no sinks configured."
  },
  {
    "control_id": "8.2",
    "control": "Collect Audit Logs",
    "IG1": "o",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260471,
    "recommendation_id": 2036730,
    "view_level": "2.4",
    "title": "Ensure Log Metric Filter and Alerts Exist for Project Ownership Assignments/Changes",
    "pivot_control_id": 428,
    "pivot_recommendation_id": 2036730,
    "url": "https://workbench.cisecurity.org/sections/1260471/recommendations/2036730",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 1"
      }
    ],
    "description": "In order to prevent unnecessary project ownership assignments to users/service-accounts and further misuses of projects and resources, all roles/Owner assignments should be monitored.\nMembers (users/Service-Accounts) with a role assignment to primitive role roles/Owner are project owners.\nThe project owner has all the privileges on the project the role belongs to. These are summarized below:\n\nAll viewer permissions on all GCP Services within the project\nPermissions for actions that modify the state of all GCP services within the project\nManage roles and permissions for a project and all resources within the project\nSet up billing for a project\n\nGranting the owner role to a member (user/Service-Account) will allow that member to modify the Identity and Access Management (IAM) policy. Therefore, grant the owner role only if the member has a legitimate purpose to manage the IAM policy. This is because the project IAM policy contains sensitive access control data. Having a minimal set of users allowed to manage IAM policy will simplify any auditing that may be necessary.",
    "rationale_statement": "Project ownership has the highest level of privileges on a project. To avoid misuse of project resources, the project ownership assignment/change actions mentioned above should be monitored and alerted to concerned recipients.\n\nSending project ownership invites\nAcceptance/Rejection of project ownership invite by user\nAdding role\\Owner to a user/service-account\nRemoving a user/Service account from role\\Owner",
    "impact_statement": "Enabling of logging may result in your project being charged for the additional logs usage.",
    "audit_procedure": "From Google Cloud Console\nEnsure that the prescribed log metric is present:\n\n\nGo to Logging/Log-based Metrics by visiting https://console.cloud.google.com/logs/metrics.\n\n\nIn the User-defined Metrics section, ensure that at least one metric <Log_Metric_Name> is present with filter text:\n\n\n(protoPayload.serviceName=\"cloudresourcemanager.googleapis.com\") \nAND (ProjectOwnership OR projectOwnerInvitee) \nOR (protoPayload.serviceData.policyDelta.bindingDeltas.action=\"REMOVE\" \nAND protoPayload.serviceData.policyDelta.bindingDeltas.role=\"roles/owner\") \nOR (protoPayload.serviceData.policyDelta.bindingDeltas.action=\"ADD\" \nAND protoPayload.serviceData.policyDelta.bindingDeltas.role=\"roles/owner\")\n\nEnsure that the prescribed Alerting Policy is present:\n\n\nGo to Alerting by visiting https://console.cloud.google.com/monitoring/alerting.\n\n\nUnder the Policies section, ensure that at least one alert policy exists for the log metric above. Clicking on the policy should show that it is configured with a condition. For example, Violates when: Any logging.googleapis.com/user/<Log Metric Name> stream is above a threshold of zero(0) for greater than zero(0) seconds means that the alert will trigger for any new owner change. Verify that the chosen alerting thresholds make sense for your organization.\n\n\nEnsure that the appropriate notifications channels have been set up.\n\n\nFrom Google Cloud CLI\nEnsure that the prescribed log metric is present:\n\nList the log metrics:\n\ngcloud logging metrics list --format json\n\n\nEnsure that the output contains at least one metric with filter set to:\n\n(protoPayload.serviceName=\"cloudresourcemanager.googleapis.com\") \nAND (ProjectOwnership OR projectOwnerInvitee) \nOR (protoPayload.serviceData.policyDelta.bindingDeltas.action=\"REMOVE\" \nAND protoPayload.serviceData.policyDelta.bindingDeltas.role=\"roles/owner\") \nOR (protoPayload.serviceData.policyDelta.bindingDeltas.action=\"ADD\" \nAND protoPayload.serviceData.policyDelta.bindingDeltas.role=\"roles/owner\")\n\n\nNote the value of the property metricDescriptor.type for the identified metric, in the format logging.googleapis.com/user/<Log Metric Name>.\n\nEnsure that the prescribed alerting policy is present:\n\nList the alerting policies:\n\ngcloud alpha monitoring policies list --format json\n\n\nEnsure that the output contains an least one alert policy where:\n\n\nconditions.conditionThreshold.filter is set to metric.type=\\\"logging.googleapis.com/user/<Log Metric Name>\\\"\nAND enabled is set to true",
    "remediation_procedure": "From Google Cloud Console\nCreate the prescribed log metric:\n\n\nGo to Logging/Logs-based Metrics by visiting https://console.cloud.google.com/logs/metrics and click \"CREATE METRIC\".\n\n\nClick the down arrow symbol on the Filter Bar at the rightmost corner and select Convert to Advanced Filter.\n\n\nClear any text and add:\n\n\n(protoPayload.serviceName=\"cloudresourcemanager.googleapis.com\") \nAND (ProjectOwnership OR projectOwnerInvitee) \nOR (protoPayload.serviceData.policyDelta.bindingDeltas.action=\"REMOVE\" \nAND protoPayload.serviceData.policyDelta.bindingDeltas.role=\"roles/owner\") \nOR (protoPayload.serviceData.policyDelta.bindingDeltas.action=\"ADD\" \nAND protoPayload.serviceData.policyDelta.bindingDeltas.role=\"roles/owner\")\n\n\n\nClick Submit Filter. The logs display based on the filter text entered by the user.\n\n\nIn the Metric Editor menu on the right, fill out the name field. Set Units to 1 (default) and the Type to Counter. This ensures that the log metric counts the number of log entries matching the advanced logs query.\n\n\nClick Create Metric.\n\n\nCreate the display prescribed Alert Policy:\n\n\nIdentify the newly created metric under the section User-defined Metrics at https://console.cloud.google.com/logs/metrics.\n\n\nClick the 3-dot icon in the rightmost column for the desired metric and select Create alert from Metric. A new page opens.\n\n\nFill out the alert policy configuration and click Save. Choose the alerting threshold and configuration that makes sense for the user's organization. For example, a threshold of zero(0) for the most recent value will ensure that a notification is triggered for every owner change in the project:\n\n\nSet `Aggregator` to `Count`\n\nSet `Configuration`:\n\n- Condition: above\n\n- Threshold: 0\n\n- For: most recent value\n\n\n\nConfigure the desired notifications channels in the section Notifications.\n\n\nName the policy and click Save.\n\n\nFrom Google Cloud CLI\nCreate a prescribed Log Metric:\n\nUse the command: gcloud beta logging metrics create\nReference for Command Usage: https://cloud.google.com/sdk/gcloud/reference/beta/logging/metrics/create\n\nCreate prescribed Alert Policy\n\nUse the command: gcloud alpha monitoring policies create\nReference for Command Usage: https://cloud.google.com/sdk/gcloud/reference/alpha/monitoring/policies/create",
    "default_value": ""
  },
  {
    "control_id": "8.2",
    "control": "Collect Audit Logs",
    "IG1": "o",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260471,
    "recommendation_id": 2036731,
    "view_level": "2.5",
    "title": "Ensure That the Log Metric Filter and Alerts Exist for Audit Configuration Changes",
    "pivot_control_id": 428,
    "pivot_recommendation_id": 2036731,
    "url": "https://workbench.cisecurity.org/sections/1260471/recommendations/2036731",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 1"
      }
    ],
    "description": "Google Cloud Platform (GCP) services write audit log entries to the Admin Activity and Data Access logs to help answer the questions of, \"who did what, where, and when?\" within GCP projects.\nCloud audit logging records information includes the identity of the API caller, the time of the API call, the source IP address of the API caller, the request parameters, and the response elements returned by GCP services. Cloud audit logging provides a history of GCP API calls for an account, including API calls made via the console, SDKs, command-line tools, and other GCP services.",
    "rationale_statement": "Admin activity and data access logs produced by cloud audit logging enable security analysis, resource change tracking, and compliance auditing.\nConfiguring the metric filter and alerts for audit configuration changes ensures the recommended state of audit configuration is maintained so that all activities in the project are audit-able at any point in time.",
    "impact_statement": "Enabling of logging may result in your project being charged for the additional logs usage.",
    "audit_procedure": "From Google Cloud Console\nEnsure the prescribed log metric is present:\n\n\nGo to Logging/Logs-based Metrics by visiting https://console.cloud.google.com/logs/metrics.\n\n\nIn the User-defined Metrics section, ensure that at least one metric <Log_Metric_Name> is present with the filter text:\n\n\nprotoPayload.methodName=\"SetIamPolicy\" AND\nprotoPayload.serviceData.policyDelta.auditConfigDeltas:*\n\nEnsure that the prescribed alerting policy is present:\n\n\nGo to Alerting by visiting https://console.cloud.google.com/monitoring/alerting.\n\n\nUnder the Policies section, ensure that at least one alert policy exists for the log metric above. Clicking on the policy should show that it is configured with a condition. For example, Violates when: Any logging.googleapis.com/user/<Log Metric Name> stream is above a threshold of 0 for greater than zero(0) seconds, means that the alert will trigger for any new owner change. Verify that the chosen alerting thresholds make sense for the user's organization.\n\n\nEnsure that appropriate notifications channels have been set up.\n\n\nFrom Google Cloud CLI\nEnsure that the prescribed log metric is present:\n\nList the log metrics:\n\ngcloud beta logging metrics list --format json\n\n\nEnsure that the output contains at least one metric with the filter set to:\n\nprotoPayload.methodName=\"SetIamPolicy\" AND\nprotoPayload.serviceData.policyDelta.auditConfigDeltas:*\n\n\nNote the value of the property metricDescriptor.type for the identified metric, in the format logging.googleapis.com/user/<Log Metric Name>.\n\nEnsure that the prescribed alerting policy is present:\n\nList the alerting policies:\n\ngcloud alpha monitoring policies list --format json\n\n\nEnsure that the output contains at least one alert policy where:\n\n\nconditions.conditionThreshold.filter is set to metric.type=\\\"logging.googleapis.com/user/<Log Metric Name>\\\"\nAND enabled is set to true",
    "remediation_procedure": "From Google Cloud Console\nCreate the prescribed log metric:\n\n\nGo to Logging/Logs-based Metrics by visiting https://console.cloud.google.com/logs/metrics and click \"CREATE METRIC\".\n\n\nClick the down arrow symbol on the Filter Bar at the rightmost corner and select Convert to Advanced Filter.\n\n\nClear any text and add:\n\n\nprotoPayload.methodName=\"SetIamPolicy\" AND\nprotoPayload.serviceData.policyDelta.auditConfigDeltas:*\n\n\n\nClick Submit Filter. Display logs appear based on the filter text entered by the user.\n\n\nIn the Metric Editor menu on the right, fill out the name field. Set Units to 1 (default) and Type to Counter. This will ensure that the log metric counts the number of log entries matching the user's advanced logs query.\n\n\nClick Create Metric.\n\n\nCreate a prescribed Alert Policy:\n\n\nIdentify the new metric the user just created, under the section User-defined Metrics at https://console.cloud.google.com/logs/metrics.\n\n\nClick the 3-dot icon in the rightmost column for the new metric and select Create alert from Metric. A new page opens.\n\n\nFill out the alert policy configuration and click Save. Choose the alerting threshold and configuration that makes sense for the organization. For example, a threshold of zero(0) for the most recent value will ensure that a notification is triggered for every owner change in the project:\n\n\nSet `Aggregator` to `Count`\n\nSet `Configuration`:\n\n- Condition: above\n\n- Threshold: 0\n\n- For: most recent value\n\n\n\nConfigure the desired notifications channels in the section Notifications.\n\n\nName the policy and click Save.\n\n\nFrom Google Cloud CLI\nCreate a prescribed Log Metric:\n\nUse the command: gcloud beta logging metrics create\nReference for command usage: https://cloud.google.com/sdk/gcloud/reference/beta/logging/metrics/create\n\nCreate prescribed Alert Policy\nUse the command: gcloud alpha monitoring policies create\nReference for command usage: https://cloud.google.com/sdk/gcloud/reference/alpha/monitoring/policies/create",
    "default_value": ""
  },
  {
    "control_id": "8.2",
    "control": "Collect Audit Logs",
    "IG1": "o",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260471,
    "recommendation_id": 2036733,
    "view_level": "2.6",
    "title": "Ensure That the Log Metric Filter and Alerts Exist for Custom Role Changes",
    "pivot_control_id": 428,
    "pivot_recommendation_id": 2036733,
    "url": "https://workbench.cisecurity.org/sections/1260471/recommendations/2036733",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 1"
      }
    ],
    "description": "It is recommended that a metric filter and alarm be established for changes to Identity and Access Management (IAM) role creation, deletion and updating activities.",
    "rationale_statement": "Google Cloud IAM provides predefined roles that give granular access to specific Google Cloud Platform resources and prevent unwanted access to other resources. However, to cater to organization-specific needs, Cloud IAM also provides the ability to create custom roles. Project owners and administrators with the Organization Role Administrator role or the IAM Role Administrator role can create custom roles.\nMonitoring role creation, deletion and updating activities will help in identifying any over-privileged role at early stages.",
    "impact_statement": "Enabling of logging may result in your project being charged for the additional logs usage.",
    "audit_procedure": "From Console:\nEnsure that the prescribed log metric is present:\n\n\nGo to Logging/Logs-based Metrics by visiting https://console.cloud.google.com/logs/metrics.\n\n\nIn the User-defined Metrics section, ensure that at least one metric <Log_Metric_Name> is present with filter text:\n\n\nresource.type=\"iam_role\" \nAND (protoPayload.methodName=\"google.iam.admin.v1.CreateRole\" \nOR protoPayload.methodName=\"google.iam.admin.v1.DeleteRole\" \nOR protoPayload.methodName=\"google.iam.admin.v1.UpdateRole\")\n\nEnsure that the prescribed alerting policy is present:\n\n\nGo to Alerting by visiting https://console.cloud.google.com/monitoring/alerting.\n\n\nUnder the Policies section, ensure that at least one alert policy exists for the log metric above. Clicking on the policy should show that it is configured with a condition. For example, Violates when: Any logging.googleapis.com/user/<Log Metric Name> stream is above a threshold of zero(0) for greater than zero(0) seconds means that the alert will trigger for any new owner change. Verify that the chosen alerting thresholds make sense for the user's organization.\n\n\nEnsure that the appropriate notifications channels have been set up.\n\n\nFrom Google Cloud CLI\nEnsure that the prescribed log metric is present:\n\nList the log metrics:\n\ngcloud logging metrics list --format json\n\n\nEnsure that the output contains at least one metric with the filter set to:\n\nresource.type=\"iam_role\"\nAND (protoPayload.methodName = \"google.iam.admin.v1.CreateRole\" OR\nprotoPayload.methodName=\"google.iam.admin.v1.DeleteRole\" OR\nprotoPayload.methodName=\"google.iam.admin.v1.UpdateRole\")\n\n\nNote the value of the property metricDescriptor.type for the identified metric, in the format logging.googleapis.com/user/<Log Metric Name>.\n\nEnsure that the prescribed alerting policy is present:\n\nList the alerting policies:\n\ngcloud alpha monitoring policies list --format json\n\n\nEnsure that the output contains an least one alert policy where:\n\n\nconditions.conditionThreshold.filter is set to metric.type=\\\"logging.googleapis.com/user/<Log Metric Name>\\\"\nAND enabled is set to true.",
    "remediation_procedure": "From Console:\nCreate the prescribed log metric:\n\n\nGo to Logging/Logs-based Metrics by visiting https://console.cloud.google.com/logs/metrics and click \"CREATE METRIC\".\n\n\nClick the down arrow symbol on the  Filter Bar at the rightmost corner and select Convert to Advanced Filter.\n\n\nClear any text and add:\n\n\nresource.type=\"iam_role\" \nAND (protoPayload.methodName =  \"google.iam.admin.v1.CreateRole\" \nOR protoPayload.methodName=\"google.iam.admin.v1.DeleteRole\" \nOR protoPayload.methodName=\"google.iam.admin.v1.UpdateRole\")\n\n\n\nClick Submit Filter. Display logs appear based on the filter text entered by the user.\n\n\nIn the Metric Editor menu on the right, fill out the name field. Set Units to 1 (default) and Type to Counter. This ensures that the log metric counts the number of log entries matching the advanced logs query.\n\n\nClick Create Metric.\n\n\nCreate a prescribed Alert Policy:\n\n\nIdentify the new metric that was just created under the section User-defined Metrics at https://console.cloud.google.com/logs/metrics.\n\n\nClick the 3-dot icon in the rightmost column for the metric and select Create alert from Metric. A new page displays.\n\n\nFill out the alert policy configuration and click Save. Choose the alerting threshold and configuration that makes sense for the user's organization. For example, a threshold of zero(0) for the most recent value ensures that a notification is triggered for every owner change in the project:\n\n\nSet `Aggregator` to `Count`\n\nSet `Configuration`:\n\n- Condition: above\n\n- Threshold: 0\n\n- For: most recent value\n\n\n\nConfigure the desired notification channels in the section Notifications.\n\n\nName the policy and click Save.\n\n\nFrom Google Cloud CLI\nCreate the prescribed Log Metric:\n\nUse the command: gcloud logging metrics create\n\nCreate the prescribed Alert Policy:\n\nUse the command: gcloud alpha monitoring policies create",
    "default_value": ""
  },
  {
    "control_id": "8.2",
    "control": "Collect Audit Logs",
    "IG1": "o",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260471,
    "recommendation_id": 2036735,
    "view_level": "2.7",
    "title": "Ensure That the Log Metric Filter and Alerts Exist for VPC Network Firewall Rule Changes",
    "pivot_control_id": 428,
    "pivot_recommendation_id": 2036735,
    "url": "https://workbench.cisecurity.org/sections/1260471/recommendations/2036735",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 2"
      }
    ],
    "description": "It is recommended that a metric filter and alarm be established for Virtual Private Cloud (VPC) Network Firewall rule changes.",
    "rationale_statement": "Monitoring for Create or Update Firewall rule events gives insight to network access changes and may reduce the time it takes to detect suspicious activity.",
    "impact_statement": "Enabling of logging may result in your project being charged for the additional logs usage. These charges could be significant depending on the size of the organization.",
    "audit_procedure": "From Google Cloud Console\nEnsure that the prescribed log metric is present:\n\n\nGo to Logging/Logs-based Metrics by visiting https://console.cloud.google.com/logs/metrics.\n\n\nIn the User-defined Metrics section, ensure at least one metric <Log_Metric_Name> is present with this filter text:\n\n\nresource.type=\"gce_firewall_rule\" \nAND (protoPayload.methodName:\"compute.firewalls.patch\" \nOR protoPayload.methodName:\"compute.firewalls.insert\"\nOR protoPayload.methodName:\"compute.firewalls.delete\")\n\nEnsure that the prescribed alerting policy is present:\n\n\nGo to Alerting by visiting https://console.cloud.google.com/monitoring/alerting.\n\n\nUnder the Policies section, ensure that at least one alert policy exists for the log metric above. Clicking on the policy should show that it is configured with a condition. For example, Violates when: Any logging.googleapis.com/user/<Log Metric Name> stream is above a threshold of zero(0) for greater than zero(0) seconds means that the alert will trigger for any new owner change. Verify that the chosen alerting thresholds make sense for the user's organization.\n\n\nEnsure that appropriate notification channels have been set up.\n\n\nFrom Google Cloud CLI\nEnsure that the prescribed log metric is present:\n\nList the log metrics:\n\ngcloud logging metrics list --format json\n\n\nEnsure that the output contains at least one metric with the filter set to:\n\nresource.type=\"gce_firewall_rule\" \nAND (protoPayload.methodName:\"compute.firewalls.patch\" \nOR protoPayload.methodName:\"compute.firewalls.insert\"\nOR protoPayload.methodName:\"compute.firewalls.delete\")\n\n\nNote the value of the property metricDescriptor.type for the identified metric, in the format logging.googleapis.com/user/<Log Metric Name>.\n\nEnsure that the prescribed alerting policy is present:\n\nList the alerting policies:\n\ngcloud alpha monitoring policies list --format json\n\n\nEnsure that the output contains an least one alert policy where:\n\n\nconditions.conditionThreshold.filter is set to metric.type=\\\"logging.googleapis.com/user/<Log Metric Name>\\\"\nAND enabled is set to true",
    "remediation_procedure": "From Google Cloud Console\nCreate the prescribed log metric:\n\n\nGo to Logging/Logs-based Metrics by visiting https://console.cloud.google.com/logs/metrics and click \"CREATE METRIC\".\n\n\nClick the down arrow symbol on the Filter Bar at the rightmost corner and select Convert to Advanced Filter.\n\n\nClear any text and add:\n\n\nresource.type=\"gce_firewall_rule\" \nAND (protoPayload.methodName:\"compute.firewalls.patch\" \nOR protoPayload.methodName:\"compute.firewalls.insert\"\nOR protoPayload.methodName:\"compute.firewalls.delete\")\n\n\n\nClick Submit Filter. Display logs appear based on the filter text entered by the user.\n\n\nIn the Metric Editor menu on the right, fill out the name field. Set Units to 1 (default) and Type to Counter. This ensures that the log metric counts the number of log entries matching the advanced logs query.\n\n\nClick Create Metric.\n\n\nCreate the prescribed Alert Policy:\n\n\nIdentify the newly created metric under the section User-defined Metrics at https://console.cloud.google.com/logs/metrics.\n\n\nClick the 3-dot icon in the rightmost column for the new metric and select Create alert from Metric. A new page displays.\n\n\nFill out the alert policy configuration and click Save. Choose the alerting threshold and configuration that makes sense for the user's organization. For example, a threshold of zero(0) for the most recent value ensures that a notification is triggered for every owner change in the project:\n\n\nSet `Aggregator` to `Count`\n\nSet `Configuration`:\n\n- Condition: above\n\n- Threshold: 0\n\n- For: most recent value\n\n\n\nConfigure the desired notifications channels in the section Notifications.\n\n\nName the policy and click Save.\n\n\nFrom Google Cloud CLI\nCreate the prescribed Log Metric\n\nUse the command: gcloud logging metrics create\n\nCreate the prescribed alert policy:\n\nUse the command: gcloud alpha monitoring policies create",
    "default_value": ""
  },
  {
    "control_id": "8.2",
    "control": "Collect Audit Logs",
    "IG1": "o",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260471,
    "recommendation_id": 2036737,
    "view_level": "2.8",
    "title": "Ensure That the Log Metric Filter and Alerts Exist for VPC Network Route Changes",
    "pivot_control_id": 428,
    "pivot_recommendation_id": 2036737,
    "url": "https://workbench.cisecurity.org/sections/1260471/recommendations/2036737",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 2"
      }
    ],
    "description": "It is recommended that a metric filter and alarm be established for Virtual Private Cloud (VPC) network route changes.",
    "rationale_statement": "Google Cloud Platform (GCP) routes define the paths network traffic takes from a VM instance to another destination. The other destination can be inside the organization VPC network (such as another VM) or outside of it. Every route consists of a destination and a next hop. Traffic whose destination IP is within the destination range is sent to the next hop for delivery.\nMonitoring changes to route tables will help ensure that all VPC traffic flows through an expected path.",
    "impact_statement": "Enabling of logging may result in your project being charged for the additional logs usage. These charges could be significant depending on the size of the organization.",
    "audit_procedure": "From Google Cloud Console\nEnsure that the prescribed Log metric is present:\n\n\nGo to Logging/Logs-based Metrics by visiting https://console.cloud.google.com/logs/metrics.\n\n\nIn the User-defined Metrics section, ensure that at least one metric <Log_Metric_Name> is present with the filter text:\n\n\nresource.type=\"gce_route\" \nAND (protoPayload.methodName:\"compute.routes.delete\" \nOR protoPayload.methodName:\"compute.routes.insert\")\n\nEnsure the prescribed alerting policy is present:\n\n\nGo to Alerting by visiting: https://console.cloud.google.com/monitoring/alerting.\n\n\nUnder the Policies section, ensure that at least one alert policy exists for the log metric above. Clicking on the policy should show that it is configured with a condition. For example, Violates when: Any logging.googleapis.com/user/<Log Metric Name> stream is above a threshold of 0 for greater than zero(0) seconds means that the alert will trigger for any new owner change. Verify that the chosen alert thresholds make sense for the user's organization.\n\n\nEnsure that the appropriate notification channels have been set up.\n\n\nFrom Google Cloud CLI\nEnsure the prescribed log metric is present:\n\nList the log metrics:\n\ngcloud logging metrics list --format json\n\n\nEnsure that the output contains at least one metric with the filter set to:\n\nresource.type=\"gce_route\" \nAND (protoPayload.methodName:\"compute.routes.delete\" \nOR protoPayload.methodName:\"compute.routes.insert\")\n\n\nNote the value of the property metricDescriptor.type for the identified metric, in the format logging.googleapis.com/user/<Log Metric Name>.\n\nEnsure that the prescribed alerting policy is present:\n\nList the alerting policies:\n\ngcloud alpha monitoring policies list --format json\n\n\nEnsure that the output contains an least one alert policy where:\n\n\nconditions.conditionThreshold.filter is set to metric.type=\\\"logging.googleapis.com/user/<Log Metric Name>\\\"\nAND enabled is set to true",
    "remediation_procedure": "From Google Cloud Console\nCreate the prescribed Log Metric:\n\n\nGo to Logging/Logs-based Metrics by visiting https://console.cloud.google.com/logs/metrics and click \"CREATE METRIC\".\n\n\nClick the down arrow symbol on the Filter Bar at the rightmost corner and select Convert to Advanced Filter\n\n\nClear any text and add:\n\n\nresource.type=\"gce_route\" \nAND (protoPayload.methodName:\"compute.routes.delete\" \nOR protoPayload.methodName:\"compute.routes.insert\")\n\n\n\nClick Submit Filter. Display logs appear based on the filter text entered by the user.\n\n\nIn the Metric Editor menu on the right, fill out the name field. Set Units to 1 (default) and Type to Counter. This ensures that the log metric counts the number of log entries matching the user's advanced logs query.\n\n\nClick Create Metric.\n\n\nCreate the prescribed alert policy:\n\n\nIdentify the newly created metric under the section User-defined Metrics at https://console.cloud.google.com/logs/metrics.\n\n\nClick the 3-dot icon in the rightmost column for the new metric and select Create alert from Metric. A new page displays.\n\n\nFill out the alert policy configuration and click Save. Choose the alerting threshold and configuration that makes sense for the user's organization. For example, a threshold of zero(0) for the most recent value ensures that a notification is triggered for every owner change in the project:\n\n\nSet `Aggregator` to `Count`\n\nSet `Configuration`:\n\n- Condition: above\n\n- Threshold: 0\n\n- For: most recent value\n\n\n\nConfigure the desired notification channels in the section Notifications.\n\n\nName the policy and click Save.\n\n\nFrom Google Cloud CLI\nCreate the prescribed Log Metric:\n\nUse the command: gcloud logging metrics create\n\nCreate the prescribed the alert policy:\n\nUse the command: gcloud alpha monitoring policies create",
    "default_value": ""
  },
  {
    "control_id": "8.2",
    "control": "Collect Audit Logs",
    "IG1": "o",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260471,
    "recommendation_id": 2036740,
    "view_level": "2.9",
    "title": "Ensure That the Log Metric Filter and Alerts Exist for VPC Network Changes",
    "pivot_control_id": 428,
    "pivot_recommendation_id": 2036740,
    "url": "https://workbench.cisecurity.org/sections/1260471/recommendations/2036740",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 2"
      }
    ],
    "description": "It is recommended that a metric filter and alarm be established for Virtual Private Cloud (VPC) network changes.",
    "rationale_statement": "It is possible to have more than one VPC within a project. In addition, it is also possible to create a peer connection between two VPCs enabling network traffic to route between VPCs.\nMonitoring changes to a VPC will help ensure VPC traffic flow is not getting impacted.",
    "impact_statement": "Enabling of logging may result in your project being charged for the additional logs usage. These charges could be significant depending on the size of the organization.",
    "audit_procedure": "From Google Cloud Console\nEnsure the prescribed log metric is present:\n\n\nGo to Logging/Logs-based Metrics by visiting https://console.cloud.google.com/logs/metrics.\n\n\nIn the User-defined Metrics section, ensure at least one metric <Log_Metric_Name> is present with filter text:\n\n\nresource.type=\"gce_network\" \nAND (protoPayload.methodName:\"compute.networks.insert\" \nOR protoPayload.methodName:\"compute.networks.patch\" \nOR protoPayload.methodName:\"compute.networks.delete\" \nOR protoPayload.methodName:\"compute.networks.removePeering\" \nOR protoPayload.methodName:\"compute.networks.addPeering\")\n\nEnsure the prescribed alerting policy is present:\n\n\nGo to Alerting by visiting https://console.cloud.google.com/monitoring/alerting.\n\n\nUnder the Policies section, ensure that at least one alert policy exists for the log metric above. Clicking on the policy should show that it is configured with a condition. For example, Violates when: Any logging.googleapis.com/user/<Log Metric Name> stream is above a threshold of 0 for greater than 0 seconds means that the alert will trigger for any new owner change. Verify that the chosen alerting thresholds make sense for the user's organization.\n\n\nEnsure that appropriate notification channels have been set up.\n\n\nFrom Google Cloud CLI\nEnsure the log metric is present:\n\nList the log metrics:\n\ngcloud logging metrics list --format json\n\n\nEnsure that the output contains at least one metric with filter set to:\n\nresource.type=\"gce_network\" \nAND protoPayload.methodName=\"beta.compute.networks.insert\" \nOR protoPayload.methodName=\"beta.compute.networks.patch\" \nOR protoPayload.methodName=\"v1.compute.networks.delete\"  \nOR protoPayload.methodName=\"v1.compute.networks.removePeering\" \nOR protoPayload.methodName=\"v1.compute.networks.addPeering\"\n\n\nNote the value of the property metricDescriptor.type for the identified metric, in the format logging.googleapis.com/user/<Log Metric Name>.\n\nEnsure the prescribed alerting policy is present:\n\nList the alerting policies:\n\ngcloud alpha monitoring policies list --format json\n\n\nEnsure that the output contains at least one alert policy where:\n\n\nconditions.conditionThreshold.filter is set to metric.type=\\\"logging.googleapis.com/user/<Log Metric Name>\\\"\nAND enabled is set to true",
    "remediation_procedure": "From Google Cloud Console\nCreate the prescribed log metric:\n\n\nGo to Logging/Logs-based Metrics by visiting https://console.cloud.google.com/logs/metrics and click \"CREATE METRIC\".\n\n\nClick the down arrow symbol on Filter Bar at the rightmost corner and select Convert to Advanced Filter.\n\n\nClear any text and add:\n\n\nresource.type=\"gce_network\" \nAND (protoPayload.methodName:\"compute.networks.insert\" \nOR protoPayload.methodName:\"compute.networks.patch\" \nOR protoPayload.methodName:\"compute.networks.delete\" \nOR protoPayload.methodName:\"compute.networks.removePeering\" \nOR protoPayload.methodName:\"compute.networks.addPeering\")\n\n\n\nClick Submit Filter. Display logs appear based on the filter text entered by the user.\n\n\nIn the Metric Editor menu on the right, fill out the name field. Set Units to 1 (default) and Type to Counter. This ensures that the log metric counts the number of log entries matching the user's advanced logs query.\n\n\nClick Create Metric.\n\n\nCreate the prescribed alert policy:\n\n\nIdentify the newly created metric under the section User-defined Metrics at https://console.cloud.google.com/logs/metrics.\n\n\nClick the 3-dot icon in the rightmost column for the new metric and select Create alert from Metric. A new page appears.\n\n\nFill out the alert policy configuration and click Save. Choose the alerting threshold and configuration that makes sense for the user's organization. For example, a threshold of 0 for the most recent value will ensure that a notification is triggered for every owner change in the project:\n\n\nSet `Aggregator` to `Count`\n\nSet `Configuration`:\n\n- Condition: above\n\n- Threshold: 0\n\n- For: most recent value\n\n\n\nConfigure the desired notification channels in the section Notifications.\n\n\nName the policy and click Save.\n\n\nFrom Google Cloud CLI\nCreate the prescribed Log Metric:\n\nUse the command: gcloud logging metrics create\n\nCreate the prescribed alert policy:\n\nUse the command: gcloud alpha monitoring policies create",
    "default_value": ""
  },
  {
    "control_id": "8.2",
    "control": "Collect Audit Logs",
    "IG1": "o",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260471,
    "recommendation_id": 2036742,
    "view_level": "2.10",
    "title": "Ensure That the Log Metric Filter and Alerts Exist for Cloud Storage IAM Permission Changes",
    "pivot_control_id": 428,
    "pivot_recommendation_id": 2036742,
    "url": "https://workbench.cisecurity.org/sections/1260471/recommendations/2036742",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 2"
      }
    ],
    "description": "It is recommended that a metric filter and alarm be established for Cloud Storage Bucket IAM changes.",
    "rationale_statement": "Monitoring changes to cloud storage bucket permissions may reduce the time needed to detect and correct permissions on sensitive cloud storage buckets and objects inside the bucket.",
    "impact_statement": "Enabling of logging may result in your project being charged for the additional logs usage. These charges could be significant depending on the size of the organization.",
    "audit_procedure": "From Google Cloud Console\nEnsure the prescribed log metric is present:\n\n\nFor each project that contains cloud storage buckets, go to Logging/Logs-based Metrics by visiting https://console.cloud.google.com/logs/metrics.\n\n\nIn the User-defined Metrics section, ensure at least one metric <Log_Metric_Name> is present with the filter text:\n\n\nresource.type=\"gcs_bucket\"\nAND protoPayload.methodName=\"storage.setIamPermissions\"\n\nEnsure that the prescribed alerting policy is present:\n\n\nGo to Alerting by visiting https://console.cloud.google.com/monitoring/alerting.\n\n\nUnder the Policies section, ensure that at least one alert policy exists for the log metric above. Clicking on the policy should show that it is configured with a condition. For example, Violates when: Any logging.googleapis.com/user/<Log Metric Name> stream is above a threshold of 0 for greater than 0 seconds means that the alert will trigger for any new owner change. Verify that the chosen alerting thresholds make sense for the user's organization.\n\n\nEnsure that the appropriate notifications channels have been set up.\n\n\nFrom Google Cloud CLI\nEnsure that the prescribed log metric is present:\n\nList the log metrics:\n\ngcloud logging metrics list --format json\n\n\nEnsure that the output contains at least one metric with the filter set to:\n\nresource.type=gcs_bucket \nAND protoPayload.methodName=\"storage.setIamPermissions\"\n\n\nNote the value of the property metricDescriptor.type for the identified metric, in the format logging.googleapis.com/user/<Log Metric Name>.\n\nEnsure the prescribed alerting policy is present:\n\nList the alerting policies:\n\ngcloud alpha monitoring policies list --format json\n\n\nEnsure that the output contains an least one alert policy where:\n\n\nconditions.conditionThreshold.filter is set to metric.type=\\\"logging.googleapis.com/user/<Log Metric Name>\\\"\nAND enabled is set to true",
    "remediation_procedure": "From Google Cloud Console\nCreate the prescribed log metric:\n\n\nGo to Logging/Logs-based Metrics by visiting https://console.cloud.google.com/logs/metrics and click \"CREATE METRIC\".\n\n\nClick the down arrow symbol on the Filter Bar at the rightmost corner and select Convert to Advanced Filter.\n\n\nClear any text and add:\n\n\nresource.type=\"gcs_bucket\" \nAND protoPayload.methodName=\"storage.setIamPermissions\"\n\n\n\nClick Submit Filter. Display logs appear based on the filter text entered by the user.\n\n\nIn the Metric Editor menu on right, fill out the name field. Set Units to 1 (default) and Type to Counter. This ensures that the log metric counts the number of log entries matching the user's advanced logs query.\n\n\nClick Create Metric.\n\n\nCreate the prescribed Alert Policy:\n\n\nIdentify the newly created metric under the section User-defined Metrics at https://console.cloud.google.com/logs/metrics.\n\n\nClick the 3-dot icon in the rightmost column for the new metric and select Create alert from Metric. A new page appears.\n\n\nFill out the alert policy configuration and click Save. Choose the alerting threshold and configuration that makes sense for the user's organization. For example, a threshold of zero(0) for the most recent value will ensure that a notification is triggered for every owner change in the project:\n\n\nSet `Aggregator` to `Count`\n\nSet `Configuration`:\n\n- Condition: above\n\n- Threshold: 0\n\n- For: most recent value\n\n\n\nConfigure the desired notifications channels in the section Notifications.\n\n\nName the policy and click Save.\n\n\nFrom Google Cloud CLI\nCreate the prescribed Log Metric:\n\nUse the command: gcloud beta logging metrics create\n\nCreate the prescribed alert policy:\n\nUse the command: gcloud alpha monitoring policies create",
    "default_value": ""
  },
  {
    "control_id": "8.2",
    "control": "Collect Audit Logs",
    "IG1": "o",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260471,
    "recommendation_id": 2036744,
    "view_level": "2.11",
    "title": "Ensure That the Log Metric Filter and Alerts Exist for SQL Instance Configuration Changes",
    "pivot_control_id": 428,
    "pivot_recommendation_id": 2036744,
    "url": "https://workbench.cisecurity.org/sections/1260471/recommendations/2036744",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 2"
      }
    ],
    "description": "It is recommended that a metric filter and alarm be established for SQL instance configuration changes.",
    "rationale_statement": "Monitoring changes to SQL instance configuration changes may reduce the time needed to detect and correct misconfigurations done on the SQL server.\nBelow are a few of the configurable options which may the impact security posture of an SQL instance:\n\n\nEnable auto backups and high availability: Misconfiguration may adversely impact business continuity, disaster recovery, and high availability\n\n\nAuthorize networks: Misconfiguration may increase exposure to untrusted networks",
    "impact_statement": "Enabling of logging may result in your project being charged for the additional logs usage. These charges could be significant depending on the size of the organization.",
    "audit_procedure": "From Google Cloud Console\nEnsure the prescribed log metric is present:\n\n\nFor each project that contains Cloud SQL instances, go to Logging/Logs-based Metrics by visiting https://console.cloud.google.com/logs/metrics.\n\n\nIn the User-defined Metrics section, ensure that at least one metric <Log_Metric_Name> is present with the filter text:\n\n\nprotoPayload.methodName=\"cloudsql.instances.update\"\n\nEnsure that the prescribed alerting policy is present:\n\n\nGo to Alerting by visiting https://console.cloud.google.com/monitoring/alerting.\n\n\nUnder the Policies section, ensure that at least one alert policy exists for the log metric above. Clicking on the policy should show that it is configured with a condition. For example, Violates when: Any logging.googleapis.com/user/<Log Metric Name> stream is above a threshold of zero(0) for greater than zero(0) seconds means that the alert will trigger for any new owner change. Verify that the chosen alerting thresholds make sense for the user's organization.\n\n\nEnsure that the appropriate notifications channels have been set up.\n\n\nFrom Google Cloud CLI\nEnsure that the prescribed log metric is present:\n\nList the log metrics:\n\ngcloud logging metrics list --format json\n\n\nEnsure that the output contains at least one metric with the filter set to\n\nprotoPayload.methodName=\"cloudsql.instances.update\"\n\n\nNote the value of the property metricDescriptor.type for the identified metric, in the format logging.googleapis.com/user/<Log Metric Name>.\n\nEnsure that the prescribed alerting policy is present:\n\nList the alerting policies:\n\ngcloud alpha monitoring policies list --format json\n\n\nEnsure that the output contains at least one alert policy where:\n\n\nconditions.conditionThreshold.filter is set to metric.type=\\\"logging.googleapis.com/user/<Log Metric Name>\\\"\nAND enabled is set to true",
    "remediation_procedure": "From Google Cloud Console\nCreate the prescribed Log Metric:\n\n\nGo to Logging/Logs-based Metrics by visiting https://console.cloud.google.com/logs/metrics and click \"CREATE METRIC\".\n\n\nClick the down arrow symbol on the Filter Bar at the rightmost corner and select Convert to Advanced Filter.\n\n\nClear any text and add:\n\n\nprotoPayload.methodName=\"cloudsql.instances.update\"\n\n\n\nClick Submit Filter. Display logs appear based on the filter text entered by the user.\n\n\nIn the Metric Editor menu on right, fill out the name field. Set Units to 1 (default) and Type to Counter. This ensures that the log metric counts the number of log entries matching the user's advanced logs query.\n\n\nClick Create Metric.\n\n\nCreate the prescribed alert policy:\n\n\nIdentify the newly created metric under the section User-defined Metrics at https://console.cloud.google.com/logs/metrics.\n\n\nClick the 3-dot icon in the rightmost column for the new metric and select Create alert from Metric. A new page appears.\n\n\nFill out the alert policy configuration and click Save. Choose the alerting threshold and configuration that makes sense for the user's organization. For example, a threshold of zero(0) for the most recent value will ensure that a notification is triggered for every owner change in the user's project:\n\n\nSet `Aggregator` to `Count`\n\nSet `Configuration`:\n\n- Condition: above\n\n- Threshold: 0\n\n- For: most recent value\n\n\n\nConfigure the desired notification channels in the section Notifications.\n\n\nName the policy and click Save.\n\n\nFrom Google Cloud CLI\nCreate the prescribed log metric:\n\nUse the command: gcloud logging metrics create\n\nCreate the prescribed alert policy:\n\nUse the command: gcloud alpha monitoring policies create\nReference for command usage: https://cloud.google.com/sdk/gcloud/reference/alpha/monitoring/policies/create",
    "default_value": ""
  },
  {
    "control_id": "8.2",
    "control": "Collect Audit Logs",
    "IG1": "o",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260471,
    "recommendation_id": 2036746,
    "view_level": "2.12",
    "title": "Ensure That Cloud DNS Logging Is Enabled for All VPC Networks",
    "pivot_control_id": 428,
    "pivot_recommendation_id": 2036746,
    "url": "https://workbench.cisecurity.org/sections/1260471/recommendations/2036746",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 1"
      }
    ],
    "description": "Cloud DNS logging records the queries from the name servers within your VPC to Stackdriver.  Logged queries can come from Compute Engine VMs, GKE containers, or other GCP resources provisioned within the VPC.",
    "rationale_statement": "Security monitoring and forensics cannot depend solely on IP addresses from VPC flow logs, especially when considering the dynamic IP usage of cloud resources, HTTP virtual host routing, and other technology that can obscure the DNS name used by a client from the IP address.  Monitoring of Cloud DNS logs provides visibility to DNS names requested by the clients within the VPC.  These logs can be monitored for anomalous domain names, evaluated against threat intelligence, and\nNote: For full capture of DNS, firewall must block egress UDP/53 (DNS) and TCP/443 (DNS over HTTPS) to prevent client from using external DNS name server for resolution.",
    "impact_statement": "Enabling of Cloud DNS logging might result in your project being charged for the additional logs usage.",
    "audit_procedure": "From Google Cloud CLI\n\nList all VPCs networks in a project:\n\ngcloud compute networks list --format=\"table[box,title='All VPC Networks'](name:label='VPC Network Name')\"\n\n\nList all DNS policies, logging enablement, and associated VPC networks:\n\ngcloud dns policies list --flatten=\"networks[]\" --format=\"table[box,title='All DNS Policies By VPC Network'](name:label='Policy Name',enableLogging:label='Logging Enabled':align=center,networks.networkUrl.basename():label='VPC Network Name')\"\n\nEach VPC Network should be associated with a DNS policy with logging enabled.",
    "remediation_procedure": "From Google Cloud CLI\nAdd New DNS Policy With Logging Enabled\nFor each VPC network that needs a DNS policy with logging enabled:\ngcloud dns policies create enable-dns-logging --enable-logging --description=\"Enable DNS Logging\" --networks=VPC_NETWORK_NAME\n\nThe VPC_NETWORK_NAME can be one or more networks in comma-separated list\nEnable Logging for Existing DNS Policy\nFor each VPC network that has an existing DNS policy that needs logging enabled:\ngcloud dns policies update POLICY_NAME --enable-logging --networks=VPC_NETWORK_NAME\n\nThe VPC_NETWORK_NAME can be one or more networks in comma-separated list",
    "default_value": "Cloud DNS logging is disabled by default on each network."
  },
  {
    "control_id": "8.2",
    "control": "Collect Audit Logs",
    "IG1": "o",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260471,
    "recommendation_id": 2036750,
    "view_level": "2.14",
    "title": "Ensure 'Access Transparency' is 'Enabled'",
    "pivot_control_id": 428,
    "pivot_recommendation_id": 2036750,
    "url": "https://workbench.cisecurity.org/sections/1260471/recommendations/2036750",
    "assessment_status": "Manual",
    "applicable_profiles": [
      {
        "title": "Level 2"
      }
    ],
    "description": "GCP Access Transparency provides audit logs for all actions that Google personnel take in your Google Cloud resources.",
    "rationale_statement": "Controlling access to your information is one of the foundations of information security. Given that Google Employees do have access to your organizations' projects for support reasons, you should have logging in place to view who, when, and why your information is being accessed.",
    "impact_statement": "To use Access Transparency your organization will need to have at one of the following support level: Premium, Enterprise, Platinum, or Gold. There will be subscription costs associated with support, as well as increased storage costs for storing the logs. You will also not be able to turn Access Transparency off yourself, and you will need to submit a service request to Google Cloud Support.",
    "audit_procedure": "From Google Cloud Console\nDetermine if Access Transparency is Enabled\n\n\nFrom the Google Cloud Home, click on the Navigation hamburger menu in the top left. Hover over the IAM & Admin Menu. Select settings in the middle of the column that opens.\n\n\nThe status will be under the heading Access Transparency. Status should be Enabled",
    "remediation_procedure": "From Google Cloud Console\nAdd privileges to enable Access Transparency\n\n\nFrom the Google Cloud Home, within the project you wish to check, click on the Navigation hamburger menu in the top left. Hover over the 'IAM and Admin'. Select IAM in the top of the column that opens.\n\n\nClick the blue button the says +add at the top of the screen.\n\n\nIn the principals field, select a user or group by typing in their associated email address.\n\n\nClick on the role field to expand it. In the filter field enter Access Transparency Admin and select it.\n\n\nClick save.\n\n\nVerify that the Google Cloud project is associated with a billing account\n\n\nFrom the Google Cloud Home, click on the Navigation hamburger menu in the top left. Select Billing.\n\n\nIf you see This project is not associated with a billing account you will need to enter billing information or switch to a project with a billing account.\n\n\nEnable Access Transparency\n\n\nFrom the Google Cloud Home, click on the Navigation hamburger menu in the top left. Hover over the IAM & Admin Menu. Select settings in the middle of the column that opens.\n\n\nClick the blue button labeled Enable Access Transparency for Organization",
    "default_value": "By default Access Transparency is not enabled."
  },
  {
    "control_id": "8.2",
    "control": "Collect Audit Logs",
    "IG1": "o",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260471,
    "recommendation_id": 2563725,
    "view_level": "2.16",
    "title": "Ensure Logging is enabled for HTTP(S) Load Balancer",
    "pivot_control_id": 428,
    "pivot_recommendation_id": 2563725,
    "url": "https://workbench.cisecurity.org/sections/1260471/recommendations/2563725",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 2"
      }
    ],
    "description": "Logging enabled on a HTTPS Load Balancer will show all network traffic and its destination.",
    "rationale_statement": "Logging will allow you to view HTTPS network traffic to your web applications.",
    "impact_statement": "On high use systems with a high percentage sample rate, the logging file may grow to high capacity in a short amount of time. Ensure that the sample rate is set appropriately so that storage costs are not exorbitant.",
    "audit_procedure": "From Google Cloud Console\n\n\nFrom Google Cloud home open the Navigation Menu in the top left.\n\n\nUnder the Networking heading select Network services.\n\n\nSelect the HTTPS load-balancer you wish to audit.\n\n\nSelect Edit then Backend Configuration.\n\n\nSelect Edit on the corresponding backend service.\n\n\nEnsure that Enable Logging is selected. Also ensure that Sample Rate is set to an appropriate level for your needs.\n\n\nFrom Google Cloud CLI\n\nRun the following command\n\ngcloud compute backend-services describe <serviceName>\n\n\nEnsure that enable-logging is enabled and sample rate is set to your desired level.",
    "remediation_procedure": "From Google Cloud Console\n\n\nFrom Google Cloud home open the Navigation Menu in the top left.\n\n\nUnder the Networking heading select Network services.\n\n\nSelect the HTTPS load-balancer you wish to audit.\n\n\nSelect Edit then Backend Configuration.\n\n\nSelect Edit on the corresponding backend service.\n\n\nClick Enable Logging.\n\n\nSet Sample Rate to a desired value. This is a percentage as a decimal point. 1.0 is 100%.\n\n\nFrom Google Cloud CLI\n\nRun the following command\n\ngcloud compute backend-services update <serviceName> --region=REGION --enable-logging --logging-sample-rate=<percentageAsADecimal>",
    "default_value": "By default logging for https load balancing is disabled. When logging is enabled it sets the default sample rate as 1.0 or 100%. Ensure this value fits the need of your organization to avoid high storage costs."
  },
  {
    "control_id": "8.2",
    "control": "Collect Audit Logs",
    "IG1": "o",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260472,
    "recommendation_id": 2036745,
    "view_level": "3.8",
    "title": "Ensure that VPC Flow Logs is Enabled for Every Subnet in a VPC Network",
    "pivot_control_id": 428,
    "pivot_recommendation_id": 2036745,
    "url": "https://workbench.cisecurity.org/sections/1260472/recommendations/2036745",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 2"
      }
    ],
    "description": "Flow Logs is a feature that enables users to capture information about the IP traffic going to and from network interfaces in the organization's VPC Subnets. Once a flow log is created, the user can view and retrieve its data in Stackdriver Logging. It is recommended that Flow Logs be enabled for every business-critical VPC subnet.",
    "rationale_statement": "VPC networks and subnetworks not reserved for internal HTTP(S) load balancing provide logically isolated and secure network partitions where GCP resources can be launched. When Flow Logs are enabled for a subnet, VMs within that subnet start reporting on all Transmission Control Protocol (TCP) and User Datagram Protocol (UDP) flows.\nEach VM samples the TCP and UDP flows it sees, inbound and outbound, whether the flow is to or from another VM, a host in the on-premises datacenter, a Google service, or a host on the Internet. If two GCP VMs are communicating, and both are in subnets that have VPC Flow Logs enabled, both VMs report the flows.\nFlow Logs supports the following use cases:\n\nNetwork monitoring\nUnderstanding network usage and optimizing network traffic expenses\nNetwork forensics\nReal-time security analysis\n\nFlow Logs provide visibility into network traffic for each VM inside the subnet and can be used to detect anomalous traffic or provide insight during security workflows.\nThe Flow Logs must be configured such that all network traffic is logged, the interval of logging is granular to provide detailed information on the connections, no logs are filtered, and metadata to facilitate investigations are included.\nNote: Subnets reserved for use by internal HTTP(S) load balancers do not support VPC flow logs.",
    "impact_statement": "Standard pricing for Stackdriver Logging, BigQuery, or Cloud Pub/Sub applies. VPC Flow Logs generation will be charged starting in GA as described in reference: https://cloud.google.com/vpc/",
    "audit_procedure": "From Google Cloud Console\n\n\nGo to the VPC network GCP Console visiting https://console.cloud.google.com/networking/networks/list\n\n\nFrom the list of network subnets, make sure for each subnet:\n\n\n\nFlow Logs is set to On\nAggregation Interval is set to 5 sec\nInclude metadata checkbox is checked\nSample rate is set to 100%\n\nNote: It is not possible to determine if a Log filter has been defined from the console.\nFrom Google Cloud CLI\ngcloud compute networks subnets list --format json | \\\n  jq -r '([\"Subnet\",\"Purpose\",\"Flow_Logs\",\"Aggregation_Interval\",\"Flow_Sampling\",\"Metadata\",\"Logs_Filtered\"] | (., map(length*\"-\"))), \n        (.[] | \n          [\n            .name, \n            .purpose,\n            (if has(\"enableFlowLogs\") and .enableFlowLogs == true then \"Enabled\" else \"Disabled\" end),\n            (if has(\"logConfig\") then .logConfig.aggregationInterval else \"N/A\" end),\n            (if has(\"logConfig\") then .logConfig.flowSampling else \"N/A\" end),\n            (if has(\"logConfig\") then .logConfig.metadata else \"N/A\" end),\n            (if has(\"logConfig\") then (.logConfig | has(\"filterExpr\")) else \"N/A\" end)\n          ]\n        ) | \n        @tsv' | \\\n  column -t\n\n\nThe output of the above command will list:\n\neach subnet\nthe subnet's purpose\na Enabled or Disabled value if Flow Logs are enabled\nthe value for Aggregation Interval or N/A if disabled, the value for Flow Sampling or N/A if disabled\nthe value for Metadata or N/A if disabled\n'true' or 'false' if a Logging Filter is configured or 'N/A' if disabled.\n\nIf the subnet's purpose is PRIVATE then Flow Logs should be Enabled.\nIf Flow Logs is enabled then:\n\nAggregation_Interval should be INTERVAL_5_SEC\nFlow_Sampling should be 1\nMetadata should be INCLUDE_ALL_METADATA\nLogs_Filtered should be false.",
    "remediation_procedure": "From Google Cloud Console\n\n\nGo to the VPC network GCP Console visiting https://console.cloud.google.com/networking/networks/list\n\n\nClick the name of a subnet, The Subnet details page displays.\n\n\nClick the EDIT button.\n\n\nSet Flow Logs to On.\n\n\nExpand the Configure Logs section.\n\n\nSet Aggregation Interval to 5 SEC.\n\n\nCheck the box beside Include metadata.\n\n\nSet Sample rate to 100.\n\n\nClick Save.\n\n\nNote: It is not possible to configure a Log filter from the console.\nFrom Google Cloud CLI\nTo enable VPC Flow Logs for a network subnet, run the following command:\ngcloud compute networks subnets update [SUBNET_NAME] --region [REGION] --enable-flow-logs --logging-aggregation-interval=interval-5-sec --logging-flow-sampling=1 --logging-metadata=include-all",
    "default_value": "By default, Flow Logs is set to Off when a new VPC network subnet is created."
  },
  {
    "control_id": "8.3",
    "control": "Ensure Adequate Audit Log Storage",
    "IG1": "o",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260471,
    "recommendation_id": 2036726,
    "view_level": "2.2",
    "title": "Ensure That Sinks Are Configured for All Log Entries",
    "pivot_control_id": 429,
    "pivot_recommendation_id": 2036726,
    "url": "https://workbench.cisecurity.org/sections/1260471/recommendations/2036726",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 1"
      }
    ],
    "description": "It is recommended to create a sink that will export copies of all the log entries. This can help aggregate logs from multiple projects and export them to a Security Information and Event Management (SIEM).",
    "rationale_statement": "Log entries are held in Cloud Logging. To aggregate logs, export them to a SIEM. To keep them longer, it is recommended to set up a log sink. Exporting involves writing a filter that selects the log entries to export, and choosing a destination in Cloud Storage, BigQuery, or Cloud Pub/Sub. The filter and destination are held in an object called a sink. To ensure all log entries are exported to sinks, ensure that there is no filter configured for a sink.\nSinks can be created in projects, organizations, folders, and billing accounts.",
    "impact_statement": "There are no costs or limitations in Cloud Logging for exporting logs, but the export destinations charge for storing or transmitting the log data.",
    "audit_procedure": "From Google Cloud Console\n\n\nGo to Logs Router by visiting https://console.cloud.google.com/logs/router.\n\n\nFor every sink, click the 3-dot button for Menu options and select View sink details.\n\n\nEnsure there is at least one sink with an empty Inclusion filter.\n\n\nAdditionally, ensure that the resource configured as Destination exists.\n\n\nFrom Google Cloud CLI\n\nEnsure that a sink with an empty filter exists. List the sinks for the project, folder or organization. If sinks are configured at a folder or organization level, they do not need to be configured for each project:\n\ngcloud logging sinks list --folder=FOLDER_ID | --organization=ORGANIZATION_ID | --project=PROJECT_ID\n\nThe output should list at least one sink with an empty filter.\n\nAdditionally, ensure that the resource configured as Destination exists.\n\nSee https://cloud.google.com/sdk/gcloud/reference/beta/logging/sinks/list for more information.",
    "remediation_procedure": "From Google Cloud Console\n\n\nGo to Logs Router by visiting https://console.cloud.google.com/logs/router.\n\n\nClick on the arrow symbol with CREATE SINK text.\n\n\nFill out the fields for Sink details.\n\n\nChoose Cloud Logging bucket in the Select sink destination drop down menu.\n\n\nChoose a log bucket in the next drop down menu.\n\n\nIf an inclusion filter is not provided for this sink, all ingested logs will be routed to the destination provided above. This may result in higher than expected resource usage.\n\n\nClick Create Sink.\n\n\nFor more information, see https://cloud.google.com/logging/docs/export/configure_export_v2#dest-create.\nFrom Google Cloud CLI\nTo create a sink to export all log entries in a Google Cloud Storage bucket:\ngcloud logging sinks create <sink-name> storage.googleapis.com/DESTINATION_BUCKET_NAME\n\nSinks can be created for a folder or organization, which will include all projects.\ngcloud logging sinks create <sink-name> storage.googleapis.com/DESTINATION_BUCKET_NAME --include-children --folder=FOLDER_ID | --organization=ORGANIZATION_ID\n\nNote:\n\n\nA sink created by the command-line above will export logs in storage buckets. However, sinks can be configured to export logs into BigQuery, or Cloud Pub/Sub, or Custom Destination.\n\n\nWhile creating a sink, the sink option --log-filter is not used to ensure the sink exports all log entries.\n\n\nA sink can be created at a folder or organization level that collects the logs of all the projects underneath bypassing the option --include-children in the gcloud command.",
    "default_value": "By default, there are no sinks configured."
  },
  {
    "control_id": "8.5",
    "control": "Collect Detailed Audit Logs",
    "IG1": "-",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260471,
    "recommendation_id": 2036731,
    "view_level": "2.5",
    "title": "Ensure That the Log Metric Filter and Alerts Exist for Audit Configuration Changes",
    "pivot_control_id": 431,
    "pivot_recommendation_id": 2036731,
    "url": "https://workbench.cisecurity.org/sections/1260471/recommendations/2036731",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 1"
      }
    ],
    "description": "Google Cloud Platform (GCP) services write audit log entries to the Admin Activity and Data Access logs to help answer the questions of, \"who did what, where, and when?\" within GCP projects.\nCloud audit logging records information includes the identity of the API caller, the time of the API call, the source IP address of the API caller, the request parameters, and the response elements returned by GCP services. Cloud audit logging provides a history of GCP API calls for an account, including API calls made via the console, SDKs, command-line tools, and other GCP services.",
    "rationale_statement": "Admin activity and data access logs produced by cloud audit logging enable security analysis, resource change tracking, and compliance auditing.\nConfiguring the metric filter and alerts for audit configuration changes ensures the recommended state of audit configuration is maintained so that all activities in the project are audit-able at any point in time.",
    "impact_statement": "Enabling of logging may result in your project being charged for the additional logs usage.",
    "audit_procedure": "From Google Cloud Console\nEnsure the prescribed log metric is present:\n\n\nGo to Logging/Logs-based Metrics by visiting https://console.cloud.google.com/logs/metrics.\n\n\nIn the User-defined Metrics section, ensure that at least one metric <Log_Metric_Name> is present with the filter text:\n\n\nprotoPayload.methodName=\"SetIamPolicy\" AND\nprotoPayload.serviceData.policyDelta.auditConfigDeltas:*\n\nEnsure that the prescribed alerting policy is present:\n\n\nGo to Alerting by visiting https://console.cloud.google.com/monitoring/alerting.\n\n\nUnder the Policies section, ensure that at least one alert policy exists for the log metric above. Clicking on the policy should show that it is configured with a condition. For example, Violates when: Any logging.googleapis.com/user/<Log Metric Name> stream is above a threshold of 0 for greater than zero(0) seconds, means that the alert will trigger for any new owner change. Verify that the chosen alerting thresholds make sense for the user's organization.\n\n\nEnsure that appropriate notifications channels have been set up.\n\n\nFrom Google Cloud CLI\nEnsure that the prescribed log metric is present:\n\nList the log metrics:\n\ngcloud beta logging metrics list --format json\n\n\nEnsure that the output contains at least one metric with the filter set to:\n\nprotoPayload.methodName=\"SetIamPolicy\" AND\nprotoPayload.serviceData.policyDelta.auditConfigDeltas:*\n\n\nNote the value of the property metricDescriptor.type for the identified metric, in the format logging.googleapis.com/user/<Log Metric Name>.\n\nEnsure that the prescribed alerting policy is present:\n\nList the alerting policies:\n\ngcloud alpha monitoring policies list --format json\n\n\nEnsure that the output contains at least one alert policy where:\n\n\nconditions.conditionThreshold.filter is set to metric.type=\\\"logging.googleapis.com/user/<Log Metric Name>\\\"\nAND enabled is set to true",
    "remediation_procedure": "From Google Cloud Console\nCreate the prescribed log metric:\n\n\nGo to Logging/Logs-based Metrics by visiting https://console.cloud.google.com/logs/metrics and click \"CREATE METRIC\".\n\n\nClick the down arrow symbol on the Filter Bar at the rightmost corner and select Convert to Advanced Filter.\n\n\nClear any text and add:\n\n\nprotoPayload.methodName=\"SetIamPolicy\" AND\nprotoPayload.serviceData.policyDelta.auditConfigDeltas:*\n\n\n\nClick Submit Filter. Display logs appear based on the filter text entered by the user.\n\n\nIn the Metric Editor menu on the right, fill out the name field. Set Units to 1 (default) and Type to Counter. This will ensure that the log metric counts the number of log entries matching the user's advanced logs query.\n\n\nClick Create Metric.\n\n\nCreate a prescribed Alert Policy:\n\n\nIdentify the new metric the user just created, under the section User-defined Metrics at https://console.cloud.google.com/logs/metrics.\n\n\nClick the 3-dot icon in the rightmost column for the new metric and select Create alert from Metric. A new page opens.\n\n\nFill out the alert policy configuration and click Save. Choose the alerting threshold and configuration that makes sense for the organization. For example, a threshold of zero(0) for the most recent value will ensure that a notification is triggered for every owner change in the project:\n\n\nSet `Aggregator` to `Count`\n\nSet `Configuration`:\n\n- Condition: above\n\n- Threshold: 0\n\n- For: most recent value\n\n\n\nConfigure the desired notifications channels in the section Notifications.\n\n\nName the policy and click Save.\n\n\nFrom Google Cloud CLI\nCreate a prescribed Log Metric:\n\nUse the command: gcloud beta logging metrics create\nReference for command usage: https://cloud.google.com/sdk/gcloud/reference/beta/logging/metrics/create\n\nCreate prescribed Alert Policy\nUse the command: gcloud alpha monitoring policies create\nReference for command usage: https://cloud.google.com/sdk/gcloud/reference/alpha/monitoring/policies/create",
    "default_value": ""
  },
  {
    "control_id": "8.5",
    "control": "Collect Detailed Audit Logs",
    "IG1": "-",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260471,
    "recommendation_id": 2036733,
    "view_level": "2.6",
    "title": "Ensure That the Log Metric Filter and Alerts Exist for Custom Role Changes",
    "pivot_control_id": 431,
    "pivot_recommendation_id": 2036733,
    "url": "https://workbench.cisecurity.org/sections/1260471/recommendations/2036733",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 1"
      }
    ],
    "description": "It is recommended that a metric filter and alarm be established for changes to Identity and Access Management (IAM) role creation, deletion and updating activities.",
    "rationale_statement": "Google Cloud IAM provides predefined roles that give granular access to specific Google Cloud Platform resources and prevent unwanted access to other resources. However, to cater to organization-specific needs, Cloud IAM also provides the ability to create custom roles. Project owners and administrators with the Organization Role Administrator role or the IAM Role Administrator role can create custom roles.\nMonitoring role creation, deletion and updating activities will help in identifying any over-privileged role at early stages.",
    "impact_statement": "Enabling of logging may result in your project being charged for the additional logs usage.",
    "audit_procedure": "From Console:\nEnsure that the prescribed log metric is present:\n\n\nGo to Logging/Logs-based Metrics by visiting https://console.cloud.google.com/logs/metrics.\n\n\nIn the User-defined Metrics section, ensure that at least one metric <Log_Metric_Name> is present with filter text:\n\n\nresource.type=\"iam_role\" \nAND (protoPayload.methodName=\"google.iam.admin.v1.CreateRole\" \nOR protoPayload.methodName=\"google.iam.admin.v1.DeleteRole\" \nOR protoPayload.methodName=\"google.iam.admin.v1.UpdateRole\")\n\nEnsure that the prescribed alerting policy is present:\n\n\nGo to Alerting by visiting https://console.cloud.google.com/monitoring/alerting.\n\n\nUnder the Policies section, ensure that at least one alert policy exists for the log metric above. Clicking on the policy should show that it is configured with a condition. For example, Violates when: Any logging.googleapis.com/user/<Log Metric Name> stream is above a threshold of zero(0) for greater than zero(0) seconds means that the alert will trigger for any new owner change. Verify that the chosen alerting thresholds make sense for the user's organization.\n\n\nEnsure that the appropriate notifications channels have been set up.\n\n\nFrom Google Cloud CLI\nEnsure that the prescribed log metric is present:\n\nList the log metrics:\n\ngcloud logging metrics list --format json\n\n\nEnsure that the output contains at least one metric with the filter set to:\n\nresource.type=\"iam_role\"\nAND (protoPayload.methodName = \"google.iam.admin.v1.CreateRole\" OR\nprotoPayload.methodName=\"google.iam.admin.v1.DeleteRole\" OR\nprotoPayload.methodName=\"google.iam.admin.v1.UpdateRole\")\n\n\nNote the value of the property metricDescriptor.type for the identified metric, in the format logging.googleapis.com/user/<Log Metric Name>.\n\nEnsure that the prescribed alerting policy is present:\n\nList the alerting policies:\n\ngcloud alpha monitoring policies list --format json\n\n\nEnsure that the output contains an least one alert policy where:\n\n\nconditions.conditionThreshold.filter is set to metric.type=\\\"logging.googleapis.com/user/<Log Metric Name>\\\"\nAND enabled is set to true.",
    "remediation_procedure": "From Console:\nCreate the prescribed log metric:\n\n\nGo to Logging/Logs-based Metrics by visiting https://console.cloud.google.com/logs/metrics and click \"CREATE METRIC\".\n\n\nClick the down arrow symbol on the  Filter Bar at the rightmost corner and select Convert to Advanced Filter.\n\n\nClear any text and add:\n\n\nresource.type=\"iam_role\" \nAND (protoPayload.methodName =  \"google.iam.admin.v1.CreateRole\" \nOR protoPayload.methodName=\"google.iam.admin.v1.DeleteRole\" \nOR protoPayload.methodName=\"google.iam.admin.v1.UpdateRole\")\n\n\n\nClick Submit Filter. Display logs appear based on the filter text entered by the user.\n\n\nIn the Metric Editor menu on the right, fill out the name field. Set Units to 1 (default) and Type to Counter. This ensures that the log metric counts the number of log entries matching the advanced logs query.\n\n\nClick Create Metric.\n\n\nCreate a prescribed Alert Policy:\n\n\nIdentify the new metric that was just created under the section User-defined Metrics at https://console.cloud.google.com/logs/metrics.\n\n\nClick the 3-dot icon in the rightmost column for the metric and select Create alert from Metric. A new page displays.\n\n\nFill out the alert policy configuration and click Save. Choose the alerting threshold and configuration that makes sense for the user's organization. For example, a threshold of zero(0) for the most recent value ensures that a notification is triggered for every owner change in the project:\n\n\nSet `Aggregator` to `Count`\n\nSet `Configuration`:\n\n- Condition: above\n\n- Threshold: 0\n\n- For: most recent value\n\n\n\nConfigure the desired notification channels in the section Notifications.\n\n\nName the policy and click Save.\n\n\nFrom Google Cloud CLI\nCreate the prescribed Log Metric:\n\nUse the command: gcloud logging metrics create\n\nCreate the prescribed Alert Policy:\n\nUse the command: gcloud alpha monitoring policies create",
    "default_value": ""
  },
  {
    "control_id": "8.5",
    "control": "Collect Detailed Audit Logs",
    "IG1": "-",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260471,
    "recommendation_id": 2036735,
    "view_level": "2.7",
    "title": "Ensure That the Log Metric Filter and Alerts Exist for VPC Network Firewall Rule Changes",
    "pivot_control_id": 431,
    "pivot_recommendation_id": 2036735,
    "url": "https://workbench.cisecurity.org/sections/1260471/recommendations/2036735",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 2"
      }
    ],
    "description": "It is recommended that a metric filter and alarm be established for Virtual Private Cloud (VPC) Network Firewall rule changes.",
    "rationale_statement": "Monitoring for Create or Update Firewall rule events gives insight to network access changes and may reduce the time it takes to detect suspicious activity.",
    "impact_statement": "Enabling of logging may result in your project being charged for the additional logs usage. These charges could be significant depending on the size of the organization.",
    "audit_procedure": "From Google Cloud Console\nEnsure that the prescribed log metric is present:\n\n\nGo to Logging/Logs-based Metrics by visiting https://console.cloud.google.com/logs/metrics.\n\n\nIn the User-defined Metrics section, ensure at least one metric <Log_Metric_Name> is present with this filter text:\n\n\nresource.type=\"gce_firewall_rule\" \nAND (protoPayload.methodName:\"compute.firewalls.patch\" \nOR protoPayload.methodName:\"compute.firewalls.insert\"\nOR protoPayload.methodName:\"compute.firewalls.delete\")\n\nEnsure that the prescribed alerting policy is present:\n\n\nGo to Alerting by visiting https://console.cloud.google.com/monitoring/alerting.\n\n\nUnder the Policies section, ensure that at least one alert policy exists for the log metric above. Clicking on the policy should show that it is configured with a condition. For example, Violates when: Any logging.googleapis.com/user/<Log Metric Name> stream is above a threshold of zero(0) for greater than zero(0) seconds means that the alert will trigger for any new owner change. Verify that the chosen alerting thresholds make sense for the user's organization.\n\n\nEnsure that appropriate notification channels have been set up.\n\n\nFrom Google Cloud CLI\nEnsure that the prescribed log metric is present:\n\nList the log metrics:\n\ngcloud logging metrics list --format json\n\n\nEnsure that the output contains at least one metric with the filter set to:\n\nresource.type=\"gce_firewall_rule\" \nAND (protoPayload.methodName:\"compute.firewalls.patch\" \nOR protoPayload.methodName:\"compute.firewalls.insert\"\nOR protoPayload.methodName:\"compute.firewalls.delete\")\n\n\nNote the value of the property metricDescriptor.type for the identified metric, in the format logging.googleapis.com/user/<Log Metric Name>.\n\nEnsure that the prescribed alerting policy is present:\n\nList the alerting policies:\n\ngcloud alpha monitoring policies list --format json\n\n\nEnsure that the output contains an least one alert policy where:\n\n\nconditions.conditionThreshold.filter is set to metric.type=\\\"logging.googleapis.com/user/<Log Metric Name>\\\"\nAND enabled is set to true",
    "remediation_procedure": "From Google Cloud Console\nCreate the prescribed log metric:\n\n\nGo to Logging/Logs-based Metrics by visiting https://console.cloud.google.com/logs/metrics and click \"CREATE METRIC\".\n\n\nClick the down arrow symbol on the Filter Bar at the rightmost corner and select Convert to Advanced Filter.\n\n\nClear any text and add:\n\n\nresource.type=\"gce_firewall_rule\" \nAND (protoPayload.methodName:\"compute.firewalls.patch\" \nOR protoPayload.methodName:\"compute.firewalls.insert\"\nOR protoPayload.methodName:\"compute.firewalls.delete\")\n\n\n\nClick Submit Filter. Display logs appear based on the filter text entered by the user.\n\n\nIn the Metric Editor menu on the right, fill out the name field. Set Units to 1 (default) and Type to Counter. This ensures that the log metric counts the number of log entries matching the advanced logs query.\n\n\nClick Create Metric.\n\n\nCreate the prescribed Alert Policy:\n\n\nIdentify the newly created metric under the section User-defined Metrics at https://console.cloud.google.com/logs/metrics.\n\n\nClick the 3-dot icon in the rightmost column for the new metric and select Create alert from Metric. A new page displays.\n\n\nFill out the alert policy configuration and click Save. Choose the alerting threshold and configuration that makes sense for the user's organization. For example, a threshold of zero(0) for the most recent value ensures that a notification is triggered for every owner change in the project:\n\n\nSet `Aggregator` to `Count`\n\nSet `Configuration`:\n\n- Condition: above\n\n- Threshold: 0\n\n- For: most recent value\n\n\n\nConfigure the desired notifications channels in the section Notifications.\n\n\nName the policy and click Save.\n\n\nFrom Google Cloud CLI\nCreate the prescribed Log Metric\n\nUse the command: gcloud logging metrics create\n\nCreate the prescribed alert policy:\n\nUse the command: gcloud alpha monitoring policies create",
    "default_value": ""
  },
  {
    "control_id": "8.5",
    "control": "Collect Detailed Audit Logs",
    "IG1": "-",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260471,
    "recommendation_id": 2036737,
    "view_level": "2.8",
    "title": "Ensure That the Log Metric Filter and Alerts Exist for VPC Network Route Changes",
    "pivot_control_id": 431,
    "pivot_recommendation_id": 2036737,
    "url": "https://workbench.cisecurity.org/sections/1260471/recommendations/2036737",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 2"
      }
    ],
    "description": "It is recommended that a metric filter and alarm be established for Virtual Private Cloud (VPC) network route changes.",
    "rationale_statement": "Google Cloud Platform (GCP) routes define the paths network traffic takes from a VM instance to another destination. The other destination can be inside the organization VPC network (such as another VM) or outside of it. Every route consists of a destination and a next hop. Traffic whose destination IP is within the destination range is sent to the next hop for delivery.\nMonitoring changes to route tables will help ensure that all VPC traffic flows through an expected path.",
    "impact_statement": "Enabling of logging may result in your project being charged for the additional logs usage. These charges could be significant depending on the size of the organization.",
    "audit_procedure": "From Google Cloud Console\nEnsure that the prescribed Log metric is present:\n\n\nGo to Logging/Logs-based Metrics by visiting https://console.cloud.google.com/logs/metrics.\n\n\nIn the User-defined Metrics section, ensure that at least one metric <Log_Metric_Name> is present with the filter text:\n\n\nresource.type=\"gce_route\" \nAND (protoPayload.methodName:\"compute.routes.delete\" \nOR protoPayload.methodName:\"compute.routes.insert\")\n\nEnsure the prescribed alerting policy is present:\n\n\nGo to Alerting by visiting: https://console.cloud.google.com/monitoring/alerting.\n\n\nUnder the Policies section, ensure that at least one alert policy exists for the log metric above. Clicking on the policy should show that it is configured with a condition. For example, Violates when: Any logging.googleapis.com/user/<Log Metric Name> stream is above a threshold of 0 for greater than zero(0) seconds means that the alert will trigger for any new owner change. Verify that the chosen alert thresholds make sense for the user's organization.\n\n\nEnsure that the appropriate notification channels have been set up.\n\n\nFrom Google Cloud CLI\nEnsure the prescribed log metric is present:\n\nList the log metrics:\n\ngcloud logging metrics list --format json\n\n\nEnsure that the output contains at least one metric with the filter set to:\n\nresource.type=\"gce_route\" \nAND (protoPayload.methodName:\"compute.routes.delete\" \nOR protoPayload.methodName:\"compute.routes.insert\")\n\n\nNote the value of the property metricDescriptor.type for the identified metric, in the format logging.googleapis.com/user/<Log Metric Name>.\n\nEnsure that the prescribed alerting policy is present:\n\nList the alerting policies:\n\ngcloud alpha monitoring policies list --format json\n\n\nEnsure that the output contains an least one alert policy where:\n\n\nconditions.conditionThreshold.filter is set to metric.type=\\\"logging.googleapis.com/user/<Log Metric Name>\\\"\nAND enabled is set to true",
    "remediation_procedure": "From Google Cloud Console\nCreate the prescribed Log Metric:\n\n\nGo to Logging/Logs-based Metrics by visiting https://console.cloud.google.com/logs/metrics and click \"CREATE METRIC\".\n\n\nClick the down arrow symbol on the Filter Bar at the rightmost corner and select Convert to Advanced Filter\n\n\nClear any text and add:\n\n\nresource.type=\"gce_route\" \nAND (protoPayload.methodName:\"compute.routes.delete\" \nOR protoPayload.methodName:\"compute.routes.insert\")\n\n\n\nClick Submit Filter. Display logs appear based on the filter text entered by the user.\n\n\nIn the Metric Editor menu on the right, fill out the name field. Set Units to 1 (default) and Type to Counter. This ensures that the log metric counts the number of log entries matching the user's advanced logs query.\n\n\nClick Create Metric.\n\n\nCreate the prescribed alert policy:\n\n\nIdentify the newly created metric under the section User-defined Metrics at https://console.cloud.google.com/logs/metrics.\n\n\nClick the 3-dot icon in the rightmost column for the new metric and select Create alert from Metric. A new page displays.\n\n\nFill out the alert policy configuration and click Save. Choose the alerting threshold and configuration that makes sense for the user's organization. For example, a threshold of zero(0) for the most recent value ensures that a notification is triggered for every owner change in the project:\n\n\nSet `Aggregator` to `Count`\n\nSet `Configuration`:\n\n- Condition: above\n\n- Threshold: 0\n\n- For: most recent value\n\n\n\nConfigure the desired notification channels in the section Notifications.\n\n\nName the policy and click Save.\n\n\nFrom Google Cloud CLI\nCreate the prescribed Log Metric:\n\nUse the command: gcloud logging metrics create\n\nCreate the prescribed the alert policy:\n\nUse the command: gcloud alpha monitoring policies create",
    "default_value": ""
  },
  {
    "control_id": "8.5",
    "control": "Collect Detailed Audit Logs",
    "IG1": "-",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260471,
    "recommendation_id": 2036740,
    "view_level": "2.9",
    "title": "Ensure That the Log Metric Filter and Alerts Exist for VPC Network Changes",
    "pivot_control_id": 431,
    "pivot_recommendation_id": 2036740,
    "url": "https://workbench.cisecurity.org/sections/1260471/recommendations/2036740",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 2"
      }
    ],
    "description": "It is recommended that a metric filter and alarm be established for Virtual Private Cloud (VPC) network changes.",
    "rationale_statement": "It is possible to have more than one VPC within a project. In addition, it is also possible to create a peer connection between two VPCs enabling network traffic to route between VPCs.\nMonitoring changes to a VPC will help ensure VPC traffic flow is not getting impacted.",
    "impact_statement": "Enabling of logging may result in your project being charged for the additional logs usage. These charges could be significant depending on the size of the organization.",
    "audit_procedure": "From Google Cloud Console\nEnsure the prescribed log metric is present:\n\n\nGo to Logging/Logs-based Metrics by visiting https://console.cloud.google.com/logs/metrics.\n\n\nIn the User-defined Metrics section, ensure at least one metric <Log_Metric_Name> is present with filter text:\n\n\nresource.type=\"gce_network\" \nAND (protoPayload.methodName:\"compute.networks.insert\" \nOR protoPayload.methodName:\"compute.networks.patch\" \nOR protoPayload.methodName:\"compute.networks.delete\" \nOR protoPayload.methodName:\"compute.networks.removePeering\" \nOR protoPayload.methodName:\"compute.networks.addPeering\")\n\nEnsure the prescribed alerting policy is present:\n\n\nGo to Alerting by visiting https://console.cloud.google.com/monitoring/alerting.\n\n\nUnder the Policies section, ensure that at least one alert policy exists for the log metric above. Clicking on the policy should show that it is configured with a condition. For example, Violates when: Any logging.googleapis.com/user/<Log Metric Name> stream is above a threshold of 0 for greater than 0 seconds means that the alert will trigger for any new owner change. Verify that the chosen alerting thresholds make sense for the user's organization.\n\n\nEnsure that appropriate notification channels have been set up.\n\n\nFrom Google Cloud CLI\nEnsure the log metric is present:\n\nList the log metrics:\n\ngcloud logging metrics list --format json\n\n\nEnsure that the output contains at least one metric with filter set to:\n\nresource.type=\"gce_network\" \nAND protoPayload.methodName=\"beta.compute.networks.insert\" \nOR protoPayload.methodName=\"beta.compute.networks.patch\" \nOR protoPayload.methodName=\"v1.compute.networks.delete\"  \nOR protoPayload.methodName=\"v1.compute.networks.removePeering\" \nOR protoPayload.methodName=\"v1.compute.networks.addPeering\"\n\n\nNote the value of the property metricDescriptor.type for the identified metric, in the format logging.googleapis.com/user/<Log Metric Name>.\n\nEnsure the prescribed alerting policy is present:\n\nList the alerting policies:\n\ngcloud alpha monitoring policies list --format json\n\n\nEnsure that the output contains at least one alert policy where:\n\n\nconditions.conditionThreshold.filter is set to metric.type=\\\"logging.googleapis.com/user/<Log Metric Name>\\\"\nAND enabled is set to true",
    "remediation_procedure": "From Google Cloud Console\nCreate the prescribed log metric:\n\n\nGo to Logging/Logs-based Metrics by visiting https://console.cloud.google.com/logs/metrics and click \"CREATE METRIC\".\n\n\nClick the down arrow symbol on Filter Bar at the rightmost corner and select Convert to Advanced Filter.\n\n\nClear any text and add:\n\n\nresource.type=\"gce_network\" \nAND (protoPayload.methodName:\"compute.networks.insert\" \nOR protoPayload.methodName:\"compute.networks.patch\" \nOR protoPayload.methodName:\"compute.networks.delete\" \nOR protoPayload.methodName:\"compute.networks.removePeering\" \nOR protoPayload.methodName:\"compute.networks.addPeering\")\n\n\n\nClick Submit Filter. Display logs appear based on the filter text entered by the user.\n\n\nIn the Metric Editor menu on the right, fill out the name field. Set Units to 1 (default) and Type to Counter. This ensures that the log metric counts the number of log entries matching the user's advanced logs query.\n\n\nClick Create Metric.\n\n\nCreate the prescribed alert policy:\n\n\nIdentify the newly created metric under the section User-defined Metrics at https://console.cloud.google.com/logs/metrics.\n\n\nClick the 3-dot icon in the rightmost column for the new metric and select Create alert from Metric. A new page appears.\n\n\nFill out the alert policy configuration and click Save. Choose the alerting threshold and configuration that makes sense for the user's organization. For example, a threshold of 0 for the most recent value will ensure that a notification is triggered for every owner change in the project:\n\n\nSet `Aggregator` to `Count`\n\nSet `Configuration`:\n\n- Condition: above\n\n- Threshold: 0\n\n- For: most recent value\n\n\n\nConfigure the desired notification channels in the section Notifications.\n\n\nName the policy and click Save.\n\n\nFrom Google Cloud CLI\nCreate the prescribed Log Metric:\n\nUse the command: gcloud logging metrics create\n\nCreate the prescribed alert policy:\n\nUse the command: gcloud alpha monitoring policies create",
    "default_value": ""
  },
  {
    "control_id": "8.5",
    "control": "Collect Detailed Audit Logs",
    "IG1": "-",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260471,
    "recommendation_id": 2036742,
    "view_level": "2.10",
    "title": "Ensure That the Log Metric Filter and Alerts Exist for Cloud Storage IAM Permission Changes",
    "pivot_control_id": 431,
    "pivot_recommendation_id": 2036742,
    "url": "https://workbench.cisecurity.org/sections/1260471/recommendations/2036742",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 2"
      }
    ],
    "description": "It is recommended that a metric filter and alarm be established for Cloud Storage Bucket IAM changes.",
    "rationale_statement": "Monitoring changes to cloud storage bucket permissions may reduce the time needed to detect and correct permissions on sensitive cloud storage buckets and objects inside the bucket.",
    "impact_statement": "Enabling of logging may result in your project being charged for the additional logs usage. These charges could be significant depending on the size of the organization.",
    "audit_procedure": "From Google Cloud Console\nEnsure the prescribed log metric is present:\n\n\nFor each project that contains cloud storage buckets, go to Logging/Logs-based Metrics by visiting https://console.cloud.google.com/logs/metrics.\n\n\nIn the User-defined Metrics section, ensure at least one metric <Log_Metric_Name> is present with the filter text:\n\n\nresource.type=\"gcs_bucket\"\nAND protoPayload.methodName=\"storage.setIamPermissions\"\n\nEnsure that the prescribed alerting policy is present:\n\n\nGo to Alerting by visiting https://console.cloud.google.com/monitoring/alerting.\n\n\nUnder the Policies section, ensure that at least one alert policy exists for the log metric above. Clicking on the policy should show that it is configured with a condition. For example, Violates when: Any logging.googleapis.com/user/<Log Metric Name> stream is above a threshold of 0 for greater than 0 seconds means that the alert will trigger for any new owner change. Verify that the chosen alerting thresholds make sense for the user's organization.\n\n\nEnsure that the appropriate notifications channels have been set up.\n\n\nFrom Google Cloud CLI\nEnsure that the prescribed log metric is present:\n\nList the log metrics:\n\ngcloud logging metrics list --format json\n\n\nEnsure that the output contains at least one metric with the filter set to:\n\nresource.type=gcs_bucket \nAND protoPayload.methodName=\"storage.setIamPermissions\"\n\n\nNote the value of the property metricDescriptor.type for the identified metric, in the format logging.googleapis.com/user/<Log Metric Name>.\n\nEnsure the prescribed alerting policy is present:\n\nList the alerting policies:\n\ngcloud alpha monitoring policies list --format json\n\n\nEnsure that the output contains an least one alert policy where:\n\n\nconditions.conditionThreshold.filter is set to metric.type=\\\"logging.googleapis.com/user/<Log Metric Name>\\\"\nAND enabled is set to true",
    "remediation_procedure": "From Google Cloud Console\nCreate the prescribed log metric:\n\n\nGo to Logging/Logs-based Metrics by visiting https://console.cloud.google.com/logs/metrics and click \"CREATE METRIC\".\n\n\nClick the down arrow symbol on the Filter Bar at the rightmost corner and select Convert to Advanced Filter.\n\n\nClear any text and add:\n\n\nresource.type=\"gcs_bucket\" \nAND protoPayload.methodName=\"storage.setIamPermissions\"\n\n\n\nClick Submit Filter. Display logs appear based on the filter text entered by the user.\n\n\nIn the Metric Editor menu on right, fill out the name field. Set Units to 1 (default) and Type to Counter. This ensures that the log metric counts the number of log entries matching the user's advanced logs query.\n\n\nClick Create Metric.\n\n\nCreate the prescribed Alert Policy:\n\n\nIdentify the newly created metric under the section User-defined Metrics at https://console.cloud.google.com/logs/metrics.\n\n\nClick the 3-dot icon in the rightmost column for the new metric and select Create alert from Metric. A new page appears.\n\n\nFill out the alert policy configuration and click Save. Choose the alerting threshold and configuration that makes sense for the user's organization. For example, a threshold of zero(0) for the most recent value will ensure that a notification is triggered for every owner change in the project:\n\n\nSet `Aggregator` to `Count`\n\nSet `Configuration`:\n\n- Condition: above\n\n- Threshold: 0\n\n- For: most recent value\n\n\n\nConfigure the desired notifications channels in the section Notifications.\n\n\nName the policy and click Save.\n\n\nFrom Google Cloud CLI\nCreate the prescribed Log Metric:\n\nUse the command: gcloud beta logging metrics create\n\nCreate the prescribed alert policy:\n\nUse the command: gcloud alpha monitoring policies create",
    "default_value": ""
  },
  {
    "control_id": "8.5",
    "control": "Collect Detailed Audit Logs",
    "IG1": "-",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260471,
    "recommendation_id": 2036744,
    "view_level": "2.11",
    "title": "Ensure That the Log Metric Filter and Alerts Exist for SQL Instance Configuration Changes",
    "pivot_control_id": 431,
    "pivot_recommendation_id": 2036744,
    "url": "https://workbench.cisecurity.org/sections/1260471/recommendations/2036744",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 2"
      }
    ],
    "description": "It is recommended that a metric filter and alarm be established for SQL instance configuration changes.",
    "rationale_statement": "Monitoring changes to SQL instance configuration changes may reduce the time needed to detect and correct misconfigurations done on the SQL server.\nBelow are a few of the configurable options which may the impact security posture of an SQL instance:\n\n\nEnable auto backups and high availability: Misconfiguration may adversely impact business continuity, disaster recovery, and high availability\n\n\nAuthorize networks: Misconfiguration may increase exposure to untrusted networks",
    "impact_statement": "Enabling of logging may result in your project being charged for the additional logs usage. These charges could be significant depending on the size of the organization.",
    "audit_procedure": "From Google Cloud Console\nEnsure the prescribed log metric is present:\n\n\nFor each project that contains Cloud SQL instances, go to Logging/Logs-based Metrics by visiting https://console.cloud.google.com/logs/metrics.\n\n\nIn the User-defined Metrics section, ensure that at least one metric <Log_Metric_Name> is present with the filter text:\n\n\nprotoPayload.methodName=\"cloudsql.instances.update\"\n\nEnsure that the prescribed alerting policy is present:\n\n\nGo to Alerting by visiting https://console.cloud.google.com/monitoring/alerting.\n\n\nUnder the Policies section, ensure that at least one alert policy exists for the log metric above. Clicking on the policy should show that it is configured with a condition. For example, Violates when: Any logging.googleapis.com/user/<Log Metric Name> stream is above a threshold of zero(0) for greater than zero(0) seconds means that the alert will trigger for any new owner change. Verify that the chosen alerting thresholds make sense for the user's organization.\n\n\nEnsure that the appropriate notifications channels have been set up.\n\n\nFrom Google Cloud CLI\nEnsure that the prescribed log metric is present:\n\nList the log metrics:\n\ngcloud logging metrics list --format json\n\n\nEnsure that the output contains at least one metric with the filter set to\n\nprotoPayload.methodName=\"cloudsql.instances.update\"\n\n\nNote the value of the property metricDescriptor.type for the identified metric, in the format logging.googleapis.com/user/<Log Metric Name>.\n\nEnsure that the prescribed alerting policy is present:\n\nList the alerting policies:\n\ngcloud alpha monitoring policies list --format json\n\n\nEnsure that the output contains at least one alert policy where:\n\n\nconditions.conditionThreshold.filter is set to metric.type=\\\"logging.googleapis.com/user/<Log Metric Name>\\\"\nAND enabled is set to true",
    "remediation_procedure": "From Google Cloud Console\nCreate the prescribed Log Metric:\n\n\nGo to Logging/Logs-based Metrics by visiting https://console.cloud.google.com/logs/metrics and click \"CREATE METRIC\".\n\n\nClick the down arrow symbol on the Filter Bar at the rightmost corner and select Convert to Advanced Filter.\n\n\nClear any text and add:\n\n\nprotoPayload.methodName=\"cloudsql.instances.update\"\n\n\n\nClick Submit Filter. Display logs appear based on the filter text entered by the user.\n\n\nIn the Metric Editor menu on right, fill out the name field. Set Units to 1 (default) and Type to Counter. This ensures that the log metric counts the number of log entries matching the user's advanced logs query.\n\n\nClick Create Metric.\n\n\nCreate the prescribed alert policy:\n\n\nIdentify the newly created metric under the section User-defined Metrics at https://console.cloud.google.com/logs/metrics.\n\n\nClick the 3-dot icon in the rightmost column for the new metric and select Create alert from Metric. A new page appears.\n\n\nFill out the alert policy configuration and click Save. Choose the alerting threshold and configuration that makes sense for the user's organization. For example, a threshold of zero(0) for the most recent value will ensure that a notification is triggered for every owner change in the user's project:\n\n\nSet `Aggregator` to `Count`\n\nSet `Configuration`:\n\n- Condition: above\n\n- Threshold: 0\n\n- For: most recent value\n\n\n\nConfigure the desired notification channels in the section Notifications.\n\n\nName the policy and click Save.\n\n\nFrom Google Cloud CLI\nCreate the prescribed log metric:\n\nUse the command: gcloud logging metrics create\n\nCreate the prescribed alert policy:\n\nUse the command: gcloud alpha monitoring policies create\nReference for command usage: https://cloud.google.com/sdk/gcloud/reference/alpha/monitoring/policies/create",
    "default_value": ""
  },
  {
    "control_id": "8.5",
    "control": "Collect Detailed Audit Logs",
    "IG1": "-",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260471,
    "recommendation_id": 2036750,
    "view_level": "2.14",
    "title": "Ensure 'Access Transparency' is 'Enabled'",
    "pivot_control_id": 431,
    "pivot_recommendation_id": 2036750,
    "url": "https://workbench.cisecurity.org/sections/1260471/recommendations/2036750",
    "assessment_status": "Manual",
    "applicable_profiles": [
      {
        "title": "Level 2"
      }
    ],
    "description": "GCP Access Transparency provides audit logs for all actions that Google personnel take in your Google Cloud resources.",
    "rationale_statement": "Controlling access to your information is one of the foundations of information security. Given that Google Employees do have access to your organizations' projects for support reasons, you should have logging in place to view who, when, and why your information is being accessed.",
    "impact_statement": "To use Access Transparency your organization will need to have at one of the following support level: Premium, Enterprise, Platinum, or Gold. There will be subscription costs associated with support, as well as increased storage costs for storing the logs. You will also not be able to turn Access Transparency off yourself, and you will need to submit a service request to Google Cloud Support.",
    "audit_procedure": "From Google Cloud Console\nDetermine if Access Transparency is Enabled\n\n\nFrom the Google Cloud Home, click on the Navigation hamburger menu in the top left. Hover over the IAM & Admin Menu. Select settings in the middle of the column that opens.\n\n\nThe status will be under the heading Access Transparency. Status should be Enabled",
    "remediation_procedure": "From Google Cloud Console\nAdd privileges to enable Access Transparency\n\n\nFrom the Google Cloud Home, within the project you wish to check, click on the Navigation hamburger menu in the top left. Hover over the 'IAM and Admin'. Select IAM in the top of the column that opens.\n\n\nClick the blue button the says +add at the top of the screen.\n\n\nIn the principals field, select a user or group by typing in their associated email address.\n\n\nClick on the role field to expand it. In the filter field enter Access Transparency Admin and select it.\n\n\nClick save.\n\n\nVerify that the Google Cloud project is associated with a billing account\n\n\nFrom the Google Cloud Home, click on the Navigation hamburger menu in the top left. Select Billing.\n\n\nIf you see This project is not associated with a billing account you will need to enter billing information or switch to a project with a billing account.\n\n\nEnable Access Transparency\n\n\nFrom the Google Cloud Home, click on the Navigation hamburger menu in the top left. Hover over the IAM & Admin Menu. Select settings in the middle of the column that opens.\n\n\nClick the blue button labeled Enable Access Transparency for Organization",
    "default_value": "By default Access Transparency is not enabled."
  },
  {
    "control_id": "8.5",
    "control": "Collect Detailed Audit Logs",
    "IG1": "-",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260478,
    "recommendation_id": 2036762,
    "view_level": "6.2.1",
    "title": "Ensure \u2018Log_error_verbosity\u2019 Database Flag for Cloud SQL PostgreSQL Instance Is Set to \u2018DEFAULT\u2019 or Stricter",
    "pivot_control_id": 431,
    "pivot_recommendation_id": 2036762,
    "url": "https://workbench.cisecurity.org/sections/1260478/recommendations/2036762",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 2"
      }
    ],
    "description": "The log_error_verbosity flag controls the verbosity/details of messages logged. Valid values are:\n\nTERSE\nDEFAULT\nVERBOSE\n\nTERSE excludes the logging of DETAIL, HINT, QUERY, and CONTEXT error information.\nVERBOSE output includes the SQLSTATE error code, source code file name, function name, and line number that generated the error.\nEnsure an appropriate value is set to 'DEFAULT' or stricter.",
    "rationale_statement": "Auditing helps in troubleshooting operational problems and also permits forensic analysis. If log_error_verbosity is not set to the correct value, too many details or too few details may be logged. This flag should be configured with a value of 'DEFAULT' or stricter. This recommendation is applicable to PostgreSQL database instances.",
    "impact_statement": "Turning on logging will increase the required storage over time. Mismanaged logs may cause your storage costs to increase. Setting custom flags via command line on certain instances will cause all omitted flags to be reset to defaults. This may cause you to lose custom flags and could result in unforeseen complications or instance restarts. Because of this, it is recommended you apply these flags changes during a period of low usage.",
    "audit_procedure": "From Google Cloud Console\n\nGo to the Cloud SQL Instances page in the Google Cloud Console by visiting https://console.cloud.google.com/sql/instances.\nSelect the instance to open its Instance Overview page\nGo to Configuration card\nUnder Database flags, check the value of log_error_verbosity flag is set to 'DEFAULT' or stricter.\n\nFrom Google Cloud CLI\n\nUse the below command for every Cloud SQL PostgreSQL database instance to verify the value of log_error_verbosity\n\ngcloud sql instances list --format=json | jq '.settings.databaseFlags[] | select(.name==\"log_error_verbosity\")|.value'",
    "remediation_procedure": "From Google Cloud Console\n\nGo to the Cloud SQL Instances page in the Google Cloud Console by visiting https://console.cloud.google.com/sql/instances.\nSelect the PostgreSQL instance for which you want to enable the database flag.\nClick Edit.\nScroll down to the Flags section.\nTo set a flag that has not been set on the instance before, click Add item, choose the flag log_error_verbosity from the drop-down menu and set appropriate value.\nClick Save to save your changes.\nConfirm your changes under Flags on the Overview page.\n\nFrom Google Cloud CLI\n\nConfigure the log_error_verbosity database flag for every Cloud SQL PosgreSQL database instance using the below command.\n\ngcloud sql instances patch <INSTANCE_NAME> --database-flags log_error_verbosity=<TERSE|DEFAULT|VERBOSE>\n\nNote: This command will overwrite all database flags previously set. To keep those and add new ones, include the values for all flags you want set on the instance; any flag not specifically included is set to its default value. For flags that do not take a value, specify the flag name followed by an equals sign (\"=\").",
    "default_value": "By default log_error_verbosity is DEFAULT."
  },
  {
    "control_id": "8.5",
    "control": "Collect Detailed Audit Logs",
    "IG1": "-",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260478,
    "recommendation_id": 2036764,
    "view_level": "6.2.2",
    "title": "Ensure That the \u2018Log_connections\u2019 Database Flag for Cloud SQL PostgreSQL Instance Is Set to \u2018On\u2019",
    "pivot_control_id": 431,
    "pivot_recommendation_id": 2036764,
    "url": "https://workbench.cisecurity.org/sections/1260478/recommendations/2036764",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 1"
      }
    ],
    "description": "Enabling the log_connections setting causes each attempted connection to the server to be logged, along with successful completion of client authentication. This parameter cannot be changed after the session starts.",
    "rationale_statement": "PostgreSQL does not log attempted connections by default. Enabling the log_connections setting will create log entries for each attempted connection as well as successful completion of client authentication which can be useful in troubleshooting issues and to determine any unusual connection attempts to the server. This recommendation is applicable to PostgreSQL database instances.",
    "impact_statement": "Turning on logging will increase the required storage over time. Mismanaged logs may cause your storage costs to increase. Setting custom flags via command line on certain instances will cause all omitted flags to be reset to defaults. This may cause you to lose custom flags and could result in unforeseen complications or instance restarts. Because of this, it is recommended you apply these flags changes during a period of low usage.",
    "audit_procedure": "From Google Cloud Console\n\nGo to the Cloud SQL Instances page in the Google Cloud Console by visiting https://console.cloud.google.com/sql/instances.\nSelect the instance to open its Instance Overview page.\nGo to the Configuration card.\nUnder Database flags, check the value of log_connections flag to determine if it is configured as expected.\n\nFrom Google Cloud CLI\n\nEnsure the below command returns on for every Cloud SQL PostgreSQL database instance:\n\ngcloud sql instances list --format=json | jq '.settings.databaseFlags[] | select(.name==\"log_connections\")|.value'",
    "remediation_procedure": "From Google Cloud Console\n\nGo to the Cloud SQL Instances page in the Google Cloud Console by visiting https://console.cloud.google.com/sql/instances.\nSelect the PostgreSQL instance for which you want to enable the database flag.\nClick Edit.\nScroll down to the Flags section.\nTo set a flag that has not been set on the instance before, click Add item, choose the flag log_connections from the drop-down menu and set the value as on.\nClick Save.\nConfirm the changes under Flags on the Overview page.\n\nFrom Google Cloud CLI\n\nConfigure the log_connections database flag for every Cloud SQL PosgreSQL database instance using the below command.\n\ngcloud sql instances patch <INSTANCE_NAME> --database-flags log_connections=on\n\nNote: \nThis command will overwrite all previously set database flags. To keep those and add new ones, include the values for all flags to be set on the instance; any flag not specifically included is set to its default value. For flags that do not take a value, specify the flag name followed by an equals sign (\"=\").",
    "default_value": "By default log_connections is off."
  },
  {
    "control_id": "8.5",
    "control": "Collect Detailed Audit Logs",
    "IG1": "-",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260478,
    "recommendation_id": 2036766,
    "view_level": "6.2.3",
    "title": "Ensure That the \u2018Log_disconnections\u2019 Database Flag for Cloud SQL PostgreSQL Instance Is Set to \u2018On\u2019",
    "pivot_control_id": 431,
    "pivot_recommendation_id": 2036766,
    "url": "https://workbench.cisecurity.org/sections/1260478/recommendations/2036766",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 1"
      }
    ],
    "description": "Enabling the log_disconnections setting logs the end of each session, including the session duration.",
    "rationale_statement": "PostgreSQL does not log session details such as duration and session end by default. Enabling the log_disconnections setting will create log entries at the end of each session which can be useful in troubleshooting issues and determine any unusual activity across a time period.\nThe log_disconnections and log_connections work hand in hand and generally, the pair would be enabled/disabled together. This recommendation is applicable to PostgreSQL database instances.",
    "impact_statement": "Turning on logging will increase the required storage over time. Mismanaged logs may cause your storage costs to increase. Setting custom flags via command line on certain instances will cause all omitted flags to be reset to defaults. This may cause you to lose custom flags and could result in unforeseen complications or instance restarts. Because of this, it is recommended you apply these flags changes during a period of low usage.",
    "audit_procedure": "From Google Cloud Console\n\nGo to the Cloud SQL Instances page in the Google Cloud Console by visiting https://console.cloud.google.com/sql/instances.\nSelect the instance to open its Instance Overview page\nGo to the Configuration card.\nUnder Database flags, check the value of log_disconnections flag is configured as expected.\n\nFrom Google Cloud CLI\n\nEnsure the below command returns on for every Cloud SQL PostgreSQL database instance:\n\ngcloud sql instances list --format=json | jq '.[].settings.databaseFlags[] | select(.name==\"log_disconnections\")|.value'",
    "remediation_procedure": "From Google Cloud Console\n\nGo to the Cloud SQL Instances page in the Google Cloud Console by visiting https://console.cloud.google.com/sql/instances.\nSelect the PostgreSQL instance where the database flag needs to be enabled.\nClick Edit.\nScroll down to the Flags section.\nTo set a flag that has not been set on the instance before, click Add item, choose the flag log_disconnections from the drop-down menu and set the value as on.\nClick Save.\nConfirm the changes under Flags on the Overview page.\n\nFrom Google Cloud CLI\n\nConfigure the log_disconnections database flag for every Cloud SQL PosgreSQL database instance using the below command:\n\ngcloud sql instances patch <INSTANCE_NAME> --database-flags log_disconnections=on\n\nNote: This command will overwrite all previously set database flags. To keep those and add new ones, include the values for all flags to be set on the instance; any flag not specifically included is set to its default value. For flags that do not take a value, specify the flag name followed by an equals sign (\"=\").",
    "default_value": "By default log_disconnections is off."
  },
  {
    "control_id": "8.5",
    "control": "Collect Detailed Audit Logs",
    "IG1": "-",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260478,
    "recommendation_id": 2036768,
    "view_level": "6.2.4",
    "title": "Ensure \u2018Log_statement\u2019 Database Flag for Cloud SQL PostgreSQL Instance Is Set Appropriately",
    "pivot_control_id": 431,
    "pivot_recommendation_id": 2036768,
    "url": "https://workbench.cisecurity.org/sections/1260478/recommendations/2036768",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 2"
      }
    ],
    "description": "The value of log_statement flag determined the SQL statements that are logged. Valid values are:\n\nnone\nddl\nmod\nall\n\nThe value ddl logs all data definition statements.\nThe value mod logs all ddl statements, plus data-modifying statements.\nThe statements are logged after a basic parsing is done and statement type is determined, thus this does not logs statements with errors. When using extended query protocol, logging occurs after an Execute message is received and values of the Bind parameters are included.\nA value of 'ddl' is recommended unless otherwise directed by your organization's logging policy.",
    "rationale_statement": "Auditing helps in forensic analysis. If log_statement is not set to the correct value, too many statements may be logged leading to issues in finding the relevant information from the logs, or too few statements may be logged with relevant information missing from the logs. Setting log_statement to align with your organization's security and logging policies facilitates later auditing and review of database activities.\nThis recommendation is applicable to PostgreSQL database instances.",
    "impact_statement": "Turning on logging will increase the required storage over time. Mismanaged logs may cause your storage costs to increase. Setting custom flags via command line on certain instances will cause all omitted flags to be reset to defaults. This may cause you to lose custom flags and could result in unforeseen complications or instance restarts. Because of this, it is recommended you apply these flags changes during a period of low usage.",
    "audit_procedure": "From Google Cloud Console\n\nGo to the Cloud SQL Instances page in the Google Cloud Console by visiting https://console.cloud.google.com/sql/instances.\nSelect the instance to open its Instance Overview page\nGo to Configuration card\nUnder Database flags, check the value of log_statement flag is set to appropriately.\n\nFrom Google Cloud CLI\n\nUse the below command for every Cloud SQL PostgreSQL database instance to verify the value of log_statement\n\ngcloud sql instances list --format=json | jq '.[].settings.databaseFlags[] | select(.name==\"log_statement\")|.value'",
    "remediation_procedure": "From Google Cloud Console\n\nGo to the Cloud SQL Instances page in the Google Cloud Console by visiting https://console.cloud.google.com/sql/instances.\nSelect the PostgreSQL instance for which you want to enable the database flag.\nClick Edit.\nScroll down to the Flags section.\nTo set a flag that has not been set on the instance before, click Add item, choose the flag log_statement from the drop-down menu and set appropriate value.\nClick Save to save your changes.\nConfirm your changes under Flags on the Overview page.\n\nFrom Google Cloud CLI\n\nConfigure the log_statement database flag for every Cloud SQL PosgreSQL database instance using the below command.\n\ngcloud sql instances patch <INSTANCE_NAME> --database-flags log_statement=<ddl|mod|all|none>\n\nNote: This command will overwrite all database flags previously set. To keep those and add new ones, include the values for all flags you want set on the instance; any flag not specifically included is set to its default value. For flags that do not take a value, specify the flag name followed by an equals sign (\"=\").",
    "default_value": ""
  },
  {
    "control_id": "8.5",
    "control": "Collect Detailed Audit Logs",
    "IG1": "-",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260478,
    "recommendation_id": 2036771,
    "view_level": "6.2.5",
    "title": "Ensure that the \u2018Log_min_messages\u2019 Flag for a Cloud SQL PostgreSQL Instance is set at minimum to 'Warning'",
    "pivot_control_id": 431,
    "pivot_recommendation_id": 2036771,
    "url": "https://workbench.cisecurity.org/sections/1260478/recommendations/2036771",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 1"
      }
    ],
    "description": "The log_min_messages flag defines the minimum message severity level that is considered as an error statement. Messages for error statements are logged with the SQL statement. Valid values include DEBUG5, DEBUG4, DEBUG3, DEBUG2, DEBUG1, INFO, NOTICE, WARNING, ERROR, LOG, FATAL, and PANIC.\nEach severity level includes the subsequent levels mentioned above. ERROR is considered the best practice setting. Changes should only be made in accordance with the organization's logging policy.",
    "rationale_statement": "Auditing helps in troubleshooting operational problems and also permits forensic analysis. If log_min_messages is not set to the correct value, messages may not be classified as error messages appropriately. An organization will need to decide their own threshold for logging log_min_messages flag.\nThis recommendation is applicable to PostgreSQL database instances.",
    "impact_statement": "Setting the threshold too low will might result in increased log storage size and length, making it difficult to find actual errors. Setting the threshold to 'Warning' will log messages for the most needed error messages. Higher severity levels may cause errors needed to troubleshoot to not be logged.\nNote: To effectively turn off logging failing statements, set this parameter to PANIC.",
    "audit_procedure": "From Google Cloud Console\n\nGo to the Cloud SQL Instances page in the Google Cloud Console by visiting https://console.cloud.google.com/sql/instances.\nSelect the instance to open its Instance Overview page.\nGo to the Configuration card.\nUnder Database flags, check the value of log_min_messages flag is in accordance with the organization's logging policy.\n\nFrom Google Cloud CLI\n\nUse the below command for every Cloud SQL PostgreSQL database instance to verify that the value of log_min_messages is in accordance with the  organization's logging policy.\n\ngcloud sql instances list --format=json | jq '.settings.databaseFlags[] | select(.name==\"log_min_messages\")|.value'",
    "remediation_procedure": "From Google Cloud Console\n\nGo to the Cloud SQL Instances page in the Google Cloud Console by visiting https://console.cloud.google.com/sql/instances\nSelect the PostgreSQL instance for which you want to enable the database flag.\nClick Edit.\nScroll down to the Flags section.\nTo set a flag that has not been set on the instance before, click Add item, choose the flag log_min_messages from the drop-down menu and set appropriate value.\nClick Save to save the changes.\nConfirm the changes under Flags on the Overview page.\n\nFrom Google Cloud CLI\n\nConfigure the log_min_messages database flag for every Cloud SQL PosgreSQL database instance using the below command.\n\ngcloud sql instances patch <INSTANCE_NAME> --database-flags log_min_messages=<DEBUG5|DEBUG4|DEBUG3|DEBUG2|DEBUG1|INFO|NOTICE|WARNING|ERROR|LOG|FATAL|PANIC>\n\nNote: This command will overwrite all database flags previously set. To keep those and add new ones, include the values for all flags to be set on the instance; any flag not specifically included is set to its default value. For flags that do not take a value, specify the flag name followed by an equals sign (\"=\").",
    "default_value": "By default log_min_messages is ERROR."
  },
  {
    "control_id": "8.5",
    "control": "Collect Detailed Audit Logs",
    "IG1": "-",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260478,
    "recommendation_id": 2036773,
    "view_level": "6.2.6",
    "title": "Ensure \u2018Log_min_error_statement\u2019 Database Flag for Cloud SQL PostgreSQL Instance Is Set to \u2018Error\u2019 or Stricter",
    "pivot_control_id": 431,
    "pivot_recommendation_id": 2036773,
    "url": "https://workbench.cisecurity.org/sections/1260478/recommendations/2036773",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 1"
      }
    ],
    "description": "The log_min_error_statement flag defines the minimum message severity level that are considered as an error statement. Messages for error statements are logged with the SQL statement. Valid values include DEBUG5, DEBUG4, DEBUG3, DEBUG2, DEBUG1, INFO, NOTICE, WARNING, ERROR, LOG, FATAL, and PANIC.\nEach severity level includes the subsequent levels mentioned above. Ensure a value of ERROR or stricter is set.",
    "rationale_statement": "Auditing helps in troubleshooting operational problems and also permits forensic analysis. If log_min_error_statement is not set to the correct value, messages may not be classified as error messages appropriately. Considering general log messages as error messages would make is difficult to find actual errors and considering only stricter severity levels as error messages may skip actual errors to log their SQL statements.\nThe log_min_error_statement flag should be set to ERROR or stricter. This recommendation is applicable to PostgreSQL database instances.",
    "impact_statement": "Turning on logging will increase the required storage over time. Mismanaged logs may cause your storage costs to increase. Setting custom flags via command line on certain instances will cause all omitted flags to be reset to defaults. This may cause you to lose custom flags and could result in unforeseen complications or instance restarts. Because of this, it is recommended you apply these flags changes during a period of low usage.",
    "audit_procedure": "From Google Cloud Console\n\nGo to the Cloud SQL Instances page in the Google Cloud Console by visiting https://console.cloud.google.com/sql/instances.\nSelect the instance to open its Instance Overview page\nGo to Configuration card\nUnder Database flags, check the value of log_min_error_statement flag is configured as to ERROR or stricter.\n\nFrom Google Cloud CLI\n\nUse the below command for every Cloud SQL PostgreSQL database instance to verify the value of log_min_error_statement is set to ERROR or stricter.\n\ngcloud sql instances list --format=json | jq '.[].settings.databaseFlags[] | select(.name==\"log_min_error_statement\")|.value'",
    "remediation_procedure": "From Google Cloud Console\n\nGo to the Cloud SQL Instances page in the Google Cloud Console by visiting https://console.cloud.google.com/sql/instances.\nSelect the PostgreSQL instance for which you want to enable the database flag.\nClick Edit.\nScroll down to the Flags section.\nTo set a flag that has not been set on the instance before, click Add item, choose the flag log_min_error_statement from the drop-down menu and set appropriate value.\nClick Save to save your changes.\nConfirm your changes under Flags on the Overview page.\n\nFrom Google Cloud CLI\n\nConfigure the log_min_error_statement database flag for every Cloud SQL PosgreSQL database instance using the below command.\n\ngcloud sql instances patch <INSTANCE_NAME> --database-flags log_min_error_statement=<DEBUG5|DEBUG4|DEBUG3|DEBUG2|DEBUG1|INFO|NOTICE|WARNING|ERROR>\n\nNote: This command will overwrite all database flags previously set. To keep those and add new ones, include the values for all flags you want set on the instance; any flag not specifically included is set to its default value. For flags that do not take a value, specify the flag name followed by an equals sign (\"=\").",
    "default_value": "By default log_min_error_statement is ERROR."
  },
  {
    "control_id": "8.5",
    "control": "Collect Detailed Audit Logs",
    "IG1": "-",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260478,
    "recommendation_id": 2036775,
    "view_level": "6.2.7",
    "title": "Ensure That the \u2018Log_min_duration_statement\u2019 Database Flag for Cloud SQL PostgreSQL Instance Is Set to \u2018-1\u2032 (Disabled)",
    "pivot_control_id": 431,
    "pivot_recommendation_id": 2036775,
    "url": "https://workbench.cisecurity.org/sections/1260478/recommendations/2036775",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 1"
      }
    ],
    "description": "The log_min_duration_statement flag defines the minimum amount of execution time of a statement in milliseconds where the total duration of the statement is logged. Ensure that log_min_duration_statement is disabled, i.e., a value of -1 is set.",
    "rationale_statement": "Logging SQL statements may include sensitive information that should not be recorded in logs. This recommendation is applicable to PostgreSQL database instances.",
    "impact_statement": "Turning on logging will increase the required storage over time. Mismanaged logs may cause your storage costs to increase. Setting custom flags via command line on certain instances will cause all omitted flags to be reset to defaults. This may cause you to lose custom flags and could result in unforeseen complications or instance restarts. Because of this, it is recommended you apply these flags changes during a period of low usage.",
    "audit_procedure": "From Google Cloud Console\n\nGo to the Cloud SQL Instances page in the Google Cloud Console by visiting https://console.cloud.google.com/sql/instances.\nSelect the instance to open its Instance Overview page.\nGo to the Configuration card.\nUnder Database flags, check that the value of log_min_duration_statement flag is set to -1.\n\nFrom Google Cloud CLI\n\nUse the below command for every Cloud SQL PostgreSQL database instance to verify the value of log_min_duration_statement is set to -1.\n\ngcloud sql instances list --format=json| jq '.settings.databaseFlags[] | select(.name==\"log_min_duration_statement\")|.value'",
    "remediation_procedure": "From Google Cloud Console\n\nGo to the Cloud SQL Instances page in the Google Cloud Console by visiting https://console.cloud.google.com/sql/instances.\nSelect the PostgreSQL instance where the database flag needs to be enabled.\nClick Edit.\nScroll down to the Flags section.\nTo set a flag that has not been set on the instance before, click Add item, choose the flag log_min_duration_statement from the drop-down menu and set a value of -1.\nClick Save.\nConfirm the changes under Flags on the Overview page.\n\nFrom Google Cloud CLI\n\nList all Cloud SQL database instances using the following command:\n\ngcloud sql instances list\n\n\nConfigure the log_min_duration_statement flag for every Cloud SQL PosgreSQL database instance using the below command:\n\ngcloud sql instances patch <INSTANCE_NAME> --database-flags log_min_duration_statement=-1\n\nNote: This command will overwrite all database flags previously set. To keep those and add new ones, include the values for all flags to be set on the instance; any flag not specifically included is set to its default value. For flags that do not take a value, specify the flag name followed by an equals sign (\"=\").",
    "default_value": "By default log_min_duration_statement is -1."
  },
  {
    "control_id": "8.5",
    "control": "Collect Detailed Audit Logs",
    "IG1": "-",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260478,
    "recommendation_id": 2036777,
    "view_level": "6.2.8",
    "title": "Ensure That 'cloudsql.enable_pgaudit' Database Flag for each Cloud Sql Postgresql Instance Is Set to 'on' For Centralized Logging",
    "pivot_control_id": 431,
    "pivot_recommendation_id": 2036777,
    "url": "https://workbench.cisecurity.org/sections/1260478/recommendations/2036777",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 1"
      }
    ],
    "description": "Ensure cloudsql.enable_pgaudit database flag for Cloud SQL PostgreSQL instance is set to on to allow for centralized logging.",
    "rationale_statement": "As numerous other recommendations in this section consist of turning on flags for logging purposes, your organization will need a way to manage these logs. You may have a solution already in place. If you do not, consider installing and enabling the open source pgaudit extension within PostgreSQL and enabling its corresponding flag of cloudsql.enable_pgaudit. This flag and installing the extension enables database auditing in PostgreSQL through the open-source pgAudit extension. This extension provides detailed session and object logging to comply with government, financial, & ISO standards and provides auditing capabilities to mitigate threats by monitoring security events on the instance. Enabling the flag and settings later in this recommendation will send these logs to Google Logs Explorer so that you can access them in a central location. to This recommendation is applicable only to PostgreSQL database instances.",
    "impact_statement": "Enabling the pgAudit extension can lead to increased data storage requirements and to ensure durability of pgAudit log records in the event of unexpected storage issues, it is recommended to enable the Enable automatic storage increases setting on the instance. Enabling flags via the command line will also overwrite all existing flags, so you should apply all needed flags in the CLI command. Also flags may require a restart of the server to be implemented or will break existing functionality so update your servers at a time of low usage.",
    "audit_procedure": "Determining if the pgAudit Flag is set to 'on'\nFrom Google Cloud Console\n\nGo to https://console.cloud.google.com/sql/instances.\nSelect the instance to open its Overview page.\nClick Edit.\nScroll down and expand Flags.\nEnsure that cloudsql.enable_pgaudit flag is set to on.\n\nFrom Google Cloud CLI\nRun the command by providing <INSTANCE_NAME>. Ensure the value of the flag is on.\ngcloud sql instances describe <INSTANCE_NAME> --format=\"json\" | jq '.settings|.|.databaseFlags[]|select(.name==\"cloudsql.enable_pgaudit\")|.value' \n\nDetermine if the pgAudit extension is installed\n\nConnect to the the server running PostgreSQL or through a SQL client of your choice.\nVia command line open the PostgreSQL shell by typing psql\nRun the following command\n\nSELECT * \nFROM pg_extension;\n\n\nIf pgAudit is in this list. If so, it is installed.\n\nDetermine if Data Access Audit logs are enabled for your project and have sufficient privileges\n\nFrom the homepage open the hamburger menu in the top left.\nScroll down to IAM & Adminand hover over it.\nIn the menu that opens up, select Audit Logs\nIn the middle of the page, in the search box next to filter search for Cloud Composer API\nSelect it, and ensure that both 'Admin Read' and 'Data Read' are checked.\n\nDetermine if logs are being sent to Logs Explorer\n\nFrom the Google Console home page, open the hamburger menu in the top left.\nIn the menu that pops open, scroll down to Logs Explorer under Operations.\nIn the query box, paste the following and search\n\nresource.type=\"cloudsql_database\"\nlogName=\"projects/<your-project-name>/logs/cloudaudit.googleapis.com%2Fdata_access\"\nprotoPayload.request.@type=\"type.googleapis.com/google.cloud.sql.audit.v1.PgAuditEntry\"\n\n\nIf it returns any log sources, they are correctly setup.",
    "remediation_procedure": "Initialize the pgAudit flag\nFrom Google Cloud Console\n\nGo to https://console.cloud.google.com/sql/instances.\nSelect the instance to open its Overview page.\nClick Edit.\nScroll down and expand Flags.\nTo set a flag that has not been set on the instance before, click Add item.\nEnter cloudsql.enable_pgaudit for the flag name and set the flag to on.\nClick Done.\nClick Save to update the configuration.\nConfirm your changes under Flags on the Overview page.\n\nFrom Google Cloud CLI\nRun the below command by providing <INSTANCE_NAME> to enable cloudsql.enable_pgaudit flag.\ngcloud sql instances patch <INSTANCE_NAME> --database-flags cloudsql.enable_pgaudit=on\n\nNote: RESTART is required to get this configuration in effect.\nCreating the extension\n\nConnect to the the server running PostgreSQL or through a SQL client of your choice.\nIf SSHing to the server in the command line open the PostgreSQL shell by typing psql\nRun the following command as a superuser.\n\nCREATE EXTENSION pgaudit;\n\nUpdating the previously created pgaudit.log flag for your Logging Needs\nFrom Console:\nNote: there are multiple options here. This command will enable logging for all databases on a server. Please see the customizing database audit logging reference for more flag options.\n\nGo to https://console.cloud.google.com/sql/instances.\nSelect the instance to open its Overview page.\nClick Edit.\nScroll down and expand Flags.\nTo set a flag that has not been set on the instance before, click Add item.\nEnter pgaudit.log=all for the flag name and set the flag to on.\nClick Done.\nClick Save to update the configuration.\nConfirm your changes under Flags on the Overview page.\n\nFrom Command Line:\nRun the command\ngcloud sql instances patch <INSTANCE_NAME> --database-flags \\\n  cloudsql.enable_pgaudit=on,pgaudit.log=all\n\nDetermine if logs are being sent to Logs Explorer\n\nFrom the Google Console home page, open the hamburger menu in the top left.\nIn the menu that pops open, scroll down to Logs Explorer under Operations.\nIn the query box, paste the following and search\n\nresource.type=\"cloudsql_database\"\nlogName=\"projects//logs/cloudaudit.googleapis.com%2Fdata_access\"\nprotoPayload.request.@type=\"type.googleapis.com/google.cloud.sql.audit.v1.PgAuditEntry\"\nIf it returns any log sources, they are correctly setup.",
    "default_value": "By default cloudsql.enable_pgaudit database flag is set to off and the extension is not enabled."
  },
  {
    "control_id": "8.6",
    "control": "Collect DNS Query Audit Logs",
    "IG1": "-",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260471,
    "recommendation_id": 2036746,
    "view_level": "2.12",
    "title": "Ensure That Cloud DNS Logging Is Enabled for All VPC Networks",
    "pivot_control_id": 432,
    "pivot_recommendation_id": 2036746,
    "url": "https://workbench.cisecurity.org/sections/1260471/recommendations/2036746",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 1"
      }
    ],
    "description": "Cloud DNS logging records the queries from the name servers within your VPC to Stackdriver.  Logged queries can come from Compute Engine VMs, GKE containers, or other GCP resources provisioned within the VPC.",
    "rationale_statement": "Security monitoring and forensics cannot depend solely on IP addresses from VPC flow logs, especially when considering the dynamic IP usage of cloud resources, HTTP virtual host routing, and other technology that can obscure the DNS name used by a client from the IP address.  Monitoring of Cloud DNS logs provides visibility to DNS names requested by the clients within the VPC.  These logs can be monitored for anomalous domain names, evaluated against threat intelligence, and\nNote: For full capture of DNS, firewall must block egress UDP/53 (DNS) and TCP/443 (DNS over HTTPS) to prevent client from using external DNS name server for resolution.",
    "impact_statement": "Enabling of Cloud DNS logging might result in your project being charged for the additional logs usage.",
    "audit_procedure": "From Google Cloud CLI\n\nList all VPCs networks in a project:\n\ngcloud compute networks list --format=\"table[box,title='All VPC Networks'](name:label='VPC Network Name')\"\n\n\nList all DNS policies, logging enablement, and associated VPC networks:\n\ngcloud dns policies list --flatten=\"networks[]\" --format=\"table[box,title='All DNS Policies By VPC Network'](name:label='Policy Name',enableLogging:label='Logging Enabled':align=center,networks.networkUrl.basename():label='VPC Network Name')\"\n\nEach VPC Network should be associated with a DNS policy with logging enabled.",
    "remediation_procedure": "From Google Cloud CLI\nAdd New DNS Policy With Logging Enabled\nFor each VPC network that needs a DNS policy with logging enabled:\ngcloud dns policies create enable-dns-logging --enable-logging --description=\"Enable DNS Logging\" --networks=VPC_NETWORK_NAME\n\nThe VPC_NETWORK_NAME can be one or more networks in comma-separated list\nEnable Logging for Existing DNS Policy\nFor each VPC network that has an existing DNS policy that needs logging enabled:\ngcloud dns policies update POLICY_NAME --enable-logging --networks=VPC_NETWORK_NAME\n\nThe VPC_NETWORK_NAME can be one or more networks in comma-separated list",
    "default_value": "Cloud DNS logging is disabled by default on each network."
  },
  {
    "control_id": "8.9",
    "control": "Centralize Audit Logs",
    "IG1": "-",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260478,
    "recommendation_id": 2036777,
    "view_level": "6.2.8",
    "title": "Ensure That 'cloudsql.enable_pgaudit' Database Flag for each Cloud Sql Postgresql Instance Is Set to 'on' For Centralized Logging",
    "pivot_control_id": 435,
    "pivot_recommendation_id": 2036777,
    "url": "https://workbench.cisecurity.org/sections/1260478/recommendations/2036777",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 1"
      }
    ],
    "description": "Ensure cloudsql.enable_pgaudit database flag for Cloud SQL PostgreSQL instance is set to on to allow for centralized logging.",
    "rationale_statement": "As numerous other recommendations in this section consist of turning on flags for logging purposes, your organization will need a way to manage these logs. You may have a solution already in place. If you do not, consider installing and enabling the open source pgaudit extension within PostgreSQL and enabling its corresponding flag of cloudsql.enable_pgaudit. This flag and installing the extension enables database auditing in PostgreSQL through the open-source pgAudit extension. This extension provides detailed session and object logging to comply with government, financial, & ISO standards and provides auditing capabilities to mitigate threats by monitoring security events on the instance. Enabling the flag and settings later in this recommendation will send these logs to Google Logs Explorer so that you can access them in a central location. to This recommendation is applicable only to PostgreSQL database instances.",
    "impact_statement": "Enabling the pgAudit extension can lead to increased data storage requirements and to ensure durability of pgAudit log records in the event of unexpected storage issues, it is recommended to enable the Enable automatic storage increases setting on the instance. Enabling flags via the command line will also overwrite all existing flags, so you should apply all needed flags in the CLI command. Also flags may require a restart of the server to be implemented or will break existing functionality so update your servers at a time of low usage.",
    "audit_procedure": "Determining if the pgAudit Flag is set to 'on'\nFrom Google Cloud Console\n\nGo to https://console.cloud.google.com/sql/instances.\nSelect the instance to open its Overview page.\nClick Edit.\nScroll down and expand Flags.\nEnsure that cloudsql.enable_pgaudit flag is set to on.\n\nFrom Google Cloud CLI\nRun the command by providing <INSTANCE_NAME>. Ensure the value of the flag is on.\ngcloud sql instances describe <INSTANCE_NAME> --format=\"json\" | jq '.settings|.|.databaseFlags[]|select(.name==\"cloudsql.enable_pgaudit\")|.value' \n\nDetermine if the pgAudit extension is installed\n\nConnect to the the server running PostgreSQL or through a SQL client of your choice.\nVia command line open the PostgreSQL shell by typing psql\nRun the following command\n\nSELECT * \nFROM pg_extension;\n\n\nIf pgAudit is in this list. If so, it is installed.\n\nDetermine if Data Access Audit logs are enabled for your project and have sufficient privileges\n\nFrom the homepage open the hamburger menu in the top left.\nScroll down to IAM & Adminand hover over it.\nIn the menu that opens up, select Audit Logs\nIn the middle of the page, in the search box next to filter search for Cloud Composer API\nSelect it, and ensure that both 'Admin Read' and 'Data Read' are checked.\n\nDetermine if logs are being sent to Logs Explorer\n\nFrom the Google Console home page, open the hamburger menu in the top left.\nIn the menu that pops open, scroll down to Logs Explorer under Operations.\nIn the query box, paste the following and search\n\nresource.type=\"cloudsql_database\"\nlogName=\"projects/<your-project-name>/logs/cloudaudit.googleapis.com%2Fdata_access\"\nprotoPayload.request.@type=\"type.googleapis.com/google.cloud.sql.audit.v1.PgAuditEntry\"\n\n\nIf it returns any log sources, they are correctly setup.",
    "remediation_procedure": "Initialize the pgAudit flag\nFrom Google Cloud Console\n\nGo to https://console.cloud.google.com/sql/instances.\nSelect the instance to open its Overview page.\nClick Edit.\nScroll down and expand Flags.\nTo set a flag that has not been set on the instance before, click Add item.\nEnter cloudsql.enable_pgaudit for the flag name and set the flag to on.\nClick Done.\nClick Save to update the configuration.\nConfirm your changes under Flags on the Overview page.\n\nFrom Google Cloud CLI\nRun the below command by providing <INSTANCE_NAME> to enable cloudsql.enable_pgaudit flag.\ngcloud sql instances patch <INSTANCE_NAME> --database-flags cloudsql.enable_pgaudit=on\n\nNote: RESTART is required to get this configuration in effect.\nCreating the extension\n\nConnect to the the server running PostgreSQL or through a SQL client of your choice.\nIf SSHing to the server in the command line open the PostgreSQL shell by typing psql\nRun the following command as a superuser.\n\nCREATE EXTENSION pgaudit;\n\nUpdating the previously created pgaudit.log flag for your Logging Needs\nFrom Console:\nNote: there are multiple options here. This command will enable logging for all databases on a server. Please see the customizing database audit logging reference for more flag options.\n\nGo to https://console.cloud.google.com/sql/instances.\nSelect the instance to open its Overview page.\nClick Edit.\nScroll down and expand Flags.\nTo set a flag that has not been set on the instance before, click Add item.\nEnter pgaudit.log=all for the flag name and set the flag to on.\nClick Done.\nClick Save to update the configuration.\nConfirm your changes under Flags on the Overview page.\n\nFrom Command Line:\nRun the command\ngcloud sql instances patch <INSTANCE_NAME> --database-flags \\\n  cloudsql.enable_pgaudit=on,pgaudit.log=all\n\nDetermine if logs are being sent to Logs Explorer\n\nFrom the Google Console home page, open the hamburger menu in the top left.\nIn the menu that pops open, scroll down to Logs Explorer under Operations.\nIn the query box, paste the following and search\n\nresource.type=\"cloudsql_database\"\nlogName=\"projects//logs/cloudaudit.googleapis.com%2Fdata_access\"\nprotoPayload.request.@type=\"type.googleapis.com/google.cloud.sql.audit.v1.PgAuditEntry\"\nIf it returns any log sources, they are correctly setup.",
    "default_value": "By default cloudsql.enable_pgaudit database flag is set to off and the extension is not enabled."
  },
  {
    "control_id": "8.11",
    "control": "Conduct Audit Log Reviews",
    "IG1": "-",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260471,
    "recommendation_id": 2036723,
    "view_level": "2.1",
    "title": "Ensure That Cloud Audit Logging Is Configured Properly",
    "pivot_control_id": 436,
    "pivot_recommendation_id": 2036723,
    "url": "https://workbench.cisecurity.org/sections/1260471/recommendations/2036723",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 1"
      }
    ],
    "description": "It is recommended that Cloud Audit Logging is configured to track all admin activities and read, write access to user data.",
    "rationale_statement": "Cloud Audit Logging maintains two audit logs for each project, folder, and organization: Admin Activity and Data Access.\n\n\nAdmin Activity logs contain log entries for API calls or other administrative actions that modify the configuration or metadata of resources. Admin Activity audit logs are enabled for all services and cannot be configured.\n\n\nData Access audit logs record API calls that create, modify, or read user-provided data. These are disabled by default and should be enabled.\nThere are three kinds of Data Access audit log information:\n\nAdmin read: Records operations that read metadata or configuration information. Admin Activity audit logs record writes of metadata and configuration information that cannot be disabled.\nData read: Records operations that read user-provided data.\nData write: Records operations that write user-provided data.\n\n\n\nIt is recommended to have an effective default audit config configured in such a way that:\n\n\nlogtype is set to DATA_READ (to log user activity tracking) and DATA_WRITES (to log changes/tampering to user data).\n\n\naudit config is enabled for all the services supported by the Data Access audit logs feature.\n\n\nLogs should be captured for all users, i.e., there are no exempted users in any of the audit config sections. This will ensure overriding the audit config will not contradict the requirement.",
    "impact_statement": "There is no charge for Admin Activity audit logs.\nEnabling the Data Access audit logs might result in your project being charged for the additional logs usage.",
    "audit_procedure": "From Google Cloud Console\n\nGo to Audit Logs by visiting https://console.cloud.google.com/iam-admin/audit.\nEnsure that Admin Read, Data Write, and Data Read are enabled for all Google Cloud services and that no exemptions are allowed.\n\nFrom Google Cloud CLI\n\nList the Identity and Access Management (IAM) policies for the project, folder, or organization:\n\ngcloud organizations get-iam-policy ORGANIZATION_ID\ngcloud resource-manager folders get-iam-policy FOLDER_ID\ngcloud projects get-iam-policy PROJECT_ID\n\n\nPolicy should have a default auditConfigs section which has the logtype set to DATA_WRITES and DATA_READ for all services. Note that projects inherit settings from folders, which in turn inherit settings from the organization. When called, projects get-iam-policy, the result shows only the policies set in the project, not the policies inherited from the parent folder or organization. Nevertheless, if the parent folder has Cloud Audit Logging enabled, the project does as well.\n\nSample output for default audit configs may look like this:\n\tauditConfigs:\n\t- auditLogConfigs:\n  \t- logType: ADMIN_READ\n  \t- logType: DATA_WRITE\n  \t- logType: DATA_READ\n \t service: allServices\n\n\nAny of the auditConfigs sections should not have parameter \"exemptedMembers:\" set, which will ensure that Logging is enabled for all users and no user is exempted.",
    "remediation_procedure": "From Google Cloud Console\n\nGo to Audit Logs by visiting https://console.cloud.google.com/iam-admin/audit.\nFollow the steps at https://cloud.google.com/logging/docs/audit/configure-data-access to enable audit logs for all Google Cloud services. Ensure that no exemptions are allowed.\n\nFrom Google Cloud CLI\n\nTo read the project's IAM policy and store it in a file run a command:\n\ngcloud projects get-iam-policy PROJECT_ID > /tmp/project_policy.yaml\n\nAlternatively, the policy can be set at the organization or folder level. If setting the policy at the organization level, it is not necessary to also set it for each folder or project.\ngcloud organizations get-iam-policy ORGANIZATION_ID > /tmp/org_policy.yaml\ngcloud resource-manager folders get-iam-policy FOLDER_ID > /tmp/folder_policy.yaml\n\n\nEdit policy in /tmp/policy.yaml, adding or changing only the audit logs configuration to:\nNote: Admin Activity Logs are enabled by default, and cannot be disabled. So they are not listed in these configuration changes.\n\nauditConfigs:\n- auditLogConfigs:\n  - logType: DATA_WRITE\n  - logType: DATA_READ\n  service: allServices\n\nNote: exemptedMembers: is not set as audit logging should be enabled for all the users\n\nTo write new IAM policy run command:\n\ngcloud organizations set-iam-policy ORGANIZATION_ID /tmp/org_policy.yaml\ngcloud resource-manager folders set-iam-policy FOLDER_ID /tmp/folder_policy.yaml\ngcloud projects set-iam-policy PROJECT_ID /tmp/project_policy.yaml\n\nIf the preceding command reports a conflict with another change, then repeat these steps, starting with the first step.",
    "default_value": "Admin Activity logs are always enabled. They cannot be disabled.\nData Access audit logs are disabled by default because they can be quite large."
  },
  {
    "control_id": "8.11",
    "control": "Conduct Audit Log Reviews",
    "IG1": "-",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260471,
    "recommendation_id": 2036746,
    "view_level": "2.12",
    "title": "Ensure That Cloud DNS Logging Is Enabled for All VPC Networks",
    "pivot_control_id": 436,
    "pivot_recommendation_id": 2036746,
    "url": "https://workbench.cisecurity.org/sections/1260471/recommendations/2036746",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 1"
      }
    ],
    "description": "Cloud DNS logging records the queries from the name servers within your VPC to Stackdriver.  Logged queries can come from Compute Engine VMs, GKE containers, or other GCP resources provisioned within the VPC.",
    "rationale_statement": "Security monitoring and forensics cannot depend solely on IP addresses from VPC flow logs, especially when considering the dynamic IP usage of cloud resources, HTTP virtual host routing, and other technology that can obscure the DNS name used by a client from the IP address.  Monitoring of Cloud DNS logs provides visibility to DNS names requested by the clients within the VPC.  These logs can be monitored for anomalous domain names, evaluated against threat intelligence, and\nNote: For full capture of DNS, firewall must block egress UDP/53 (DNS) and TCP/443 (DNS over HTTPS) to prevent client from using external DNS name server for resolution.",
    "impact_statement": "Enabling of Cloud DNS logging might result in your project being charged for the additional logs usage.",
    "audit_procedure": "From Google Cloud CLI\n\nList all VPCs networks in a project:\n\ngcloud compute networks list --format=\"table[box,title='All VPC Networks'](name:label='VPC Network Name')\"\n\n\nList all DNS policies, logging enablement, and associated VPC networks:\n\ngcloud dns policies list --flatten=\"networks[]\" --format=\"table[box,title='All DNS Policies By VPC Network'](name:label='Policy Name',enableLogging:label='Logging Enabled':align=center,networks.networkUrl.basename():label='VPC Network Name')\"\n\nEach VPC Network should be associated with a DNS policy with logging enabled.",
    "remediation_procedure": "From Google Cloud CLI\nAdd New DNS Policy With Logging Enabled\nFor each VPC network that needs a DNS policy with logging enabled:\ngcloud dns policies create enable-dns-logging --enable-logging --description=\"Enable DNS Logging\" --networks=VPC_NETWORK_NAME\n\nThe VPC_NETWORK_NAME can be one or more networks in comma-separated list\nEnable Logging for Existing DNS Policy\nFor each VPC network that has an existing DNS policy that needs logging enabled:\ngcloud dns policies update POLICY_NAME --enable-logging --networks=VPC_NETWORK_NAME\n\nThe VPC_NETWORK_NAME can be one or more networks in comma-separated list",
    "default_value": "Cloud DNS logging is disabled by default on each network."
  },
  {
    "control_id": "11.2",
    "control": "Perform Automated Backups",
    "IG1": "o",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260474,
    "recommendation_id": 2036791,
    "view_level": "6.7",
    "title": "Ensure That Cloud SQL Database Instances Are Configured With Automated Backups",
    "pivot_control_id": 456,
    "pivot_recommendation_id": 2036791,
    "url": "https://workbench.cisecurity.org/sections/1260474/recommendations/2036791",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 1"
      }
    ],
    "description": "It is recommended to have all SQL database instances set to enable automated backups.",
    "rationale_statement": "Backups provide a way to restore a Cloud SQL instance to recover lost data or recover from a problem with that instance. Automated backups need to be set for any instance that contains data that should be protected from loss or damage. This recommendation is applicable for SQL Server, PostgreSql, MySql generation 1 and MySql generation 2 instances.",
    "impact_statement": "Automated Backups will increase required size of storage and costs associated with it.",
    "audit_procedure": "From Google Cloud Console\n\nGo to the Cloud SQL Instances page in the Google Cloud Console by visiting https://console.cloud.google.com/sql/instances.\nClick the instance name to open its instance details page.\nGo to the Backups menu.\nEnsure that Automated backups is set to Enabled and Backup time is mentioned.\n\nFrom Google Cloud CLI\n\nList all Cloud SQL database instances using the following command:\n\ngcloud sql instances list\n\n\nEnsure that the below command returns True for every Cloud SQL database instance.\n\ngcloud sql instances describe <INSTANCE_NAME> --format=\"value('Enabled':settings.backupConfiguration.enabled)\"",
    "remediation_procedure": "From Google Cloud Console\n\nGo to the Cloud SQL Instances page in the Google Cloud Console by visiting https://console.cloud.google.com/sql/instances.\nSelect the instance where the backups need to be configured.\nClick Edit.\nIn the Backups section, check `Enable automated backups', and choose a backup window.\nClick Save.\n\nFrom Google Cloud CLI\n\nList all Cloud SQL database instances using the following command:\n\ngcloud sql instances list\n\n\nEnable Automated backups for every Cloud SQL database instance using the below command:\n\ngcloud sql instances patch <INSTANCE_NAME> --backup-start-time <[HH:MM]>\n\nThe backup-start-time parameter is specified in 24-hour time, in the UTC\u00b100 time zone, and specifies the start of a 4-hour backup window. Backups can start any time during the backup window.",
    "default_value": "By default, automated backups are not configured for Cloud SQL instances. Data backup is not possible on any Cloud SQL instance unless Automated Backup is configured."
  },
  {
    "control_id": "13.6",
    "control": "Collect Network Traffic Flow Logs",
    "IG1": "-",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260472,
    "recommendation_id": 2036745,
    "view_level": "3.8",
    "title": "Ensure that VPC Flow Logs is Enabled for Every Subnet in a VPC Network",
    "pivot_control_id": 475,
    "pivot_recommendation_id": 2036745,
    "url": "https://workbench.cisecurity.org/sections/1260472/recommendations/2036745",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 2"
      }
    ],
    "description": "Flow Logs is a feature that enables users to capture information about the IP traffic going to and from network interfaces in the organization's VPC Subnets. Once a flow log is created, the user can view and retrieve its data in Stackdriver Logging. It is recommended that Flow Logs be enabled for every business-critical VPC subnet.",
    "rationale_statement": "VPC networks and subnetworks not reserved for internal HTTP(S) load balancing provide logically isolated and secure network partitions where GCP resources can be launched. When Flow Logs are enabled for a subnet, VMs within that subnet start reporting on all Transmission Control Protocol (TCP) and User Datagram Protocol (UDP) flows.\nEach VM samples the TCP and UDP flows it sees, inbound and outbound, whether the flow is to or from another VM, a host in the on-premises datacenter, a Google service, or a host on the Internet. If two GCP VMs are communicating, and both are in subnets that have VPC Flow Logs enabled, both VMs report the flows.\nFlow Logs supports the following use cases:\n\nNetwork monitoring\nUnderstanding network usage and optimizing network traffic expenses\nNetwork forensics\nReal-time security analysis\n\nFlow Logs provide visibility into network traffic for each VM inside the subnet and can be used to detect anomalous traffic or provide insight during security workflows.\nThe Flow Logs must be configured such that all network traffic is logged, the interval of logging is granular to provide detailed information on the connections, no logs are filtered, and metadata to facilitate investigations are included.\nNote: Subnets reserved for use by internal HTTP(S) load balancers do not support VPC flow logs.",
    "impact_statement": "Standard pricing for Stackdriver Logging, BigQuery, or Cloud Pub/Sub applies. VPC Flow Logs generation will be charged starting in GA as described in reference: https://cloud.google.com/vpc/",
    "audit_procedure": "From Google Cloud Console\n\n\nGo to the VPC network GCP Console visiting https://console.cloud.google.com/networking/networks/list\n\n\nFrom the list of network subnets, make sure for each subnet:\n\n\n\nFlow Logs is set to On\nAggregation Interval is set to 5 sec\nInclude metadata checkbox is checked\nSample rate is set to 100%\n\nNote: It is not possible to determine if a Log filter has been defined from the console.\nFrom Google Cloud CLI\ngcloud compute networks subnets list --format json | \\\n  jq -r '([\"Subnet\",\"Purpose\",\"Flow_Logs\",\"Aggregation_Interval\",\"Flow_Sampling\",\"Metadata\",\"Logs_Filtered\"] | (., map(length*\"-\"))), \n        (.[] | \n          [\n            .name, \n            .purpose,\n            (if has(\"enableFlowLogs\") and .enableFlowLogs == true then \"Enabled\" else \"Disabled\" end),\n            (if has(\"logConfig\") then .logConfig.aggregationInterval else \"N/A\" end),\n            (if has(\"logConfig\") then .logConfig.flowSampling else \"N/A\" end),\n            (if has(\"logConfig\") then .logConfig.metadata else \"N/A\" end),\n            (if has(\"logConfig\") then (.logConfig | has(\"filterExpr\")) else \"N/A\" end)\n          ]\n        ) | \n        @tsv' | \\\n  column -t\n\n\nThe output of the above command will list:\n\neach subnet\nthe subnet's purpose\na Enabled or Disabled value if Flow Logs are enabled\nthe value for Aggregation Interval or N/A if disabled, the value for Flow Sampling or N/A if disabled\nthe value for Metadata or N/A if disabled\n'true' or 'false' if a Logging Filter is configured or 'N/A' if disabled.\n\nIf the subnet's purpose is PRIVATE then Flow Logs should be Enabled.\nIf Flow Logs is enabled then:\n\nAggregation_Interval should be INTERVAL_5_SEC\nFlow_Sampling should be 1\nMetadata should be INCLUDE_ALL_METADATA\nLogs_Filtered should be false.",
    "remediation_procedure": "From Google Cloud Console\n\n\nGo to the VPC network GCP Console visiting https://console.cloud.google.com/networking/networks/list\n\n\nClick the name of a subnet, The Subnet details page displays.\n\n\nClick the EDIT button.\n\n\nSet Flow Logs to On.\n\n\nExpand the Configure Logs section.\n\n\nSet Aggregation Interval to 5 SEC.\n\n\nCheck the box beside Include metadata.\n\n\nSet Sample rate to 100.\n\n\nClick Save.\n\n\nNote: It is not possible to configure a Log filter from the console.\nFrom Google Cloud CLI\nTo enable VPC Flow Logs for a network subnet, run the following command:\ngcloud compute networks subnets update [SUBNET_NAME] --region [REGION] --enable-flow-logs --logging-aggregation-interval=interval-5-sec --logging-flow-sampling=1 --logging-metadata=include-all",
    "default_value": "By default, Flow Logs is set to Off when a new VPC network subnet is created."
  },
  {
    "control_id": "16.7",
    "control": "Use Standard Hardening Configuration Templates for Application Infrastructure",
    "IG1": "-",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260475,
    "recommendation_id": 2036759,
    "view_level": "6.1.3",
    "title": "Ensure That the \u2018Local_infile\u2019 Database Flag for a Cloud SQL MySQL Instance Is Set to \u2018Off\u2019",
    "pivot_control_id": 505,
    "pivot_recommendation_id": 2036759,
    "url": "https://workbench.cisecurity.org/sections/1260475/recommendations/2036759",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 1"
      }
    ],
    "description": "It is recommended to set the local_infile database flag for a Cloud SQL MySQL instance to off.",
    "rationale_statement": "The local_infile flag controls the server-side LOCAL capability for LOAD DATA statements. Depending on the local_infile setting, the server refuses or permits local data loading by clients that have LOCAL enabled on the client side.\nTo explicitly cause the server to refuse LOAD DATA LOCAL statements (regardless of how client programs and libraries are configured at build time or runtime), start mysqld with local_infile disabled. local_infile can also be set at runtime.\nDue to security issues associated with the local_infile flag, it is recommended to disable it. This recommendation is applicable to MySQL database instances.",
    "impact_statement": "Disabling local_infile makes the server refuse local data loading by clients that have LOCAL enabled on the client side.",
    "audit_procedure": "From Google Cloud Console\n\nGo to the Cloud SQL Instances page in the Google Cloud Console by visiting https://console.cloud.google.com/sql/instances.\nSelect the instance to open its Instance Overview page\nEnsure the database flag local_infile that has been set is listed under the Database flags section.\n\nFrom Google Cloud CLI\n\nList all Cloud SQL database instances:\n\ngcloud sql instances list\n\n\nEnsure the below command returns off for every Cloud SQL MySQL database instance.\n\ngcloud sql instances describe INSTANCE_NAME --format=json | jq '.settings.databaseFlags[] | select(.name==\"local_infile\")|.value'",
    "remediation_procedure": "From Google Cloud Console\n\nGo to the Cloud SQL Instances page in the Google Cloud Console by visiting https://console.cloud.google.com/sql/instances.\nSelect the MySQL instance where the database flag needs to be enabled.\nClick Edit.\nScroll down to the Flags section.\nTo set a flag that has not been set on the instance before, click Add item, choose the flag local_infile from the drop-down menu, and set its value to off.\nClick Save.\nConfirm the changes under Flags on the Overview page.\n\nFrom Google Cloud CLI\n\nList all Cloud SQL database instances using the following command:\n\ngcloud sql instances list\n\n\nConfigure the local_infile database flag for every Cloud SQL Mysql database instance using the below command:\n\ngcloud sql instances patch INSTANCE_NAME --database-flags local_infile=off\n\nNote : \n\nThis command will overwrite all database flags that were previously set. To keep those and add new ones, include the values for all flags to be set on the instance; any flag not specifically included is set to its default value. For flags that do not take a value, specify the flag name followed by an equals sign (\"=\").",
    "default_value": "By default local_infile is on."
  },
  {
    "control_id": "16.10",
    "control": "Apply Secure Design Principles in Application Architectures",
    "IG1": "-",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260470,
    "recommendation_id": 2036720,
    "view_level": "1.12",
    "title": "Ensure API Keys Only Exist for Active Services",
    "pivot_control_id": 532,
    "pivot_recommendation_id": 2036720,
    "url": "https://workbench.cisecurity.org/sections/1260470/recommendations/2036720",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 2"
      }
    ],
    "description": "API Keys should only be used for services in cases where other authentication methods are unavailable. Unused keys with their permissions in tact may still exist within a project. Keys are insecure because they can be viewed publicly, such as from within a browser, or they can be accessed on a device where the key resides. It is recommended to use standard authentication flow instead.",
    "rationale_statement": "To avoid the security risk in using API keys, it is recommended to use standard authentication flow instead. Security risks involved in using API-Keys appear below:\n\n\nAPI keys are simple encrypted strings\n\n\nAPI keys do not identify the user or the application making the API request\n\n\nAPI keys are typically accessible to clients, making it easy to discover and steal an API key",
    "impact_statement": "Deleting an API key will break dependent applications (if any).",
    "audit_procedure": "From Console:\n\n\nFrom within the Project you wish to audit Go to APIs & Services\\Credentials.\n\n\nIn the section API Keys, no API key should be listed.\n\n\nFrom Google Cloud Command Line\n\n\nRun the following from within the project you wish to audit gcloud services api-keys list --filter.\n\n\nThere should be no keys listed at the project level.",
    "remediation_procedure": "From Console:\n\n\nGo to APIs & Services\\Credentials using\n\n\nIn the section API Keys, to delete API Keys: Click the Delete Bin Icon in front of every API Key Name.\n\n\nFrom Google Cloud Command Line\n\n\nRun the following from within the project you wish to audit gcloud services api-keys list --filter\n\n\n**Pipe the results into **\ngcloud alpha services api-keys delete",
    "default_value": "By default, API keys are not created for a project."
  },
  {
    "control_id": "16.10",
    "control": "Apply Secure Design Principles in Application Architectures",
    "IG1": "-",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260470,
    "recommendation_id": 2036721,
    "view_level": "1.13",
    "title": "Ensure API Keys Are Restricted To Use by Only Specified Hosts and Apps",
    "pivot_control_id": 532,
    "pivot_recommendation_id": 2036721,
    "url": "https://workbench.cisecurity.org/sections/1260470/recommendations/2036721",
    "assessment_status": "Manual",
    "applicable_profiles": [
      {
        "title": "Level 2"
      }
    ],
    "description": "API Keys should only be used for services in cases where other authentication methods are unavailable. In this case, unrestricted keys are insecure because they can be viewed publicly, such as from within a browser, or they can be accessed on a device where the key resides. It is recommended to restrict API key usage to trusted hosts, HTTP referrers and apps. It is recommended to use the more secure standard authentication flow instead.",
    "rationale_statement": "Security risks involved in using API-Keys appear below:\n\n\nAPI keys are simple encrypted strings\n\n\nAPI keys do not identify the user or the application making the API request\n\n\nAPI keys are typically accessible to clients, making it easy to discover and steal an API key\n\n\nIn light of these potential risks, Google recommends using the standard authentication flow instead of API keys. However, there are limited cases where API keys are more appropriate. For example, if there is a mobile application that needs to use the Google Cloud Translation API, but doesn't otherwise need a backend server, API keys are the simplest way to authenticate to that API.\nIn order to reduce attack vectors, API-Keys can be restricted only to trusted hosts, HTTP referrers and applications.",
    "impact_statement": "Setting Application Restrictions may break existing application functioning, if not done carefully.",
    "audit_procedure": "From Google Cloud Console\n\n\nGo to APIs & Services\\Credentials using https://console.cloud.google.com/apis/credentials\n\n\nIn the section API Keys, Click the API Key Name. The API Key properties display on a new page.\n\n\nFor every API Key, ensure the section Key restrictions parameter Application restrictions is not set to None.\n\n\nOr,\n\nEnsure Application restrictions is set to HTTP referrers and the referrer is not set to wild-cards (* or *.[TLD] or *.[TLD]/*) allowing access to any/wide HTTP referrer(s)\n\nOr,\n\nEnsure Application restrictions is set to IP addresses and  referrer is not set to any host (0.0.0.0 or 0.0.0.0/0 or ::0)\n\nFrom Google Cloud Command Line\n\nRun the following from within the project you wish to audit\n\ngcloud services api-keys list --filter=\"-restrictions:*\" --format=\"table[box](displayName:label='Key With No Restrictions')",
    "remediation_procedure": "From Google Cloud Console\nLeaving Keys in Place\n\n\nGo to APIs & Services\\Credentials using https://console.cloud.google.com/apis/credentials\n\n\nIn the section API Keys, Click the API Key Name. The API Key properties display on a new page.\n\n\nIn the Key restrictions section, set the application restrictions to any of HTTP referrers, IP addresses, Android apps, iOS apps.\n\n\nClick Save.\n\n\nRepeat steps 2,3,4 for every unrestricted API key.\nNote: Do not set HTTP referrers to wild-cards (* or *.[TLD] or .[TLD]/) allowing access to any/wide HTTP referrer(s)\nDo not set IP addresses and  referrer to any host (0.0.0.0 or 0.0.0.0/0 or ::0)\n\n\nRemoving Keys\nAnother option is to remove the keys entirely.\n\n\nGo to APIs & Services\\Credentials using https://console.cloud.google.com/apis/credentials\n\n\nIn the section API Keys, select the checkbox next to each key you wish to remove\n\n\nSelect Delete and confirm.",
    "default_value": "By default, Application Restrictions are set to None."
  },
  {
    "control_id": "16.10",
    "control": "Apply Secure Design Principles in Application Architectures",
    "IG1": "-",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260470,
    "recommendation_id": 2036722,
    "view_level": "1.14",
    "title": "Ensure API Keys Are Restricted to Only APIs That Application Needs Access",
    "pivot_control_id": 532,
    "pivot_recommendation_id": 2036722,
    "url": "https://workbench.cisecurity.org/sections/1260470/recommendations/2036722",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 2"
      }
    ],
    "description": "API Keys should only be used for services in cases where other authentication methods are unavailable. API keys are always at risk because they can be viewed publicly, such as from within a browser, or they can be accessed on a device where the key resides. It is recommended to restrict API keys to use (call) only APIs required by an application.",
    "rationale_statement": "Security risks involved in using API-Keys are below:\n\n\nAPI keys are simple encrypted strings\n\n\nAPI keys do not identify the user or the application making the API request\n\n\nAPI keys are typically accessible to clients, making it easy to discover and steal an API key\n\n\nIn light of these potential risks, Google recommends using the standard authentication flow instead of API-Keys. However, there are limited cases where API keys are more appropriate. For example, if there is a mobile application that needs to use the Google Cloud Translation API, but doesn't otherwise need a backend server, API keys are the simplest way to authenticate to that API.\nIn order to reduce attack surfaces by providing least privileges, API-Keys can be restricted to use (call) only APIs required by an application.",
    "impact_statement": "Setting API restrictions may break existing application functioning, if not done carefully.",
    "audit_procedure": "From Console:\n\n\nGo to APIs & Services\\Credentials using https://console.cloud.google.com/apis/credentials\n\n\nIn the section API Keys, Click the API Key Name. The API Key properties display on a new page.\n\n\nFor every API Key, ensure the section Key restrictions parameter API restrictions is not set to None.\n\n\nOr,\nEnsure API restrictions is not set to Google Cloud APIs\nNote: Google Cloud APIs represents the API collection of all cloud services/APIs offered by Google cloud.\nFrom Google Cloud CLI\n\nList all API Keys.\n\ngcloud services api-keys list\n\nEach key should have a line that says restrictions: followed by varying parameters and NOT have a line saying  - service: cloudapis.googleapis.com as shown here\n restrictions:\n  apiTargets:\n  - service: cloudapis.googleapis.com",
    "remediation_procedure": "From Console:\n\n\nGo to APIs & Services\\Credentials using https://console.cloud.google.com/apis/credentials\n\n\nIn the section API Keys, Click the API Key Name. The API Key properties display on a new page.\n\n\nIn the Key restrictions section go to API restrictions.\n\n\nClick the Select API drop-down to choose an API.\n\n\nClick Save.\n\n\nRepeat steps 2,3,4,5 for every unrestricted API key\n\n\nNote: Do not set API restrictions to Google Cloud APIs, as this option allows access to all services offered by Google cloud.\nFrom Google Cloud CLI\n\nList all API keys.\n\ngcloud services api-keys list\n\n\nNote the UID of the key to add restrictions to.\nRun the update command with the appropriate flags to add the required restrictions.\n\ngcloud alpha services api-keys update <UID> <restriction_flags>\n\nNote- Flags can be found by running\ngcloud alpha services api-keys update --help\n\nor in this documentation\nhttps://cloud.google.com/sdk/gcloud/reference/alpha/services/api-keys/update",
    "default_value": "By default, API restrictions are set to None."
  },
  {
    "control_id": "16.10",
    "control": "Apply Secure Design Principles in Application Architectures",
    "IG1": "-",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260470,
    "recommendation_id": 2036724,
    "view_level": "1.15",
    "title": "Ensure API Keys Are Rotated Every 90 Days",
    "pivot_control_id": 532,
    "pivot_recommendation_id": 2036724,
    "url": "https://workbench.cisecurity.org/sections/1260470/recommendations/2036724",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 2"
      }
    ],
    "description": "API Keys should only be used for services in cases where other authentication methods are unavailable. If they are in use it is recommended to rotate API keys every 90 days.",
    "rationale_statement": "Security risks involved in using API-Keys are listed below:\n\n\nAPI keys are simple encrypted strings\n\n\nAPI keys do not identify the user or the application making the API request\n\n\nAPI keys are typically accessible to clients, making it easy to discover and steal an API key\n\n\nBecause of these potential risks, Google recommends using the standard authentication flow instead of API Keys. However, there are limited cases where API keys are more appropriate. For example, if there is a mobile application that needs to use the Google Cloud Translation API, but doesn't otherwise need a backend server, API keys are the simplest way to authenticate to that API.\nOnce a key is stolen, it has no expiration, meaning it may be used indefinitely unless the project owner revokes or regenerates the key.\nRotating API keys will reduce the window of opportunity for an access key that is associated with a compromised or terminated account to be used.\nAPI keys should be rotated to ensure that data cannot be accessed with an old key that might have been lost, cracked, or stolen.",
    "impact_statement": "Regenerating Key may break existing client connectivity as the client will try to connect with older API keys they have stored on devices.",
    "audit_procedure": "From Google Cloud Console\n\n\nGo to APIs & Services\\Credentials using https://console.cloud.google.com/apis/credentials\n\n\nIn the section API Keys, for every key ensure the creation date is less than 90 days.\n\n\nFrom Google Cloud CLI\nTo list keys, use the command\ngcloud services api-keys list\n\nEnsure the date in createTime is within 90 days.",
    "remediation_procedure": "From Google Cloud Console\n\n\nGo to APIs & Services\\Credentials using https://console.cloud.google.com/apis/credentials\n\n\nIn the section API Keys, Click the API Key Name. The API Key properties display on a new page.\n\n\nClick REGENERATE KEY to rotate API key.\n\n\nClick Save.\n\n\nRepeat steps 2,3,4 for every API key that has not been rotated in the last 90 days.\n\n\nNote: Do not set HTTP referrers to wild-cards (* or *.[TLD] or .[TLD]/) allowing access to any/wide HTTP referrer(s)\nDo not set IP addresses and  referrer to any host (0.0.0.0 or 0.0.0.0/0 or ::0)\nFrom Google Cloud CLI\nThere is not currently a way to regenerate and API key using gcloud commands. To 'regenerate' a key you will need to create a new one, duplicate the restrictions from the key being rotated, and delete the old key.\n\nList existing keys.\n\ngcloud services api-keys list\n\n\n\nNote the UID and restrictions of the key to regenerate.\n\n\nRun this command to create a new API key. <key_name> is the display name of the new key.\n\n\ngcloud alpha services api-keys create --display-name=\"<key_name>\"\n\nNote the UID of the newly created key\n\nRun the update command to add required restrictions.\n\nNote - the restriction may vary for each key. Refer to this documentation for the appropriate flags.\nhttps://cloud.google.com/sdk/gcloud/reference/alpha/services/api-keys/update\ngcloud alpha services api-keys update <UID of new key>\n\n\nDelete the old key.\n\ngcloud alpha services api-keys delete <UID of old key>",
    "default_value": ""
  },
  {
    "control_id": "16.11",
    "control": "Leverage Vetted Modules or Services for Application Security Components",
    "IG1": "-",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260473,
    "recommendation_id": 2036778,
    "view_level": "4.10",
    "title": "Ensure That App Engine Applications Enforce HTTPS Connections",
    "pivot_control_id": 508,
    "pivot_recommendation_id": 2036778,
    "url": "https://workbench.cisecurity.org/sections/1260473/recommendations/2036778",
    "assessment_status": "Manual",
    "applicable_profiles": [
      {
        "title": "Level 2"
      }
    ],
    "description": "In order to maintain the highest level of security all connections to an application should be secure by default.",
    "rationale_statement": "Insecure HTTP connections maybe subject to eavesdropping which can expose sensitive data.",
    "impact_statement": "All connections to appengine will automatically be redirected to the HTTPS endpoint ensuring that all connections are secured by TLS.",
    "audit_procedure": "Verify that the app.yaml file controlling the application contains a line which enforces secure connections. For example\nhandlers:\n- url: /.*\n  secure: always\n  redirect_http_response_code: 301\n  script: auto\n\nhttps://cloud.google.com/appengine/docs/standard/python3/config/appref",
    "remediation_procedure": "Add a line to the app.yaml file controlling the application which enforces secure connections. For example\nhandlers:\n- url: /.*\n  **secure: always**\n  redirect_http_response_code: 301\n  script: auto\n\n[https://cloud.google.com/appengine/docs/standard/python3/config/appref]",
    "default_value": "By default both HTTP and HTTP are supported"
  },
  {
    "control_id": "17.2",
    "control": "Establish and Maintain Contact Information for Reporting Security Incidents",
    "IG1": "o",
    "IG2": "o",
    "IG3": "o",
    "section_id": 1260470,
    "recommendation_id": 2036725,
    "view_level": "1.16",
    "title": "Ensure Essential Contacts is Configured for Organization",
    "pivot_control_id": 514,
    "pivot_recommendation_id": 2036725,
    "url": "https://workbench.cisecurity.org/sections/1260470/recommendations/2036725",
    "assessment_status": "Automated",
    "applicable_profiles": [
      {
        "title": "Level 1"
      }
    ],
    "description": "It is recommended that Essential Contacts is configured to designate email addresses for Google Cloud services to notify of important technical or security information.",
    "rationale_statement": "Many Google Cloud services, such as Cloud Billing, send out notifications to share important information with Google Cloud users. By default, these notifications are sent to members with certain Identity and Access Management (IAM) roles. With Essential Contacts, you can customize who receives notifications by providing your own list of contacts.",
    "impact_statement": "There is no charge for Essential Contacts.",
    "audit_procedure": "From Google Cloud Console\n\nGo to Essential Contacts by visiting https://console.cloud.google.com/iam-admin/essential-contacts\nMake sure the organization appears in the resource selector at the top of the page.  The resource selector tells you what project, folder, or organization you are currently managing contacts for.\nEnsure that appropriate email addresses are configured for each of the following notification categories:\n\n\nLegal\nSecurity\nSuspension\nTechnical\nTechnical Incidents\n\nAlternatively, appropriate email addresses can be configured for the All notification category to receive all possible important notifications.\nFrom Google Cloud CLI\n\nTo list all configured organization Essential Contacts run a command:\n\ngcloud essential-contacts list --organization=<ORGANIZATION_ID>\n\n\nEnsure at least one appropriate email address is configured for each of the following notification categories:\n\n\nLEGAL\nSECURITY\nSUSPENSION\nTECHNICAL\nTECHNICAL_INCIDENTS\n\nAlternatively, appropriate email addresses can be configured for the ALL notification category to receive all possible important notifications.",
    "remediation_procedure": "From Google Cloud Console\n\nGo to Essential Contacts by visiting https://console.cloud.google.com/iam-admin/essential-contacts\nMake sure the organization appears in the resource selector at the top of the page.  The resource selector tells you what project, folder, or organization you are currently managing contacts for.\nClick +Add contact\nIn the Email and Confirm Email fields, enter the email address of the contact.\nFrom the Notification categories drop-down menu, select the notification categories that you want the contact to receive communications for.\nClick Save\n\nFrom Google Cloud CLI\n\nTo add an organization Essential Contacts run a command:\n\ngcloud essential-contacts create --email=\"<EMAIL>\" \\\n  --notification-categories=\"<NOTIFICATION_CATEGORIES>\" \\\n  --organization=<ORGANIZATION_ID>",
    "default_value": "By default, there are no Essential Contacts configured.\nIn the absence of an Essential Contact, the following IAM roles are used to identify users to notify for the following categories:\n\nLegal: roles/billing.admin\nSecurity: roles/resourcemanager.organizationAdmin\nSuspension: roles/owner\nTechnical: roles/owner\nTechnical Incidents: roles/owner"
  }
]